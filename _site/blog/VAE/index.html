<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
  Jekyll integration by somiibo.com
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
--><html>
	<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

<title>Variational Autoencoders Derived</title>
<meta name="description" content="">

<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/assets/icon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:4000/assets/icon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:4000/assets/icon/favicon-16x16.png">
<link rel="manifest" href="http://localhost:4000/assets/icon/manifest.json">
<link rel="mask-icon" href="http://localhost:4000/assets/icon/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="http://localhost:4000/assets/icon/favicon.ico">
<meta name="msapplication-config" content="http://localhost:4000/assets/icon/browserconfig.xml">
<meta name="theme-color" content="#ffffff">

<!-- CSS -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<noscript><link rel="stylesheet" href="http://localhost:4000/assets/css/noscript.css"></noscript>

	</head>
	<body class="is-loading">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Header -->
        <header id="header">
          <a href="http://localhost:4000/" class="logo">Ludwig Winkler</a>
        </header>

				<!-- Nav -->
					<nav id="nav">

            <ul class="links">
  <li class=""><a href="http://localhost:4000/">Home</a></li>
  <li class=" active "><a href="http://localhost:4000/blog/">Blog</a></li>
  <li class=""><a href="http://localhost:4000/readinglist/">Reading List</a></li>
  <li class=""><a href="http://localhost:4000/photography/">Photography</a></li>
  <li class=""><a href="http://localhost:4000/about/">About</a></li>
</ul>


						<ul class="icons">
              <li><a href="https://twitter.com/default" class="icon fa-twitter" rel="nofollow"><span class="label">Twitter</span></a></li>
              <!-- <li><a href="https://facebook.com/default" class="icon fa-facebook" rel="nofollow"><span class="label">Facebook</span></a></li> -->
              <!-- <li><a href="https://instagram.com/default" class="icon fa-instagram" rel="nofollow"><span class="label">Instagram</span></a></li> -->
              <li><a href="https://github.com/default" class="icon fa-github" rel="nofollow"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
				<div id="main">
          <section class="post">
    				<header class="major">
      				<span class="date">10 Aug 2020</span>
      				<h1>Variational Autoencoders Derived</h1>
      				<p>How to get to the objective function of VAEs ... </p>
      			</header>
      			<div class="image main"><img src="" alt=""></div>
      			<p></p>
<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
       <script type="text/x-mathjax-config">
         MathJax.Hub.Config({
           tex2jax: {
             inlineMath: [ ['$','$'], ["\\(","\\)"] ],
             displayMath: [['$$','$$']],
             processEscapes: true
           }
         });
       </script>
       <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


<!-- ### Variational Autoencoders -->

<p>Let $x$ denote a random variable which is generated by a random process.
This random process first samples a random latent variable $z$ and subsequently generates $x|z \sim p(x|z)$ by conditioning the random process $p(x|z)$ on the random variable $z$.
Thus we are dealing with a generative model which can generate valid samples $x$ from some random $z$.
We are interested in the latent distribution of $p(z||x)$ given the data $x$ and wish to learn it.
Intuitively, we want to know for a given $x$ what the latent variables $z$ were that generated them.
This is akin to observing some observation $x$ and being able to say: I know the $z$ ‘s that generated that!.</p>

<p>By Bayes rule we now that for a distribution $ p ( x | z ) $ there also exists the distribution $ p ( z | x ) $, the distribution we are interested in.</p>

<script type="math/tex; mode=display">\begin{align}
p(z|x) = \frac{p(z,x)}{p(x)} = \frac{p(x|z)p(z)}{p(x)}
\end{align}</script>

<p>The crux of the problem is that we can only observe the data distribution $p(x)$ through a data set $\mathcal{D}= \{ x_i \}_{i=0}^N$.
So we neither know what form the data generating process $p(x|z)$ has nor what the true latent distribution $p(z)$ is.
Additionally, the data probability $p(x)$ is even more obscure.
How would you even answer the question of how probable your data set is?</p>

<p>What we do know is the following: We want to find a variational distribution, let’s name it $q_\phi(z |x)$ with the optimizable parameters $\phi$, which we want to be as close as possible to the true distribution $p(z |x)$.
The motivation behind this formulation is that the true latent conditional distribution $p(z|x)$ could be very complicated, but we will choose a simpler variational distribution $q_\phi(z |x)$ that we can conveniently work with.
It might not be able to represent all the modes and fat tails that could potentially occur in $p(z |x)$ but better than nothing, right?</p>

<p>Information theory gives us the right tools to measure the difference between $q_\phi(z|x)$ and $p(z|x)$ through the Kullback-Leibler divergence:
<script type="math/tex">\mathbb{KL} \left[ q_\phi(z|x) \ || \ p(z|x) \right]</script>
The state of affairs sofar is that we have an easy to work with distribution $q_\phi(z|x)$ with the trainable parameters $\phi$ and that we wish to minimize the divergence to the true latent distribution $p(z|x)$.
We can also rewrite $p(z|x)$ according to Bayes rule to maybe make the computations a bit more tractable.
We can now write out the Kullback-Leibler divergence and inspect the terms that arise from some algebraic manipulation:</p>

<p><script type="math/tex">% <![CDATA[
\begin{align}
	\mathbb{KL} \left[ q_\phi(z \| x) \ || \ p(z \| x) \right] &= \mathbb{E}_{q_\phi(z \|x)} \left[ \log \frac{q_\phi(z \| x)}{p(z \| x)} \right] \\
	&= \mathbb{E}_{q_\phi(z|x)} \left[ \log q_\phi(z|x) - \log p(z|x)\right] \\
	&= \mathbb{E}_{q_\phi(z|x)} \left[ \log q_\phi(z|x) - \log \frac{p(z,x)}{p(x)}\right] \\
	&= \mathbb{E}_{q_\phi(z|x)} \left[ \log q_\phi(z|x) - \log p(z,x) + \log p(x)\right]
\end{align} %]]></script>
From earlier we know, that the data marginal probability $p(x)$ is almost surely intractable so we might want to avoid working with it directly.
But by applying Bayes’ rule we suddenly see that we are working with the joint probability $p(z,x)$.
Given the fact that $0 \leq \mathbb{KL}$ we can deduce
<script type="math/tex">% <![CDATA[
\begin{align}
	0 &\leq \mathbb{KL} \left[ q_\phi(z|x) \ || \ p(z|x) \right] \\
	0 &\leq \mathbb{E}_{q_\phi(z|x)} \left[ \log q_\phi(z|x) - \log p(z,x) + \log p(x) \right] \\
	0 &\geq \mathbb{E}_{q_\phi(z|x)} \left[ -\log q_\phi(z|x) + \log p(z,x) - \log p(x) \right] \\
	\log p(x) &\geq \mathbb{E}_{q_\phi(z|x)} \left[ - \log q_\phi(z|x) + \log p(z,x)\right] \\
	\log p(x) &\geq \mathbb{E}_{q_\phi(z|x)} \left[ - \log q_\phi(z|x) + \log p(x|z) p(z)\right] \\
	\log p(x) &\geq \mathbb{E}_{q_\phi(z|x)} \left[ - \log q_\phi(z|x) + \log p(x|z) + \log p(z)\right] \\
	\log p(x) &\geq \mathbb{E}_{q_\phi(z|x)} \left[ \log \frac{p(z)}{q_\phi(z|x)} + \log p(x|z) \right] \\
	\log p(x) &\geq -\mathbb{E}_{q_\phi(z|x)} \left[ \log \frac{q_\phi(z|x)}{p(z)} \right] + \mathbb{E}_{q_\phi(z|x)} \left[ \log p(x | z) \right] \\
	\log p(x) &\geq -\mathbb{KL} \left[ q_\phi(z|x) || p(z) \right] + \mathbb{E}_{q_\phi(z|x)} \left[ \log p(x|z) \right]
\end{align} %]]></script>
What does the inequality above tell us?
It says that if we want to maximize the probability of the data we must minimize the KL divergence in the first term and maximize the probability of the generative model $p(x|z)$.
So for any given $z$, we want the generative model $p(x|z)$.
If we optimize the two terms on the right, we will obtain an inference model $q_\phi(z|x)$ which inverts the generative model $p(x|z)$.</p>

<p>The problem, though, is that we have no clue what either $p(z)$ nor the true generative model $p(x|z)$ actually is.
Here comes the fun part: Let’s just assume stuff and parameterize both $p(z)$ and $p(x|z)$ such that we can easily and conveniently work with them.
Since $p(z)$ is a latent distribution we will enforce a strong simplicity by assuming that it follows a standard normal distribution $\mathcal{N}(0, I)$.
We could assume any other family of distributions but the standard normal distribution has lots of nice perks and properties.
This might seem bold but if the generative model $p(x|z)$ is flexible enough it can generate any $x$ from this comparatively simpel $z$.
Now let’s turn our attention to $p(x|z)$: We will change the unknown $p(x|z)$ to a parameterized and differentiable $p_\theta(x|z)$ such that we can maximize the probability of the data $x$ for a given $z$.</p>

<p>Now we have the following objective function:</p>

<script type="math/tex; mode=display">\begin{align}
	\log p(x) \geq -\mathbb{KL} \left[ q_\phi(z|x) || p(z) \right] + \mathbb{E}_{q_\phi(z|x)} \left[ \log p_\theta(x|z) \right]
\end{align}</script>

<p>which, upon closer inspection, has a lot of similarities to an autoencoder, except that it’s probabilistic!
We use the distribution $q_\phi(z|x)$ to infer some latent code from a given sample.
Through the KL divergence we enforce that the latent representation should be close to the simplified assumption of $p(z) = \mathcal{N}(0,I)$.
The same latent code $z$ should be reconstructed to the true sample $x$ by the generative model $p_\theta(x|z)$.
So we can actually interpret $q_\phi(z|x)$ as a probabilistic encoder and $p_\theta(x|z)$ as a decoder.</p>

<p>It is important to note that the prior and data loglikelihood are not balanced with respect to the data set size as it is done in Bayesian neural network and the parameter prior.
The KL divergence between the latent code $q_\phi(z|x)$ and the prior $p_\theta(z)$ is computed for each data point independently and is equally balanced.</p>

      		</section>

          <!-- <div class="comments-wrapper">
          <div id="disqus_thread"></div> -->
          <!-- <script>
              /**
               *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
               *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
               */

              var disqus_config = function () {
                  this.page.url = '/blog/VAE/';  /*Replace PAGE_URL with your page's canonical URL variable*/
                  this.page.identifier = '/blog/VAE/'; /*Replace PAGE_IDENTIFIER with your page's unique identifier variable*/
              };

              (function() {  /* dont endit below this line */
                  var d = document, s = d.createElement('script');

                  s.src = 'https://default.disqus.com/embed.js';

                  s.setAttribute('data-timestamp', +new Date());
                  (d.head || d.body).appendChild(s);
              })();
          </script> -->
          <!-- <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript> -->
        <!-- </div>/.comments-wrapper -->


					<!-- Footer -->
						<footer>
              <ul class="actions">
                <li><a href="http://localhost:4000/blog/" class="button">My Blog</a></li>
              </ul>
						</footer>
					</div>

				<!-- Footer -->
        <!-- <footer id="footer">
  <section>
    <form method="POST" action="https://formspree.io/">
      <div class="field">
        <label for="name">Name</label>
        <input type="text" name="name" id="name" />
      </div>
      <div class="field">
        <label for="email">Email</label>
        <input type="text" name="email" id="email" />
      </div>
      <div class="field">
        <label for="message">Message</label>
        <textarea name="message" id="message" rows="3"></textarea>
      </div>
      <ul class="actions">
        <li><input type="submit" value="Send Message" /></li>
      </ul>
    </form>
  </section>
  <section class="split contact">
    <section class="alt">
      <h3>Location</h3>
      <p>Berlin, Germany</p>
    </section>
    <section>
      <h3>Phone</h3>
      <p><a href="tel:"></a></p>
    </section>
    <section>
      <h3>Email</h3>
      <p><a href="mailto:"></a></p>
    </section>
    <section>
      <h3>Social</h3>
      <ul class="icons alt">
        <li><a href="https://twitter.com/ludiXIVwinkler" class="icon fa-twitter" rel="nofollow"><span class="label">Twitter</span></a></li>
        <!-- <li><a href="https://facebook.com/default" class="icon fa-facebook" rel="nofollow"><span class="label">Facebook</span></a></li> -->
        <!-- <li><a href="https://instagram.com/default" class="icon fa-instagram" rel="nofollow"><span class="label">Instagram</span></a></li> -->
        <li><a href="https://github.com/ludwigwinkler" class="icon fa-github" rel="nofollow"><span class="label">GitHub</span></a></li>
      
    
  

<!-- Copyright -->
<div id="copyright">
  <ul>
       <li>© HTML5 UP</li>
       <li>Design by <a href="https://html5up.net" rel="nofollow">HTML5 UP</a>
</li>
       <li>Jekyll Integration by <a href="https://soundgrail.com">SoundGrail</a>
</li>
       <li>Theme made by <a href="https://github.com/iwiedenm/jekyll-theme-massively-src"> iwiedenm</a>
</li>
 </ul>
</div>
 --&gt;

			</div>

      <!-- Scripts -->
  		<!-- <!-- DYN -->
<script src="http://localhost:4000/assets/js/jquery.min.js"></script>
<script src="http://localhost:4000/assets/js/jquery.scrollex.min.js"></script>
<script src="http://localhost:4000/assets/js/jquery.scrolly.min.js"></script>
<script src="http://localhost:4000/assets/js/skel.min.js"></script>
<script src="http://localhost:4000/assets/js/util.js"></script>
<script src="http://localhost:4000/assets/js/main.js"></script>
 --&gt;
			<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=default"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'default');
</script>
 -->

	</body>
</html>
