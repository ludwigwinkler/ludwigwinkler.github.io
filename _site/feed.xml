<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-10-15T22:28:39+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ludwig Winkler</title><subtitle>Jekyll version of the Massively theme by HTML5UP</subtitle><entry><title type="html">Israel to Jordan</title><link href="http://localhost:4000/blog/IsraelJordan23/" rel="alternate" type="text/html" title="Israel to Jordan" /><published>2023-10-14T00:00:00+02:00</published><updated>2023-10-14T00:00:00+02:00</updated><id>http://localhost:4000/blog/IsraelJordan23</id><content type="html" xml:base="http://localhost:4000/blog/IsraelJordan23/">&lt;!-- ## Berlin Over The Years --&gt;
&lt;style&gt;
    .image-gallery {overflow: auto; margin-left: -1%!important;}
    .image-gallery li {float: left; float: top; display: block; margin: 0 0 1% 1%; width: 99%;}
    .image-gallery li a {text-align: top; text-decoration: none!important; color: #777;}
    .image-gallery li a span {display: block; text-overflow: ellipsis; overflow: hidden; white-space: nowrap; padding: 3px 0;}
    .image-gallery li a img {width: 100%; height: 100%; display: flex; vertical-align: top;
    }
&lt;/style&gt;

&lt;ul class=&quot;image-gallery&quot;&gt;
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231001-_DSC3720.jpg&quot; title=&quot;20231001-_DSC3720&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231001-_DSC3720.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231001-_DSC3720&quot; title=&quot;20231001-_DSC3720&quot; /&gt;&lt;span&gt;20231001-_DSC3720&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231001-_DSC3720.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231001-_DSC3720.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231002-_DSC3839.jpg&quot; title=&quot;20231002-_DSC3839&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231002-_DSC3839.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231002-_DSC3839&quot; title=&quot;20231002-_DSC3839&quot; /&gt;&lt;span&gt;20231002-_DSC3839&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231002-_DSC3839.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231002-_DSC3839.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231003-_DSC3857.jpg&quot; title=&quot;20231003-_DSC3857&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231003-_DSC3857.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231003-_DSC3857&quot; title=&quot;20231003-_DSC3857&quot; /&gt;&lt;span&gt;20231003-_DSC3857&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231003-_DSC3857.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231003-_DSC3857.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231003-_DSC3925.jpg&quot; title=&quot;20231003-_DSC3925&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231003-_DSC3925.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231003-_DSC3925&quot; title=&quot;20231003-_DSC3925&quot; /&gt;&lt;span&gt;20231003-_DSC3925&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231003-_DSC3925.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231003-_DSC3925.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231003-_DSC3962.jpg&quot; title=&quot;20231003-_DSC3962&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231003-_DSC3962.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231003-_DSC3962&quot; title=&quot;20231003-_DSC3962&quot; /&gt;&lt;span&gt;20231003-_DSC3962&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231003-_DSC3962.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231003-_DSC3962.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231005-_DSC4279.jpg&quot; title=&quot;20231005-_DSC4279&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231005-_DSC4279.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231005-_DSC4279&quot; title=&quot;20231005-_DSC4279&quot; /&gt;&lt;span&gt;20231005-_DSC4279&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231005-_DSC4279.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231005-_DSC4279.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231006-_DSC4356.jpg&quot; title=&quot;20231006-_DSC4356&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231006-_DSC4356.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231006-_DSC4356&quot; title=&quot;20231006-_DSC4356&quot; /&gt;&lt;span&gt;20231006-_DSC4356&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231006-_DSC4356.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231006-_DSC4356.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4371.jpg&quot; title=&quot;20231008-_DSC4371&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231008-_DSC4371.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231008-_DSC4371&quot; title=&quot;20231008-_DSC4371&quot; /&gt;&lt;span&gt;20231008-_DSC4371&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4371.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231008-_DSC4371.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4395.jpg&quot; title=&quot;20231008-_DSC4395&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231008-_DSC4395.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231008-_DSC4395&quot; title=&quot;20231008-_DSC4395&quot; /&gt;&lt;span&gt;20231008-_DSC4395&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4395.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231008-_DSC4395.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4508.jpg&quot; title=&quot;20231008-_DSC4508&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231008-_DSC4508.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231008-_DSC4508&quot; title=&quot;20231008-_DSC4508&quot; /&gt;&lt;span&gt;20231008-_DSC4508&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4508.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231008-_DSC4508.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4594.jpg&quot; title=&quot;20231008-_DSC4594&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231008-_DSC4594.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231008-_DSC4594&quot; title=&quot;20231008-_DSC4594&quot; /&gt;&lt;span&gt;20231008-_DSC4594&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4594.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231008-_DSC4594.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4802.jpg&quot; title=&quot;20231008-_DSC4802&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231008-_DSC4802.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231008-_DSC4802&quot; title=&quot;20231008-_DSC4802&quot; /&gt;&lt;span&gt;20231008-_DSC4802&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4802.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231008-_DSC4802.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4948.jpg&quot; title=&quot;20231008-_DSC4948&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231008-_DSC4948.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231008-_DSC4948&quot; title=&quot;20231008-_DSC4948&quot; /&gt;&lt;span&gt;20231008-_DSC4948&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231008-_DSC4948.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231008-_DSC4948.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231009-_DSC5257.jpg&quot; title=&quot;20231009-_DSC5257&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231009-_DSC5257.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231009-_DSC5257&quot; title=&quot;20231009-_DSC5257&quot; /&gt;&lt;span&gt;20231009-_DSC5257&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231009-_DSC5257.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231009-_DSC5257.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231009-_DSC5294.jpg&quot; title=&quot;20231009-_DSC5294&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231009-_DSC5294.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231009-_DSC5294&quot; title=&quot;20231009-_DSC5294&quot; /&gt;&lt;span&gt;20231009-_DSC5294&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231009-_DSC5294.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231009-_DSC5294.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231009-_DSC5325.jpg&quot; title=&quot;20231009-_DSC5325&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/israeljordan23/20231009-_DSC5325.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;20231009-_DSC5325&quot; title=&quot;20231009-_DSC5325&quot; /&gt;&lt;span&gt;20231009-_DSC5325&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/israeljordan23/20231009-_DSC5325.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/israeljordan23/20231009-_DSC5325.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
&lt;/ul&gt;</content><author><name></name></author><category term="photography" /><summary type="html">Tel Aviv, Jerusalem and Wadi Rum</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/photo_gallery/israeljordan23/20231009-_DSC5294.jpg" /></entry><entry><title type="html">Fokker, Planck &amp;amp; Kolmogorov Revisited</title><link href="http://localhost:4000/blog/Kramers/" rel="alternate" type="text/html" title="Fokker, Planck &amp; Kolmogorov Revisited" /><published>2023-07-21T00:00:00+02:00</published><updated>2023-07-21T00:00:00+02:00</updated><id>http://localhost:4000/blog/Kramers</id><content type="html" xml:base="http://localhost:4000/blog/Kramers/">&lt;head&gt;
&lt;!-- &lt;script type=&quot;text/x-mathjax-config&quot;&gt;  --&gt;
  &lt;!-- MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: &quot;all&quot; } } }); &lt;/script&gt; --&gt;
&lt;!-- uncomment two lines above and remove the html css to svg lines --&gt;
&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: &quot;all&quot; } },
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [ ['$','$'], [&quot;\\(&quot;,&quot;\\)&quot;] ],
      displayMath: [['$$','$$'], ['\[' , '\]'], ['\\[', '\\]']],
      processEscapes: true
    },
    &quot;HTML-CSS&quot;: { linebreaks: { automatic: true } },
    CommonHTML: { linebreaks: { automatic: true } },
    SVG: { linebreaks: { automatic: true } }
    });
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;

&lt;p&gt;A Dutch, a German and a Russian walk into a bar â€¦&lt;/p&gt;

&lt;p&gt;At the core of the partial differential equations that will describe the change of a distribution both forward and backward in time lies the Chapman-Kolmogorov equation
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	p(x_{t + \tau}) &amp; = \int p(x_{t + \tau} , x'_{t}) \ dx'_t \\
	&amp; = \int p(x_{t + \tau} | x'_{t}) \ p(x'_t) \ dx'_t
\end{align} %]]&gt;&lt;/script&gt;
which simply expands over an auxiliary variable $xâ€™_t$ while simultaneously marginalizing it out and factorizing the joint distribution &lt;script type=&quot;math/tex&quot;&gt;p(x_{t+\tau}, x'_t)&lt;/script&gt; into a conditional distribution.
The conditional distribution above states that we can start from any &lt;script type=&quot;math/tex&quot;&gt;x'_t&lt;/script&gt; and by moving to &lt;script type=&quot;math/tex&quot;&gt;x_{t+\tau}&lt;/script&gt; with the right transition probability &lt;script type=&quot;math/tex&quot;&gt;p(x_{t + \tau} | x'_{t})&lt;/script&gt; we will obtain the correct marginal distribution &lt;script type=&quot;math/tex&quot;&gt;p(x_{t+\tau})&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;We will assume a stochastic differential equation the first two orders of which can be estimated with
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	M^{(n)} (x'_t) = \int (x_{t+\tau} - x'_t)^n  p(x_{t + \tau} | x'_t) dx_{t+\tau}
\end{align}&lt;/script&gt;
such that the dynamics are described by the Ito drift-diffusion process
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	dX'_t = &amp; M^{(1)}(X'_t) dt + M^{(2)}(X'_t) dW_t \\
	= &amp; \mu(X'_t, t) dt + \sigma(X'_t, t) dW_t \\
\end{align} %]]&gt;&lt;/script&gt;
with the Wiener process &lt;script type=&quot;math/tex&quot;&gt;W_t&lt;/script&gt;.
The important part is to note the â€˜directionâ€™ of the differential which is evaluated strictly forward in time.
We take &lt;script type=&quot;math/tex&quot;&gt;x'_t&lt;/script&gt; as a sort of origin point which doesnâ€™t change and weight the differential &lt;script type=&quot;math/tex&quot;&gt;x_{t+\tau} - x'_t&lt;/script&gt; by the appropriate transition probability &lt;script type=&quot;math/tex&quot;&gt;p(x_{t+\tau} | x'_t)&lt;/script&gt; over every possible &lt;script type=&quot;math/tex&quot;&gt;x_{t+\tau}&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;forward-equation&quot;&gt;Forward Equation&lt;/h3&gt;

&lt;p&gt;The Chapman-Kolmogorov equation fro the forward Kramers-Moyal expansion can be rewritten with the help of an auxilliary variable as
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	p(x_{t + \tau}) = &amp; \int p(x_{t + \tau} | x'_{t}) \ p(x'_t) \ dx'_t \\
	= &amp; \int_{X'} \int_{Y} \delta(y_{t+\tau} - x_{t+\tau}) p(y_{t + \tau} | x'_{t}) \ dy_{t+\tau} p(x'_t) dx'_t
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The main component of the Kramers-Moyal expansions is the use of the Taylor expansion on a shifted function.
The classical Taylor expansion $T_{f,a}(x)$ of a function $f(x)$ around a root point $a$ says that we can reconstruct the function $f(x)$ with an infinite sum consisting of its derivatives
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	T_{f,a}(x) = \sum_{n=0}^\infty \frac{f^{(n)}(a)}{n!} (x - a)^n
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;What happens if we introduce an offset $h$ to the root point $a$ which can take on any value we want?
It turns out that the arbitrary offset $h$ can directly be used as a distance measure to the root point.
The Taylor expansion of the shifted function $f(a + h)$ then becomes
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	T_{f,a}(h) = \sum_{n=0}^\infty \frac{f^{(n)}(a)}{n!} h^n
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can then first expand the delta function $\delta ( y_{t+\tau} - x_{t+\tau} )$ with $\pm x_t$ and subsequently expand the Taylor series to obtain
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	\delta(y_{t+\tau} - x_{t+\tau}) = &amp; \delta(\overbrace{y_{t+\tau} - x'_t}^{h} + \overbrace{x'_t - x_{t+\tau}}^{a} ) \\
	= &amp; \sum_{n=0}^\infty \frac{1}{n!} \underbrace{\partial_{x'}^{n} \delta(x'_t - x_{t+\tau}) }_{f^{(n)}(a)} \underbrace{( y_{t+\tau} - x'_t)^n}_{h^n}
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can plug the expanded Taylor series back in to get
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
p(x_{t + \tau}) 
= &amp; \int_{X'} \int_{Y} \overbrace{\delta(y_{t+\tau} - x_{t+\tau})}^{\text{Taylor Expansion}} p(y_{t + \tau} | x'_{t}) \ dy_{t+\tau} \ p(x'_t) dx'_t \\
= &amp; \int_{X'} \int_{Y} \sum_{n=0}^\infty \frac{1}{n!} ( y_{t+\tau} - x'_t)^n \ \partial_{x'}^{n} \left[ \delta(x'_t - x_{t+\tau}) \right] p(y_{t + \tau} | x'_{t}) \ dy_{t+\tau} \ p(x'_t) dx'_t \\
= &amp; \sum_{n=0}^\infty \frac{1}{n!} \int_{X'} \int_{Y} ( y_{t+\tau} - x'_t)^n \ \underbrace{ \partial_{x'}^{n} \left[ \delta(x'_t - x_{t+\tau})\right]}_{?} p(y_{t + \tau} | x'_{t}) \ dy_{t+\tau} \ p(x'_t) dx'_t \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Now we need to find out, how to deal with the $n$â€™th derivative of Dirac delta function inside an integral.&lt;/p&gt;

&lt;h3 id=&quot;a-quick-intermezzo-on-delta-functions-and-integration-by-parts&quot;&gt;A Quick Intermezzo on Delta Functions and Integration by Parts&lt;/h3&gt;

&lt;p&gt;In my work so far, I got the feeling that two mathematical tricks provide the most joy to physicists when they donâ€™t know how to proceed: 1) Taylor Expansions and 2) Integration by Parts.
We already encountered the Taylor expansion, so get ready to observe the second trick, integration by parts (IbP).&lt;/p&gt;

&lt;p&gt;It should be first stated that the delta is a weird beast which is more or less only defined where itâ€™s argument is zero.
For $\delta(0)=1$ and $\delta(x)=0, x \neq 0$.
For an integral of the product of $\int \delta(x=xâ€™) f(x) dx = f(xâ€™)$, the Dirac delta function serves as a sort of â€˜selectorâ€™ which ignores any contribution of the integral except where $x=xâ€™$ because only when $x=xâ€™$ will it be one, otherwise zero.&lt;/p&gt;

&lt;p&gt;Fortunately, we can yield the physicists favourite magic spell when dealing with probabilities: Integration by Parts.
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
\int_{x=-\infty}^\infty u'(x) v(x) dx = \left[ u(x) v(x) \right]_{x=-\infty}^\infty - \int_{x=-\infty}^\infty u(x) v'(x) dx
\end{align}&lt;/script&gt;
which is the just integrating a rearranged product rule $(u(x) v(x))â€™ = uâ€™(x) v(x) + u(x) vâ€™(x)$ over the domain of $x$:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\int_a^b (u(x) v(x))' dx &amp;= \int_a^b u'(x) v(x) dx + \int_a^b u(x) v'(x) dx \\
&amp; \Updownarrow \\
\int u'(x) v(x) dx &amp;= \left[ u(x) v(x) \right]_{x=a}^b - \int_a^b u(x) v'(x) dx
\end{align} %]]&gt;&lt;/script&gt;
where the integration cancels only the derivative of the product as the others are a product of a derivative and another function.&lt;/p&gt;

&lt;p&gt;If the function $f(x)$ has compact support, meaning that ${f(x)=0 | x = \pm \infty }$, the the evaluation of the derivative-free component in integration by parts vanishes.
So if weâ€™re dealing with a probability distribution which is assumed to be zero at the far ends, we obtain the simplified term
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
\int_{x=-\infty}^\infty \delta'(x) f(x) dx = \underbrace{\left[ \delta(x) f(x) \right]_{x=-\infty}^\infty}_{=0} - \int_{x=-\infty}^\infty \delta(x) f'(x) dx
\end{align}&lt;/script&gt;
For higher order derivatives this generalizes to
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
\int_{x=-\infty}^\infty \delta^{(n)} (x) f(x) dx = \sum_k^{n-1} \left[ (-1)^k \delta^{(k)}(x) f^{(n-k)}(x) \right]_{x=-\infty}^\infty + (-1)^n \int_{x=-\infty}^\infty \delta(x) f^{(n)}(x) dx
\end{align}&lt;/script&gt;
which more or less moves the all the derivatives from the Dirac delta function over to $f(x)$ which is often called the â€˜test functionâ€™ when inside an integral over the full domain.
Since all the derivates and the function $f$ itself are zero at $x=\pm \infty$, $f^{(n)}(\pm \infty) = f(\pm \infty)=0 \ \forall n \in \mathbb{N}$, the term simplifies to
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\int_{x=-\infty}^\infty \delta^{(n)} (x) f(x) dx &amp;= \underbrace{\sum_k^{n-1} \left[ (-1)^k \delta^{(k)}(x) f^{(n-k)}(x) \right]_{x=-\infty}^\infty}_{f^{(n)}(\pm \infty) = f(\pm \infty)=0} + (-1)^n \int_{x=-\infty}^\infty \delta(x) f^{(n)}(x) dx \\
&amp;= (-1)^n \int_{x=-\infty}^\infty \delta(x) f^{(n)}(x) dx
\end{align} %]]&gt;&lt;/script&gt;
which we will utilize in our further derivation.&lt;/p&gt;

&lt;p&gt;Intermezzo is over.&lt;/p&gt;

&lt;h3 id=&quot;continuing-with-kramers-moyal&quot;&gt;Continuing with Kramers-Moyal&lt;/h3&gt;

&lt;p&gt;We now have 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
p(x_{t + \tau}) 
= &amp; \sum_{n=0}^\infty \frac{1}{n!} \int_{X'} \int_{Y} ( y_{t+\tau} - x'_t)^n \ \underbrace{ \partial_{x'}^{n} \left[ \delta(x'_t - x_{t+\tau})\right]}_{?} p(y_{t + \tau} | x'_{t}) \ dy_{t+\tau} \ p(x'_t) dx'_t \\
\end{align} %]]&gt;&lt;/script&gt;
which we rearrange to
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
p(x_{t + \tau}) 
= &amp; \sum_{n=0}^\infty \frac{1}{n!} \int_{X'} \partial_{x'}^{n} \left[ \delta(x'_t - x_{t+\tau})\right] \underbrace{\int_{Y} ( y_{t+\tau} - x'_t)^n \ p(y_{t + \tau} | x'_{t}) \ dy_{t+\tau}}_{M^{(n)}(x'_t)} \ p(x'_t) dx'_t \\
= &amp; \sum_{n=0}^\infty \frac{1}{n!} \underbrace{ \int_{X'} \underbrace{ \partial_{x'}^{n} \left[ \delta(x'_t - x_{t+\tau})\right]}_{u'(x)} \underbrace{M^{(n)}(x'_t) \ p(x'_t)}_{v(x)} dx'_t }_{\text{Integration by Parts with Dirac delta function}} \\
= &amp; \sum_{n=0}^\infty \frac{1}{n!} (-1)^n \int_{X'} \delta(x'_t - x_{t+\tau}) \partial_{x'}^{n}  \left[ M^{(n)}(x'_t) \ p(x'_t) \right] dx'_t\\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The delta function &lt;script type=&quot;math/tex&quot;&gt;\delta(x'_t - x_{t+\tau})&lt;/script&gt; is only one if the values of the two &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;â€™s is the same &lt;em&gt;irrespective of time&lt;/em&gt;.
It thus serves as a selector which reduces to the integral over the domain &lt;script type=&quot;math/tex&quot;&gt;X'&lt;/script&gt; to a single evaluation at the numerical value of &lt;script type=&quot;math/tex&quot;&gt;x_{t+\tau}&lt;/script&gt;.
So we get the following sum which we expand up to the second order
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
p(x_{t + \tau}) 
= &amp; \sum_{n=0}^\infty \frac{1}{n!} (-1)^n \partial_{x}^{n}  \left[ M^{(n)}(x_t) \ p(x_t) \right]\\
= &amp; p(x_t) - \partial_{x} \left[ M^{(1)}(x_t) \ p(x_t) \right] + \frac{1}{2} \partial_{x}^2  \left[ M^{(2)}(x_t) \ p(x_t) \right] + \mathcal{O}(n^3)\\
\end{align} %]]&gt;&lt;/script&gt;
where the $n=0$ eliminates most of the operators in the first summand.
Pulling &lt;script type=&quot;math/tex&quot;&gt;p(x_t)&lt;/script&gt; to the left side and finding that the change between &lt;script type=&quot;math/tex&quot;&gt;p(x_{t+\tau})&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;p(x_t)&lt;/script&gt; should be proportional to &lt;script type=&quot;math/tex&quot;&gt;\partial_t p(x_t) \tau&lt;/script&gt; for a small step size &lt;script type=&quot;math/tex&quot;&gt;\tau&lt;/script&gt; analogously to an Euler discretization, we obtain
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	p(x_{t+\tau}) - p(x_t) = &amp; \partial_t p(x_t) \tau \\
	\frac{p(x_{t+\tau}) - p(x_t)}{\tau} = &amp; \partial_t p(x_t).
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Finally we can note that we can could cut off the Taylor expansion after the second order and realize that Taylor expansion is equivalent to the time derivative in the limit of time, i.e. &lt;script type=&quot;math/tex&quot;&gt;\lim_{\tau \rightarrow 0}&lt;/script&gt; and we can proclaim that
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	\partial_t p(x_t) = &amp; - \partial_{x_t} \left[ M^{(1)}(x_t) p(x_t) \right] + \frac{1}{2} \partial_{x_t}^2 \left[M^{(2)}(x_t) p(x_t) \right] \\
	= &amp; - \partial_{x_t} \left[ \mu(x_t) p(x_t) \right] + \frac{1}{2} \partial_{x_t}^2 \left[ \sigma^2(x_t) p(x_t) \right] \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;!-- $$
\begin{align}
	\partial_t p(x_t) = &amp; - \partial_{x_t} \left[ \mu(x_t) p(x_t) \right] + \frac{1}{2} \partial_{x_t}^2 \left[ \sigma^2(x_t) p(x_t) \right] \\
\end{align}
$$ --&gt;

&lt;h3 id=&quot;backward-equation&quot;&gt;Backward Equation&lt;/h3&gt;

&lt;p&gt;The Kolmogorov backward equation (KBE) can be derived in the same way while paying attention to the derivatives.&lt;/p&gt;

&lt;p&gt;In the Kolmogorov forward equation the differential operators &lt;script type=&quot;math/tex&quot;&gt;M^{(n)}&lt;/script&gt; were defined for for stochastic variables following the natural arrow of time.
For the backward expansion of &lt;script type=&quot;math/tex&quot;&gt;p(x_t | x'_{t'})&lt;/script&gt; we will use differential operators on &lt;script type=&quot;math/tex&quot;&gt;x'_{t'}&lt;/script&gt;.
We thus have the ordering of time &lt;script type=&quot;math/tex&quot;&gt;t' \leq t' + \tau \leq t&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Again we start with the Chapman-Kolmogorov equation and insert an intermediate variable &lt;script type=&quot;math/tex&quot;&gt;x''_{t+\tau}&lt;/script&gt;:
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	p(x_t | x'_t) = \int p(x_t | x''_{t'+\tau}) p(x''_{t'+\tau} | x'_{t'}) dx''_{t'+\tau}
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We expand the transition probability &lt;script type=&quot;math/tex&quot;&gt;p(x''_{t'+\tau} | x'_{t'})&lt;/script&gt; again with a Dirac function 
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	p(x''_{t'+\tau} | x'_{t'}) = \int \delta(y_{t'+\tau} - x''_{t'+\tau}) p(y_{t'+\tau} | x'_{t'}) dy_{t'+\tau}
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Then we expand the Dirac function with the Taylor series just as in the Forward Kolmogorov equation to obtain
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	\delta(y_{t'+\tau} - x''_{t'+\tau})
	= &amp; \delta( y_{t'+\tau} - x'_{t'} + x'_{t'} - x''_{t'+\tau}) \\
	= &amp; \sum_{n=0}^\infty \frac{1}{n!} (y_{t' + \tau} - x'_{t'})^n \ \partial_{x'}^n \ \delta(x'_{t'} - x''_{t'+\tau})
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Plugging the expanded Dirac function back into the transition probability we obtain
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	p(x''_{t'+\tau} | x'_{t'}) = &amp; \int \delta(y_{t'+\tau} - x''_{t'+\tau}) p(y_{t'+\tau} | x_{t'}) dy_{t+\tau} \\
	= &amp; \int \sum_{n=0}^\infty \frac{1}{n!} (y_{t' + \tau} - x'_{t'})^n \ \partial_{x'}^n \ \delta(x'_{t'} - x''_{t'+\tau}) p(y_{t'+\tau} | x_{t}) dy_{t'+\tau} \\
	= &amp; \sum_{n=0}^\infty \frac{1}{n!} \partial_{x'}^n \ \delta(x'_{t'} - x''_{t'+\tau}) \int (y_{t' + \tau} - x'_t)^n  p(y_{t'+\tau} | x_{t'}) dy_{t'+\tau} \\
	= &amp; \sum_{n=0}^\infty \frac{1}{n!} \partial_{x'}^n \ \delta(x'_{t'} - x''_{t'+\tau}) M^{(n)}(x'_{t'}) \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We now plug in the Taylor expansion to substitute &lt;script type=&quot;math/tex&quot;&gt;p(x''_{t'+\tau} | x'_{t'})&lt;/script&gt; in our original master equation and get
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	p(x_t | x'_t) 
	&amp;= \int p(x_t | x''_{t'+\tau}) p(x''_{t'+\tau} | x'_{t'}) dx''_{t'+\tau} \\
	&amp;= \int p(x_t | x''_{t'+\tau}) \sum_{n=0}^\infty \frac{1}{n!} \partial_{x'}^n \ \delta(x'_{t'} - x''_{t'+\tau}) M^{(n)}(x'_{t'}) dx''_{t'+\tau} \\
	&amp;= \sum_{n=0}^\infty \frac{1}{n!} M^{(n)}(x'_{t'}) \int p(x_t | x''_{t'+\tau}) \partial_{x'}^n \ \delta(x'_{t'} - x''_{t'+\tau}) dx''_{t'+\tau} \\
\end{align} %]]&gt;&lt;/script&gt;
where we pulled out the &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; and the &lt;script type=&quot;math/tex&quot;&gt;M^{(n)}(x'_{t'})&lt;/script&gt; as they are independent of the integral over &lt;script type=&quot;math/tex&quot;&gt;x''_{t'+\tau}&lt;/script&gt;.
Given our derivation of the KFE, we would be quick to reapply integration by parts, but it turns out that the distribution inside the integral doesnâ€™t contain &lt;script type=&quot;math/tex&quot;&gt;x'_{t'}&lt;/script&gt; and therefore we can pull the derivative out of the integral.
Since a Dirac delta function inside an integral is just a selector, we eliminate the integral and obtain
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	p(x_t | x'_t) 
	&amp;= \sum_{n=0}^\infty \frac{1}{n!} M^{(n)}(x'_{t'}) \ \partial_{x'}^n \int p(x_t | x''_{t'+\tau}) \ \delta(x'_{t'} - x''_{t'+\tau}) dx''_{t'+\tau} \\
	&amp;= \sum_{n=0}^\infty \frac{1}{n!} M^{(n)}(x'_{t'}) \ \partial_{x'}^n p(x_t | x'_{t'+\tau}) \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Expanding the sum up to the second order 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	p(x_t | x'_t) 
	&amp;= p(x_t | x'_{t'+\tau}) + M^{(1)}(x'_{t'}) \ \partial_{x'} p(x_t | x'_{t'+\tau}) + \frac{1}{2} M^{(2)}(x'_{t'}) \ \partial_{x'}^2 p(x_t | x'_{t'+\tau}) \\
\end{align} %]]&gt;&lt;/script&gt;
and taking the limit of &lt;script type=&quot;math/tex&quot;&gt;\tau \rightarrow 0&lt;/script&gt; while discretizing it a la Euler, we get
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	p(x_t | x'_t) - p(x_t | x'_{t'+\tau})
	&amp;= M^{(1)}(x'_{t'}) \ \partial_{x'} p(x_t | x'_{t'+\tau}) + \frac{1}{2} M^{(2)}(x'_{t'}) \ \partial_{x'}^2 p(x_t | x'_{t'+\tau}) \\
	- (p(x_t | x'_{t'+\tau}) - p(x_t | x'_t))
	&amp;= M^{(1)}(x'_{t'}) \ \partial_{x'} p(x_t | x'_{t'}) \ \tau + \frac{1}{2} M^{(2)}(x'_{t'}) \ \partial_{x'}^2 p(x_t | x'_{t'}) \ \tau \\
\end{align} %]]&gt;&lt;/script&gt;
and by dividing by &lt;script type=&quot;math/tex&quot;&gt;\tau&lt;/script&gt;, we finally get
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	- \frac{p(x_t | x'_{t'+\tau}) - p(x_t | x'_t)}{\tau}
	&amp;= - \partial_{x'} p(x_t | x'_{t'}) \\
	&amp;= M^{(1)}(x'_{t'}) \ \partial_{x'} p(x_t | x'_{t'}) + \frac{1}{2} M^{(2)}(x'_{t'}) \ \partial_{x'}^2 p(x_t | x'_{t'}) \\
	&amp;= \mu(x'_{t'}) \ \partial_{x'} p(x_t | x'_{t'}) + \frac{1}{2} \sigma^2(x'_{t'}) \ \partial_{x'}^2 p(x_t | x'_{t'}) \\
\end{align} %]]&gt;&lt;/script&gt;
which tells us how the probability distribution &lt;script type=&quot;math/tex&quot;&gt;p(x_t | x'_{t'})&lt;/script&gt; changes as we move further backwards in time.&lt;/p&gt;</content><author><name></name></author><summary type="html">Distributions as partial differential equations over time</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/blog/blogthumbnails/kramersmoyal.png" /></entry><entry><title type="html">Fokker, Planck &amp;amp; Ito</title><link href="http://localhost:4000/blog/FokkerPlanck/" rel="alternate" type="text/html" title="Fokker, Planck &amp; Ito" /><published>2023-07-21T00:00:00+02:00</published><updated>2023-07-21T00:00:00+02:00</updated><id>http://localhost:4000/blog/FokkerPlanck</id><content type="html" xml:base="http://localhost:4000/blog/FokkerPlanck/">&lt;head&gt;
&lt;!-- &lt;script type=&quot;text/x-mathjax-config&quot;&gt;  --&gt;
  &lt;!-- MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: &quot;all&quot; } } }); &lt;/script&gt; --&gt;
&lt;!-- uncomment two lines above and remove the html css to svg lines --&gt;
&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: &quot;all&quot; } },
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [ ['$','$'], [&quot;\\(&quot;,&quot;\\)&quot;] ],
      displayMath: [['$$','$$'], ['\[' , '\]'], ['\\[', '\\]']],
      processEscapes: true
    },
    &quot;HTML-CSS&quot;: { linebreaks: { automatic: true } },
    CommonHTML: { linebreaks: { automatic: true } },
    SVG: { linebreaks: { automatic: true } }
    });
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\newcommand{\Efunc}[1]{\mathbb{E}\left[ #1\right]}
\newcommand{\Vfunc}[1]{\mathbb{V}\left[ #1\right]}
\newcommand{\KL}[2]{\text{KL}\left[ #1 \ || \ #2 \right]}
\newcommand{\denom}[1]{\frac{1}{#1}}
\newcommand{\drift}{\mu(X_t, t)}
\newcommand{\diff}{\sigma(X_t, t)}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;A Dutch, a German and a Japanese walk into a bar â€¦&lt;/p&gt;

&lt;p&gt;Let us consider the random variable &lt;script type=&quot;math/tex&quot;&gt;X_t&lt;/script&gt; that follows an Ito drift-diffusion process of the form
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	dX_t = \drift dt + \diff dW_t
\end{align}&lt;/script&gt;
where &lt;script type=&quot;math/tex&quot;&gt;W_t&lt;/script&gt; is a Wiener process with &lt;script type=&quot;math/tex&quot;&gt;W_t \sim \mathcal{N}(0, t)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;We want to study an arbitrary function &lt;script type=&quot;math/tex&quot;&gt;f(X_t)&lt;/script&gt; with a compact support, meaning that &lt;script type=&quot;math/tex&quot;&gt;f(X_t)=0, X_t \in \{ -\infty, \infty \}&lt;/script&gt;.
Intuitively, this means that for the extreme values of &lt;script type=&quot;math/tex&quot;&gt;\pm \infty&lt;/script&gt; the function &lt;script type=&quot;math/tex&quot;&gt;f(X_t)&lt;/script&gt; evaluates to zero. 
The function &lt;script type=&quot;math/tex&quot;&gt;f(X_t)&lt;/script&gt; should be twice differentiable in its argument &lt;script type=&quot;math/tex&quot;&gt;X_t&lt;/script&gt; such that we can use the Taylor expansion up to the second order, giving us 
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	df = \partial_x f(X_t) dX_t + \denom{2} \partial_x^2 f(X_t) dX_t^2.
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;For the infinitissimal values &lt;script type=&quot;math/tex&quot;&gt;dt&lt;/script&gt;, any term with an exponent higher than one will go towards zero at a faster rate.
Thus the terms &lt;script type=&quot;math/tex&quot;&gt;dt^2&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;dt dW_t = dt^{1.5}&lt;/script&gt; will evaluate to zero at the limit.
We can then plug in the dynamics of &lt;script type=&quot;math/tex&quot;&gt;X_t&lt;/script&gt; to obtain
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	df(X_t) = &amp; \partial_x f(X_t) dX_t + \denom{2} \partial_x^2 f(X_t) dX_t^2 \\
	= &amp; \partial_x f(X_t) \left( \drift dt + \diff dW_t \right) + \denom{2} \partial_x^2 f(X_t) \left(\drift dt + \diff dW_t \right)^2 \\
	= &amp; \partial_x f(X_t) \left( \drift dt + \diff dW_t \right) \\
	&amp; + \denom{2} \partial_x^2 f(X_t) \big( \drift^2 \underbrace{dt^2}_{=0} + \drift \diff \underbrace{ dt \ dW_t}_{=0} + \diff^2 \underbrace{dW_t^2}_{=dt} \big) \\
	= &amp;\left(\drift \partial_x f(X_t) + \denom{2} \diff^2 \partial_x^2 f(X_t) \right) dt + \diff \partial_x f(X_t) dW_t 
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can abbreviate the notation to enable a higher degree of notational brevity and write
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	df = \left( \mu \partial_x f + \denom{2} \sigma^2 \partial_x^2 f \right) dt + \sigma \partial_x f dW_t
\end{align}&lt;/script&gt;
which is identical to the line above but shorter and less cluttered.&lt;/p&gt;

&lt;p&gt;We can easily see that the differential &lt;script type=&quot;math/tex&quot;&gt;df&lt;/script&gt; follows an Ito drift-diffusion process, although with modified drift and diffusion terms in direct comparison to &lt;script type=&quot;math/tex&quot;&gt;dX_t&lt;/script&gt;.
Naturally we can take the expectation of to isolate the drift of &lt;script type=&quot;math/tex&quot;&gt;df&lt;/script&gt; since &lt;script type=&quot;math/tex&quot;&gt;\Efunc{dW_t}=0&lt;/script&gt; by definition,
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	\Efunc{df} &amp; = \Efunc{ \mu \partial_x f + \denom{2} \sigma^2 \partial_x^2 f } dt \\
	\frac{d}{dt} \Efunc{f} &amp; = \Efunc{ \mu \partial_x f + \denom{2} \sigma^2 \partial_x^2 f }
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Since the Wiener process &lt;script type=&quot;math/tex&quot;&gt;W_t&lt;/script&gt; introduces stochasticity into the evolution of &lt;script type=&quot;math/tex&quot;&gt;X_t&lt;/script&gt;, we are in fact dealing with a distribution &lt;script type=&quot;math/tex&quot;&gt;p(x, t)&lt;/script&gt;.
We can then proceed by plugging in the distribution &lt;script type=&quot;math/tex&quot;&gt;p(x, t)&lt;/script&gt; into the expectation and writing it out in its full glory,
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	\frac{d}{dt} \Efunc{f} &amp; = \Efunc{ \mu \partial_x f + \denom{2} \sigma^2 \partial_x^2 f } \\
	&amp;= \int_{-\infty}^\infty \left( \mu \partial_x f + \denom{2} \sigma^2 \partial_x^2 f \right) p(x, t) dx \\
	&amp;= \int_{-\infty}^\infty \mu \ \partial_x f \ p(x, t) dx + \denom{2} \int_{-\infty}^\infty \sigma^2 \ \partial_x^2 f \ p(x, t) dx
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The state so far is that we reduced the expected change in &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; to two integrals which we now have to solve.
For this we can utilize integration by parts which is the sort of the anti derivative of the product rule.
Remember that
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	\partial_x \left[ u(x) v(x) \right] = \partial_x \left[  u(x) \right] v(x) + u(x) \partial_x \left[ v(x) \right]
\end{align}&lt;/script&gt;
or in a easier form
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	\left( u(x) v(x) \right)' = u'(x) v(x) + u(x) v'(x)
\end{align}&lt;/script&gt;
The integration by parts rule states that for a range &lt;script type=&quot;math/tex&quot;&gt;x \in [ a, b ]&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	\left[ u(x) v(x) \right]_a^b = \int_a^b u'(x) v(x) dx + \int_a^b u(x) v'(x) dx
\end{align}&lt;/script&gt;
or alternatively
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	\int_a^b u(x) v'(x) dx = \left[ u(x) v(x) \right]_a^b - \int_a^b u'(x) v(x) dx + 
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can now proceed to identify the relevant terms &lt;script type=&quot;math/tex&quot;&gt;u(x)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;v(x)&lt;/script&gt; in the two integrals,
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	\frac{d}{dt} \Efunc{f} = &amp; \int_{-\infty}^\infty \underbrace{\mu \ p(x, t)}_{u(x)} \ \underbrace{\partial_x f}_{v'(x)}  dx + \denom{2} \int_{-\infty}^\infty \underbrace{ \sigma^2 \ p(x, t)}_{u(x)} \ \underbrace{\partial_x^2 f}_{v
	(x)} dx \\
	= &amp; \underbrace{\left[  \mu \ p(x, t)  \  f \right]_{-\infty}^\infty}_{=0} - \int_{-\infty}^\infty  \partial_x \left[ \mu \ p(x, t) \right] \ f \ dx \\
	&amp; + \denom{2} \underbrace{\left[  \sigma^2 \ p(x, t)  \  \partial_x f \right]_{-\infty}^\infty}_{=0} - \denom{2} \int_{-\infty}^\infty  \partial_x \left[ \sigma^2 \ p(x, t) \right] \ \partial_x f \ dx
\end{align} %]]&gt;&lt;/script&gt;
For any reasonable probability distribution, evaluating &lt;script type=&quot;math/tex&quot;&gt;p(x,t)&lt;/script&gt; at &lt;script type=&quot;math/tex&quot;&gt;\pm \infty&lt;/script&gt; evaluates to zero such that the evaluation brackets &lt;script type=&quot;math/tex&quot;&gt;\left[ p(x,t) \ldots \right]_{-\infty}^\infty = 0&lt;/script&gt;.
We can then apply the integration by parts a second time on the second integral to obtain
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	\frac{d}{dt} \Efunc{f} = &amp; - \int_{-\infty}^\infty  \partial_x \left[ \mu \ p(x, t) \right] \ f \ dx - \denom{2} \int_{-\infty}^\infty  \underbrace{\partial_x \left[ \sigma^2 \ p(x, t) \right]}_{u(x)} \ \underbrace{\partial_x f}_{v'(x)} \ dx \\
	= &amp; \int_{-\infty}^\infty  \partial_x \left[ \mu \ p(x, t) \right] \ f \ dx \\
	&amp; - \denom{2} \underbrace{\left[ \partial_x \left[ \sigma^2 \ p(x, t) \right] \ f \right]_{-\infty}^\infty}_{=0} + \denom{2} \int_{-\infty}^\infty  \partial_x^2 \left[ \sigma^2 \ p(x, t) \right] \ f \ dx \\
	= &amp; \int_{-\infty}^\infty f \left( - \partial_x \left[ \mu \ p(x, t) \right] + \denom{2} \partial_x^2 \left[ \sigma^2 \ p(x, t) \right] \right) dx
\end{align} %]]&gt;&lt;/script&gt;
With Leibnizâ€™ rule we can pull in the time derivative on the left hand side to obtain
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
	\frac{d}{dt} \Efunc{f} = &amp; \frac{d}{dt} \int_{-\infty}^\infty f(x) p(x,t) dx \\
	=&amp; \int_{-\infty}^\infty f(x) \ \partial_t \ p(x,t) dx
\end{align} %]]&gt;&lt;/script&gt;
which gives us
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	\int_{-\infty}^\infty f(x) \ \partial_t \ p(x,t) dx = \int_{-\infty}^\infty f \left( - \partial_x \left[ \mu \ p(x, t) \right] + \denom{2} \partial_x^2 \left[ \sigma^2 \ p(x, t) \right] \right) dx
\end{align}&lt;/script&gt;
The last step to obtain the Fokker-Planck equation is to observe that the function &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; which is integrated over occurs both on the left and the right hand side.
Since the integrals &lt;script type=&quot;math/tex&quot;&gt;\int f(x) \ldots dx&lt;/script&gt; is identical on both sides we can equate the derivatives directly to obtain
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
	\partial_t \ p(x,t) = - \partial_x \left[ \mu \ p(x, t) \right] + \denom{2} \partial_x^2 \left[ \sigma^2 \ p(x, t) \right]
\end{align}&lt;/script&gt;
which is the Fokker-Planck equation!&lt;/p&gt;</content><author><name></name></author><summary type="html">Fokker-Planck Equation Via Ito Calculus</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/blog/blogthumbnails/fokkerplanckito.png" /></entry><entry><title type="html">Fast Fourier Transform</title><link href="http://localhost:4000/blog/FastFourierTransform/" rel="alternate" type="text/html" title="Fast Fourier Transform" /><published>2023-04-11T00:00:00+02:00</published><updated>2023-04-11T00:00:00+02:00</updated><id>http://localhost:4000/blog/FastFourierTransform</id><content type="html" xml:base="http://localhost:4000/blog/FastFourierTransform/">&lt;head&gt;
&lt;!-- &lt;script type=&quot;text/x-mathjax-config&quot;&gt;  --&gt;
  &lt;!-- MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: &quot;all&quot; } } }); &lt;/script&gt; --&gt;
&lt;!-- uncomment two lines above and remove the html css to svg lines --&gt;
&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: &quot;all&quot; } },
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [ ['$','$'], [&quot;\\(&quot;,&quot;\\)&quot;] ],
      displayMath: [['$$','$$'], ['\[' , '\]'], ['\\[', '\\]']],
      processEscapes: true
    },
    &quot;HTML-CSS&quot;: { linebreaks: { automatic: true } },
    CommonHTML: { linebreaks: { automatic: true } },
    SVG: { linebreaks: { automatic: true } }
    });
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;
&lt;/head&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\def\tr#1{\text{Tr}\left[ #1 \right]}
 \def\Efunc#1{\mathPbb{E}\left[ #1\right]}
 \def\Efuncc#1#2{\mathbb{E}_{#1}\left[ #2 \right]}
 \def\red#1{\textcolor{red}{#1}}
 \def\blue#1{\textcolor{blue}{#1}}
 \newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;During the Easter holiday at my parents house, I discovered a 800 page digital signal processings book in my dadâ€™s book shelf.
Leafing through the pages and examining the table of contents, I saw a whole section on the Fast Fourier Transform (FFT) which has been called by many scientists one of the most important algorithms of our time.&lt;/p&gt;

&lt;p&gt;To quote â€˜What a Wonderful Worldâ€™ by Louis Armstrong:&lt;/p&gt;

&lt;p&gt;ðŸŽ¼ &lt;em&gt;â€˜And I think to myself, what a wonderful (world) algorithm â€¦â€˜&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;But how does this apparently â€˜super-duper important algorithmâ€™ actually work?
Thatâ€™s when I went down a rabbit whole full of complex exponentials, recursion and nifty tricks for periodic functions.&lt;/p&gt;

&lt;h3 id=&quot;why-were-going-to-what-were-going-to-do&quot;&gt;Why weâ€™re going to what weâ€™re going to do&lt;/h3&gt;

&lt;p&gt;If you went looking for an explanation of the Fast Fourier Transform (FFT) you already know how frequencies, Fourier transformations and complex numbers relate to each other.
One thing to point out is that FFT is an algorithm to compute the Discrete Fourier Transform (DFT) efficiently.
So Iâ€™m going to skip the introduction on the continuous Fourier transformation and the like.&lt;/p&gt;

&lt;h3 id=&quot;eulers-identity&quot;&gt;Eulerâ€™s Identity&lt;/h3&gt;

&lt;p&gt;It always amazes me how a few mathematicians 200-300 years ago laid the theoretical groundwork for so many ideas that we use today on a daily basis.
The names of Gauss, Euler, Fourier and Laplace have appeared so many times in my studies and work that you tend to forgot that those people did their work with a candle on their desk because the use of electricity developed yet, while the fundamental basics of electrical engineering stands on the shoulders of their enormous mathematical contributions.&lt;/p&gt;

&lt;p&gt;My understanding of the FFT started out with the innocuous equation known as Eulerâ€™s Identity:
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
  e^{\pm i x} = \cos x \pm i sin x
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Weâ€™re fairly familiar with the standard &lt;script type=&quot;math/tex&quot;&gt;e^x&lt;/script&gt; which is just the exponential function but once we introduce the complex number $i$ into the fray, things get really, not exactly weird, but circly and trigonometric.&lt;/p&gt;

&lt;p&gt;The real exponential can be rewritten as
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
  e^{x} = \sum_{k=0}^\infty \frac{x^k}{k!}
\end{align}&lt;/script&gt;
and if we add the complex number $i$ as an argument modifier, it starts to modify the entire equation:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  e^{x} 
  &amp;= \sum_{k=0}^\infty \frac{(ix)^k}{k!} \\
  &amp;= \sum_{k=0}^\infty i^k \frac{x^k}{k!}.
\end{align} %]]&gt;&lt;/script&gt;
Now we have to deal with infinite power of the complex number $i$ but it turns out it reduces to just four numbers,
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align*}
  i^0 &amp;= 1                  &amp;&amp;  i^4 = i^3 \cdot i = -i \cdot i  &amp;&amp; = 1  &amp;&amp; \ldots\\
  i^1 &amp;= i                  &amp;&amp;  i^5 = i^4 \cdot i = 1 \cdot i   &amp;&amp; = i   &amp;&amp; \ldots\\
  i^2 &amp;= -1                 &amp;&amp;  i^6 = i^5 \cdot i = i \cdot i   &amp;&amp; = -1  &amp;&amp; \ldots\\
  i^3 &amp;= i \cdot i^2 = -i   &amp;&amp;  i^7 = i^6 \cdot i = -1 \cdot i  &amp;&amp; = -i &amp;&amp; \ldots \\
\end{align*} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;the computation of which we can recycle every fourth power with the modulo operator $k \% 4$.&lt;/p&gt;

&lt;p&gt;We can now write out the sum for a couple of terms and see whether a convenient structure reveals itself (spoiler alert: it does):
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  e^{ix} 
  &amp;= 1 + i x - \frac{x^2}{2!} - i \frac{x^3}{3!} + \frac{x^4}{4!} + i \frac{x^5}{5!} - \frac{x^6}{6!} - i \frac{x^7}{7!} + \ldots \\
  &amp;= \underbrace{1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \ldots}_{\text{Real}} + \underbrace{i \left( x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} \ldots \right)}_{\text{Imaginary}} \\
  &amp;= \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!} x^{2n} + i \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)!} x^{2n+1}
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where $i$â€™th power switches the sign of the terms and whether theyâ€™re complex or not according to the table a few lines above.&lt;/p&gt;

&lt;p&gt;Fortunately for us, it just so happens that the MacLaurin series (Taylor series when the root is zero) for the sine and cosine are precisely the power series that occured in the equation above, 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  e^{ix} 
  &amp;= 1 + i x - \frac{x^2}{2!} - i \frac{x^3}{3!} + \frac{x^4}{4!} + i \frac{x^5}{5!} - \frac{x^6}{6!} - i \frac{x^7}{7!} + \ldots \\
  &amp;= \underbrace{1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \ldots}_{\text{Real}} + \underbrace{i \left( x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} \ldots \right)}_{\text{Imaginary}} \\
  &amp;= \underbrace{\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!} x^{2n}}_{\text{MacLaurin Series: } \cos(x)} + i \underbrace{\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)!} x^{2n+1}}_{\text{MacLaurin Series:} \sin(x)} \\
  &amp;= \cos(x) + i \sin(x)
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;I like to think of complex numbers as endowing a linear term with an additional, magic dimension which can interact with the real dimension in convenient ways.
While complex numbers live in a â€˜2Dâ€™ real and imaginary space with two dimensions, quaternions take it to a whole new level and allow working with multiple dimensions, all enclosed in linear terms.
The advantage is that a possibly complex rotation around the origin is just a simple addition for complex numbers.
So instead of constructing complicated rotation matrices all you have to do is multiply two linear terms where the imaginary respectively quaternions take care of the cross-dimensional interactions.&lt;/p&gt;

&lt;h3 id=&quot;the-nth-root-of-unity-or-walking-around-a-circle-in-n-steps&quot;&gt;The nâ€™th Root of Unity (or walking around a circle in N steps)&lt;/h3&gt;

&lt;p&gt;The second ingredient to the Discrete Fourier Transform (DFT) is walking in a circle in the complex plane.
Let us define a function $w(n)$ with $0 \leq n \leq N$
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
w(n) 
&amp;= e^{-i 2 \pi \frac{n}{N}} \\
&amp;= \cos\left(2 \pi \frac{n}{N} \right) - i \sin \left(2 \pi \frac{n}{N} \right)
\end{align} %]]&gt;&lt;/script&gt;
where we can conclude that the ratio lies in $0 \leq \frac{n}{N} \leq 1$ since $0 \leq n \leq N$.
We know that a full rotation of a sine and cosine function in terms of radians is defined in the range $[0, 2 \pi]$.
If we plug the fraction $\frac{n}{N}$ as multiplicative factor in front of the $2\pi$ then we will move from $0$ to $2\pi$ in exactly $n$ steps.
Plugging $2 \pi \frac{n}{N}$ into the sine and cosine function lets us do a full rotation in the complex plane in precisely $n$ steps.&lt;/p&gt;

&lt;p&gt;The term $e^{-i 2 \pi \frac{n}{N}}$ is called the nâ€™th root of unity, although I prefer to think of it as doing a full rotation with a radius of one in the complex plane in $n$ steps.&lt;/p&gt;

&lt;h3 id=&quot;the-star-of-the-show-the-discrete-fourier-transform&quot;&gt;The Star of the Show: The Discrete Fourier Transform&lt;/h3&gt;

&lt;p&gt;Letâ€™s get the horse out of the barn and define the Discrete Fourier Transform (DFT) as
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  X_k 
  &amp;= \sum_{n=0}^{N-1} x_n e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{n}{N}} \\
\end{align} %]]&gt;&lt;/script&gt;
which for a signal of length $N$ computes $0 \leq k \leq N-1$ frequency components (where the $N-1$ arises from zero indexing which we use to denote the offset of the signal at $k=0$).&lt;/p&gt;

&lt;p&gt;In my undergraduate signals and systems courses, I liked to think of Fourier analysis algorithms as computing the ratio between a signal and a composite frequency by dropping the complex part below the main signal:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  X_k 
  &amp;= \sum_{n=0}^{N-1} x_n e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{n}{N}} \\
  &amp;= \sum_{n=0}^{N-1} \frac{x_n}{e^{i 2 \pi \ \cdot \ k \ \cdot \ \frac{n}{N}}} \\
\big( \text{contribution of frequency} &amp;= \frac{\text{signal}}{\text{frequency}} \big)
\end{align} %]]&gt;&lt;/script&gt;
An alternative intuition for me is the that the Fourier transform computes the correlation of a signal with a series of sinusoids with increasing frequency.
If a signal aligns perfectly with a particular sinusoid, it will yield a high correlation score, whereas if the signal is completely orthogonal, it has zero correlation and will the correlation score is zero.&lt;/p&gt;

&lt;p&gt;One technical peculiarity, which is determined by the Nyquist-Shannon sampling theorem, is that we can have only half the number of frequency bins vis-a-vis the signal length.
The discrete signal $x_n$ is by definition a sampling frequency, as the underlying continuous signal is sampled/measured at discrete steps.
Nyquist-Shannon says that you need twice the sampling frequency for a signal in order to be sure that you have a â€˜definiteâ€™ representation of the signal.
For a signal of length N, we can only have $N/2$ present frequencies which we can accurately measure.&lt;/p&gt;

&lt;p&gt;I spend a good hour figuring out why the DFT of a real signal is always mirrored in the frequency bins.
Most explanations on the internet only plot the real part of the spectrum, which is precisely where that detail matters.
Unsurprisingly for a real signal, this equates to plotting
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
X_k 
&amp;= \text{Re}\left( \sum_{n=0}^{N-1} x_n e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{n}{N}} \right) \\
&amp;= \text{Re} \left( \sum_{n=0}^{N-1} x_n \left( \cos\left(2 \pi k \frac{n}{N} \right) - i \sin \left(2 \pi k \frac{n}{N} \right) \right) \right) \\
&amp;= \sum_{n=0}^{N-1} x_n \cos \left(2 \pi k \frac{n}{N} \right).
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Considering that the cosine function is periodic by definition it is mirrored at points $(â€¦ -2\pi, -\pi, 0, \pi, 2\pi, â€¦)$.
Said differently, 
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
\cos(x) = \cos(2\pi - x), \quad 0 \leq x \leq 2\pi
\end{align}&lt;/script&gt;
which repeats for arbitrary integer multiples of 2 in either directions as $\cos$ is an even, periodic function from $0$ to $2\pi$.
So we have
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\text{Re}\left( X_k \right) 
&amp;\stackrel{!}{=} \text{Re}\left( X_{N-k} \right) \\
\sum_{n=0}^{N-1} x_n \cos \left(2 \pi k \frac{n}{N} \right) 
&amp; = \sum_{n=0}^{N-1} x_n \cos \left(2 \pi (N-k) \frac{n}{N} \right) \\
&amp; = \sum_{n=0}^{N-1} x_n \cos \left(2 \pi n -2 \pi k \frac{n}{N} \right) \\
&amp; = \sum_{n=0}^{N-1} x_n \cos \left( - 2 \pi k \frac{n}{N} \right) \\
&amp; = \sum_{n=0}^{N-1} x_n \cos \left(2 \pi k \frac{n}{N} \right) \\
\end{align} \\ %]]&gt;&lt;/script&gt;
where since $n$ is an integer, the $2 \pi n$ term is just a full period in the cosine function and the for an even function such as the cosine, $f(x)=f(-x)$, the negative sign is in the RHS cosine function is identical to its positive sign.&lt;/p&gt;

&lt;p&gt;If the signal $x_n$ is complex, this feature does not hold anymore, as complex $i \sin$ terms would interact with complex parts of the signal $x_n$ resulting in â€˜spill oversâ€™ into the real dimension as the multiplication of two imaginary numbers results in a real number.&lt;/p&gt;

&lt;h3 id=&quot;the-cooler-sibling-of-the-dft-the-fast-fourier-transform&quot;&gt;The cooler sibling of the DFT: The Fast Fourier Transform&lt;/h3&gt;

&lt;p&gt;One big drawback of the DFT is that it scales quadratically with the signal length, requiring $N^2$ operations for a signal of length $N$.
Remember that 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  X_k 
  &amp;= \sum_{n=0}^{N-1} x_n e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{n}{N}} \\
\end{align} %]]&gt;&lt;/script&gt;
which implies that for each $0 \leq k \leq N$ frequencies we need to add $N$ terms in the summation with additional multiplications of complex numbers.
For a real signal, we can save the second half, $N/2 \leq k \leq N$ as its a symmetric evaluation, but that doesnâ€™t hold for complex signals.&lt;/p&gt;

&lt;p&gt;The solution is a divide and conquer algorithm which heavily exploits the specific structure of the $n$â€™th root of unities in the complex exponential.
Remember that the naive implementation would cost us $O(N^2)$ computations for a signal of length $N$.
We wonâ€™t get around examining every entry $n$ in the signal so one $N$ has to stay, because otherwise we would skip possibly essential data in the signal.
But we can exploit the cyclic structure in the $n$â€™th root of unity (aka the complex exponential) and reuse computations to reduce the $N$ in the frequencies to a $\log N$ to get an $O(N \log N)$ algorithm.&lt;/p&gt;

&lt;h3 id=&quot;an-algebraic-approach&quot;&gt;An Algebraic Approach&lt;/h3&gt;

&lt;p&gt;Letâ€™s consider the DFT for a particular frequency $X_k$:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  X_k 
  &amp;= \sum_{n=0}^{N-1} x_n e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{n}{N}} \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;which we can rewrite to equivalently by dividing the even and odd numbered entries in the signal $x_n$ to
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  X_k 
  &amp;= \sum_{m=0}^{N/2-1} \underbrace{x_{2m} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{2m}{N}} }_{\text{even DFT computations of $x_n$}} + \sum_{m=0}^{N/2-1} \underbrace{ x_{2m+1} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{2m+1}{N}} }_{\text{odd DFT computations of $x_n$}} \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;This split into even and odd entries is valid, as we might only go from $[0, â€¦, m, â€¦, N/2]$ but we compensate for that by scaling the index from $m$ to $2m$.&lt;/p&gt;

&lt;p&gt;Next we split off the $+1$ in the complex exponential in the odd DFT computations and drop the $2$ below the fraction in the complex exponential to get
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
X_k 
&amp;= \sum_{m=0}^{N/2-1} \underbrace{x_{2m} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{2m}{N}} }_{\text{even DFT computations of $x_n$}}  + \sum_{m=0}^{N/2-1} \underbrace{ x_{2m+1} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{2m+1}{N}} }_{\text{odd DFT computations of $x_n$}} \\
&amp;= \sum_{m=0}^{N/2-1}x_{2m} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{2m}{N}} + e^{-i 2 \pi \frac{k}{N}} \sum_{m=0}^{N/2-1} x_{2m+1} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{2m}{N}} \\
&amp;= \sum_{m=0}^{N/2-1}x_{2m} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{m}{N/2}} + e^{-i 2 \pi \frac{k}{N}} \sum_{m=0}^{N/2-1} x_{2m+1} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{m}{N/2}} \\
&amp;= \text{DFT}(\text{even}(x_n), k, N/2) + e^{-i 2 \pi \frac{k}{N}} \ \text{DFT}(\text{odd}(x_n), k, N/2) \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;and right here is the key insight that each summand has the exact same functional form of a DFT that we defined earlier, except for a multiplication for the odd entries and the shortened index $m$.&lt;/p&gt;

&lt;p&gt;But we furthermore exploit the periodicity of the sinusoids, which we already encounter in the frequency spectrum of real signals above.
An even function is more or less defined as $f(x) = f(-x)$ and an odd function as $f(x) = - f(-x)$.&lt;/p&gt;

&lt;p&gt;Now it just so happens that the cosine is an even function and the sinus is an odd function for a single period.
But since we defined our signal of length $N$ over a single period of $2 \pi$ (for specific integer multiple $k$, but thatâ€™s not important for the intuition), we now that for a cosine we only have to compute ${0, \ldots, k, \ldots, N/2}$  since ${N/2, \ldots, k, \ldots, N}$ is handed to us on a platter due to the even property of the cosine function.&lt;/p&gt;

&lt;p&gt;The same applies to the sinus function which we can mirror for all always of ${N/2, \ldots, k, \ldots, N}$ by adjusting it with the complex exponential.
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  X_k 
  &amp;= \text{DFT}(\text{even}(x_n), k, N/2) + e^{-i 2 \pi \frac{k}{N}} \ \text{DFT}(\text{odd}(x_n), k, N/2) \\
  X_{k + \frac{N}{2}}
  &amp;= \text{DFT}(\text{even}(x_n), k, N/2) - e^{-i 2 \pi \frac{k}{N}} \ \text{DFT}(\text{odd}(x_n), k, N/2) \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can show this more rigorously by writing out $X_{k + \frac{N}{2}}$ to get
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  X_{k + \frac{N}{2}} 
  &amp;= \sum_{m=0}^{N/2-1}x_{2m} e^{-i 2 \pi \ \cdot \ (k + \frac{N}{2}) \ \cdot \ \frac{m}{N/2}} + e^{-i 2 \pi \frac{(k+ \frac{N}{2})}{N}} \sum_{m=0}^{N/2-1} x_{2m+1} e^{-i 2 \pi \ \cdot \ (k + \frac{N}{2}) \ \cdot \ \frac{m}{N/2}} \\
  &amp;= \sum_{m=0}^{N/2-1}x_{2m} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{m}{N/2}} \underbrace{\ e^{-i2\pi \ m}}_{=1 + i 0 = 1} + e^{-i 2 \pi \frac{k}{N}} \underbrace{e^{-i\pi}}_{=-1} \sum_{m=0}^{N/2-1} x_{2m+1} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{m}{N/2}} \ \underbrace{e^{-i2\pi \ m}}_{= 1 + i0 = 1} \\
  &amp;= \sum_{m=0}^{N/2-1}x_{2m} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{m}{N/2}} - e^{-i 2 \pi \frac{k}{N}} \sum_{m=0}^{N/2-1} x_{2m+1} e^{-i 2 \pi \ \cdot \ k \ \cdot \ \frac{m}{N/2}} \\
  &amp;= \text{DFT}(\text{even}(x_n), k, N/2) - e^{-i 2 \pi \frac{k}{N}} \ \text{DFT}(\text{odd}(x_n), k, N/2) \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where the complex exponentials evaluate accordingly due to $m$ being integers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The log scaling of the FFT algorithm stems from the fact that we can split the computation into even and odd terms which are again DFTâ€™s, and that each application of a DFT gives us the second half of the frequency bins for for free (with a simple array addition and one complex multiplication).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I said earlier that we canâ€™t save ourselves from going through our signal at least once, but by exploiting the symmetry properties of the sinusoids, we already halved the computations for the $k$ frequency bins in half.
So while we have to do a full â€˜spatialâ€™ pass of $n$ over the $x_n$â€™s, we can save ourselves half the time by mirroring in the â€˜frequencyâ€™ pass for the index $k$.&lt;/p&gt;

&lt;p&gt;We can play this game again to get
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  \text{DFT}(\text{even}(x_n), k, N/2) 
  &amp;= \text{DFT}(\text{even}(\text{even}(x_n)), k, N/4)+ e^{-i 2 \pi \frac{k}{N}} \ \text{DFT}(\text{odd}(\text{even}(x_n)), k, N/4) \\
  &amp; + e^{-i 2 \pi \frac{k}{N}} \left( \text{DFT}(\text{even}(\text{odd}(x_n)), k, N/4)+ e^{-i 2 \pi \frac{k}{N}} \ \text{DFT}(\text{odd}(\text{odd}(x_n)), k, N/4) \right) \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where we realize with &lt;em&gt;a sudden burst of clarity&lt;/em&gt; that for every recursive DFT split, we only have to compute the first half of the frequencies, as the second half can be reconstructed from the already computed values in the first half.&lt;/p&gt;

&lt;!-- I find it especially nice to observe that for every subsampling/splitting into even and odd terms we effectively half the sampling frequency.
While we nominally compute the frequency bin $k$, by doing steps, we reduce the frequency by a factor of two.
But we observe that for each split into an even lower sampling frequency ( like from $N/2$ to $N/4$ in the second application of the DFT), we multiply the split terms by what was originally called the 'twiddle' factor $\exp(-i2 \pi k/N)$.
As we half the sampling resolution by taking every second entry, we have to keep multiplying these complex exponentials, which double the frequency, thus correcting for the reduced sampling frequency.

For the example above, we have $\exp(-i 2\pi k/N) \cdot \exp(-i 2\pi k/N) = \exp(-i2 \pi \ 2 k/N)$ after the second application of the  ra --&gt;

&lt;h3 id=&quot;a-linear-algebraic-approach&quot;&gt;A (Linear) Algebraic Approach&lt;/h3&gt;

&lt;p&gt;Things are always better when visualized and fortunately we can write out the DFT as a matrix-vector multiplication.
For this efficient algorithn, we require that the length $N$ is a root of 2, such that we can repeatedly divide the length $N$ by two until we arrive at a DFT length of one.&lt;/p&gt;

&lt;p&gt;First we will define the $n$â€™th root of unity as
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
w_N = e^{-\frac{i 2 \pi}{N}} \qquad w_N^{n \cdot k} = e^{-i 2 \pi \ k \ \frac{n}{N}}
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can now construct the full $K \times N$ matrix where each row of the matrix corresponds to a particular frequency $k$ and where naturally $K=N$.
For a signal of length $N=8$ this gives us&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{matrix}
0 \leq k \leq N/2: \\ \\ \\ \\ N/2 \leq k \leq N: \\
\end{matrix} \begin{bmatrix}
w^0 &amp; w^0 &amp; w^0 &amp; w^0 &amp; w^0 &amp; w^0 &amp; w^0 &amp; w^0\\
w^0 &amp; w^1 &amp; w^2 &amp; w^3 &amp; w^4 &amp; w^5 &amp; w^6 &amp; w^7 \\
w^0 &amp; w^2 &amp; w^4 &amp; w^6 &amp; w^8 &amp; w^{10} &amp; w^{12} &amp; w^{14} \\
w^0 &amp; w^3 &amp; w^6 &amp; w^9 &amp; w^{12} &amp; w^{15} &amp; w^{18} &amp; w^{21} \\
\hline
w^0 &amp; w^4 &amp; w^8 &amp; w^{12} &amp; w^{16} &amp; w^{20} &amp; w^{24} &amp; w^{28} \\
w^0 &amp; w^5 &amp; w^{10} &amp; w^{15} &amp; w^{20} &amp; w^{25} &amp; w^{30} &amp; w^{35} \\
w^0 &amp; w^6 &amp; w^{12} &amp; w^{18} &amp; w^{24} &amp; w^{30} &amp; w^{36} &amp; w^{42} \\
w^0 &amp; w^7 &amp; w^{14} &amp; w^{21} &amp; w^{28} &amp; w^{35} &amp; w^{42} &amp; w^{49} \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;We use this matrix as a projection for our signal $x_n$ to obtain the frequency bins.
Doing this naively would cost us exactly $8 \times 8 = 64$ operations&lt;/p&gt;

&lt;p&gt;But what do know about the roots of unity that we can exploit?
While it may appear that the roots of unity are just increasing haphazardly, there are many duplicates &lt;em&gt;as the complex exponentials are circular&lt;/em&gt;.
This means that for example $w_8^2=w_8^{10}$ as with a length of $N=8$, $w_8^{10}$ does a full circle back to $w_8^2$ (it requires â€˜8 stepsâ€™ to do a full circle and has â€˜2 stepsâ€™ left to end up where $w^2$ is already, so the modulo operator respectively the periodic property of the complex exponential).
Similarly $w_8^4=w_8^{12}$.&lt;/p&gt;

&lt;p&gt;Additionally, our astute obeservation of earlier tells that we donâ€™t need to compute the second half of the matrix, but can instead reconstruct it from the results in the upper half.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{matrix} 0 \leq k \leq N/2: \\ \\ \\ \\ N/2 \leq k \leq N: \\ \end{matrix} 
\begin{bmatrix}
w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0\\
w_8^0 &amp; w_8^1 &amp; w_8^2 &amp; w_8^3 &amp; w_8^4 &amp; w_8^5 &amp; w_8^6 &amp; w_8^7 \\
w_8^0 &amp; w_8^2 &amp; w_8^4 &amp; w_8^6 &amp; w_8^8 &amp; w_8^{10} &amp; w_8^{12} &amp; w_8^{14} \\
w_8^0 &amp; w_8^3 &amp; w_8^6 &amp; w_8^9 &amp; w_8^{12} &amp; w_8^{15} &amp; w_8^{18} &amp; w_8^{21} \\
\hline
w_8^0 &amp; w_8^4 &amp; w_8^8 &amp; w_8^{12} &amp; w_8^{16} &amp; w_8^{20} &amp; w_8^{24} &amp; w_8^{28} \\
w_8^0 &amp; w_8^5 &amp; w_8^{10} &amp; w_8^{15} &amp; w_8^{20} &amp; w_8^{25} &amp; w_8^{30} &amp; w_8^{35} \\
w_8^0 &amp; w_8^6 &amp; w_8^{12} &amp; w_8^{18} &amp; w_8^{24} &amp; w_8^{30} &amp; w_8^{36} &amp; w_8^{42} \\
w_8^0 &amp; w_8^7 &amp; w_8^{14} &amp; w_8^{21} &amp; w_8^{28} &amp; w_8^{35} &amp; w_8^{42} &amp; w_8^{49} \\
\end{bmatrix} \\
\\
\qquad \qquad \qquad \Big \downarrow \\
\\
\begin{matrix}
0 \leq k \leq N/2: \\
\\
\\
\\
N/2 \leq k \leq N: \\
\end{matrix} \left[ 
\begin{array}{cccccccc}
w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0\\
w_8^0 &amp; w_8^1 &amp; w_8^2 &amp; w_8^3 &amp; w_8^4 &amp; w_8^5 &amp; w_8^6 &amp; w_8^7 \\
w_8^0 &amp; w_8^2 &amp; w_8^4 &amp; w_8^6 &amp; w_8^8 &amp; w_8^{10} &amp; w_8^{12} &amp; w_8^{14} \\
w_8^0 &amp; w_8^3 &amp; w_8^6 &amp; w_8^9 &amp; w_8^{12} &amp; w_8^{15} &amp; w_8^{18} &amp; w_8^{21} \\
\hline
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
\end{array} \right] %]]&gt;&lt;/script&gt;

&lt;p&gt;The next step is to split the matrices into even and odd entries of $x_n$,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\left[ \begin{array}{cccc cccc}
w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0\\
w_8^0 &amp; w_8^1 &amp; w_8^2 &amp; w_8^3 &amp; w_8^4 &amp; w_8^5 &amp; w_8^6 &amp; w_8^7 \\
w_8^0 &amp; w_8^2 &amp; w_8^4 &amp; w_8^6 &amp; w_8^8 &amp; w_8^{10} &amp; w_8^{12} &amp; w_8^{14} \\
w_8^0 &amp; w_8^3 &amp; w_8^6 &amp; w_8^9 &amp; w_8^{12} &amp; w_8^{15} &amp; w_8^{18} &amp; w_8^{21} \\
\hline
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
\end{array} \right] \\
\qquad \Big \downarrow \quad \text{Split}\\
\begin{matrix}
\underbrace{\begin{bmatrix}
w_8^0 &amp; - &amp; w_8^0 &amp; - &amp; w_8^0 &amp; - &amp; w_8^0 &amp; - \\
w_8^0 &amp; - &amp; w_8^2 &amp; - &amp; w_8^4 &amp; - &amp; w_8^6 &amp; - \\
w_8^0 &amp; - &amp; w_8^4 &amp; - &amp; w_8^8 &amp; - &amp; w_8^{12} &amp; - \\
w_8^0 &amp; - &amp; w_8^6 &amp; - &amp; w_8^{12} &amp; - &amp; w_8^{18} &amp; - \\
\hline
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
\end{bmatrix}
}_{\text{even entries of $x_n$}} 
&amp;, 
\underbrace{ 
\begin{bmatrix}
- &amp; w_8^0 &amp; - &amp; w_8^0 &amp; - &amp; w_8^0 &amp; - &amp; w_8^0\\
- &amp; w_8^1 &amp; - &amp; w_8^3 &amp; - &amp; w_8^5 &amp; - &amp; w_8^7 \\
- &amp; w_8^2 &amp; - &amp; w_8^6 &amp; - &amp; w_8^{10} &amp; - &amp; w_8^{14} \\
- &amp; w_8^3 &amp; - &amp; w_8^9 &amp; - &amp; w_8^{15} &amp; - &amp; w_8^{21} \\
\hline
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
- &amp; - &amp; - &amp; - &amp; - &amp; - &amp; -  &amp; - \\
\end{bmatrix}
}_{\text{odd entries of $x_n$}} \\
\big \downarrow &amp; \qquad \qquad \qquad \big \downarrow \text{Extract} \ e^{-i2\pi \frac{k}{N}} \\
\begin{bmatrix}
w_8^0&amp; w_8^0 &amp; w_8^0 &amp; w_8^0\\
w_8^0&amp; w_8^2 &amp; w_8^4 &amp; w_8^6 \\
w_8^0&amp; w_8^4 &amp; w_8^{8} &amp; w_8^{12} \\
w_8^0&amp; w_8^6 &amp; w_8^{12} &amp; w_8^{18} \\
\end{bmatrix}
&amp; 
\begin{bmatrix}
w_8^0 &amp;     &amp;     &amp; \\
    &amp; w_8^1 &amp;     &amp; \\
    &amp;     &amp; w_8^2 &amp; \\
    &amp;     &amp;     &amp; w_8^3 \\
\end{bmatrix}
\begin{bmatrix}
w_8^0 &amp; w_8^0 &amp; w_8^0 &amp; w_8^0\\
w_8^0 &amp; w_8^2 &amp; w_8^4 &amp; w_8^6 \\
w_8^0 &amp; w_8^4 &amp; w_8^{8} &amp; w_8^{12} \\
w_8^0 &amp; w_8^6 &amp; w_8^{12} &amp; w_8^{18} \\
\end{bmatrix} \\
\qquad \big \downarrow \text{DIT} &amp; \qquad \big \downarrow \text{DIT} \\
\begin{bmatrix}
w_4^0 &amp; w_4^0 &amp; w_4^0 &amp; w_4^0\\
w_4^0 &amp; w_4^1 &amp; w_4^2 &amp; w_4^3 \\
w_4^0 &amp; w_4^2 &amp; w_4^{4} &amp; w_4^{6} \\
w_4^0 &amp; w_4^3 &amp; w_4^6 &amp; w_4^{9} \\
\end{bmatrix}
&amp; \begin{bmatrix}
w_8^0 &amp;     &amp;     &amp; \\
    &amp; w_8^1 &amp;     &amp; \\
    &amp;     &amp; w_8^2 &amp; \\
    &amp;     &amp;     &amp; w_8^3 \\
\end{bmatrix}
\begin{bmatrix}
w_4^0 &amp; w_4^0 &amp; w_4^0 &amp; w_4^0\\
w_4^0 &amp; w_4^1 &amp; w_4^2 &amp; w_4^3 \\
w_4^0 &amp; w_4^2 &amp; w_4^{4} &amp; w_4^{6} \\
w_4^0 &amp; w_4^3 &amp; w_4^6 &amp; w_4^{9} \\
\end{bmatrix} \\
\end{matrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;where the DIT stands for â€˜Decimation in Timeâ€™ where we flip the $2$ in the complex exponential $\frac{2m}{N}$ down to $\frac{m}{N/2}$ which halves both the nominator and denominator, i.e.
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
w_8^6 = e^{-i2\pi \ k \ \frac{2m}{N}} |_{m=1, k=3, N=8} = e^{-i2\pi \ k \ \frac{m}{N/2}} |_{m=1, k=3, N=8} = w_4^3 
\end{align}&lt;/script&gt;
Besides being mathematically correct, it makes intuitively sense, as doing $6$ steps with $1/8$â€™th of a stepsize is the same as doing $3$ steps with $1/4$â€™th of a step size on a circle.&lt;/p&gt;

&lt;p&gt;So we obtain two DFTâ€™s of shape $4 \times 4$,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
X_0 \\ X_1 \\ X_2 \\ X_3 \\
\end{bmatrix} 
=
\begin{bmatrix}
w_4^0 &amp; w_4^0 &amp; w_4^0 &amp; w_4^0\\
w_4^0 &amp; w_4^1 &amp; w_4^2 &amp; w_4^3 \\
w_4^0 &amp; w_4^2 &amp; w_4^{4} &amp; w_4^{6} \\
w_4^0 &amp; w_4^3 &amp; w_4^6 &amp; w_4^{9} \\
\end{bmatrix}
\begin{bmatrix}
x_0 \\ x_2 \\ x_4 \\ x_6 \\
\end{bmatrix}
+ 
\underbrace{
\begin{bmatrix}
w_8^0 &amp;     &amp;     &amp; \\
    &amp; w_8^1 &amp;     &amp; \\
    &amp;     &amp; w_8^2 &amp; \\
    &amp;     &amp;     &amp; w_8^3 \\
\end{bmatrix}}_{e^{-i 2 \pi \frac{k}{N}}}
\begin{bmatrix}
w_4^0 &amp; w_4^0 &amp; w_4^0 &amp; w_4^0\\
w_4^0 &amp; w_4^1 &amp; w_4^2 &amp; w_4^3 \\
w_4^0 &amp; w_4^2 &amp; w_4^{4} &amp; w_4^{6} \\
w_4^0 &amp; w_4^3 &amp; w_4^6 &amp; w_4^{9} \\
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_3 \\ x_5 \\ x_7 \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;The magic periodicity reuses the computations in the first half of the DFT to give the second half $X_{k+N/2}$ frequency bins with minimal overhead:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\left[ \begin{array}{} X_4 \\ X_5 \\ X_6 \\ X_7 \\ \end{array} \right] =
\underbrace{
\begin{bmatrix}
w_4^0 &amp; w_4^0 &amp; w_4^0 &amp; w_4^0\\
w_4^0 &amp; w_4^1 &amp; w_4^2 &amp; w_4^3 \\
w_4^0 &amp; w_4^2 &amp; w_4^{4} &amp; w_4^{6} \\
w_4^0 &amp; w_4^3 &amp; w_4^6 &amp; w_4^{9} \\
\end{bmatrix}
\begin{bmatrix}
x_0 \\ x_2 \\ x_4 \\ x_6 \\
\end{bmatrix}
}_{\text{already computed above}}
-
\underbrace{
\begin{bmatrix}
w_8^4 &amp;     &amp;     &amp; \\
    &amp; w_8^5 &amp;     &amp; \\
    &amp;     &amp; w_8^6 &amp; \\
    &amp;     &amp;     &amp; w_8^7 \\
\end{bmatrix}}_{e^{-i 2 \pi \frac{k}{N}}}
\underbrace{
\begin{bmatrix}
w_4^0 &amp; w_4^0 &amp; w_4^0 &amp; w_4^0\\
w_4^0 &amp; w_4^1 &amp; w_4^2 &amp; w_4^3 \\
w_4^0 &amp; w_4^2 &amp; w_4^{4} &amp; w_4^{6} \\
w_4^0 &amp; w_4^3 &amp; w_4^6 &amp; w_4^{9} \\
\end{bmatrix}
\begin{bmatrix}
x_1 \\ x_3 \\ x_5 \\ x_7 \\
\end{bmatrix}
}_{\text{already been computed}} %]]&gt;&lt;/script&gt;

&lt;p&gt;Not using the structure of the matrix respectively the complex periodicity would have left us with a $ 8 \times 8 = 64$ matrix multiplication.
Using the tricks laid out above costs us two $4 \times 4$ matrix multplications, two $4$ additions and two $4$ multiplications for a grand total of $2 \cdot (4 \times 4) + 2 \cdot 4 + 2 \cdot 4 = 48$ operations&lt;/p&gt;

&lt;p&gt;Upon closer inspection of the first matrix being multiplied with $[ x_0, x_2, x_4, x_6]$ we can notice that matrix exhibits the same properties and structure as the original DFT matrix.
This is were the recursion kicks in in the linear algebra formulation.&lt;/p&gt;

&lt;p&gt;For that to happen, we take the even of the evens, $[x_0, x_4]$ and the odds of the even $[x_2, x_6]$ and split them as before:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\text{DFT}
\left( \left[
\begin{array}{}
x_0 \\ x_2 \\ x_4 \\ x_6 \\
\end{array}
\right]
\right)
=
\left[
  \begin{array}{}
X_0 \\ X_1 \\ X_2 \\ X_3 \\
\end{array}
\right]
= 
\underbrace{
\begin{bmatrix}
w_4^0 &amp; w_4^0 &amp; w_4^0 &amp; w_4^0\\
w_4^0 &amp; w_4^1 &amp; w_4^2 &amp; w_4^3 \\
w_4^0 &amp; w_4^2 &amp; w_4^{4} &amp; w_4^{6} \\
w_4^0 &amp; w_4^3 &amp; w_4^6 &amp; w_4^{9} \\
\end{bmatrix}
}_{\text{yet again a DFT matrix}}
\begin{bmatrix}
x_0 \\ x_2 \\ x_4 \\ x_6 \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;Again using the key insight that we can reconstruct the second half of the DFT bins from the first half, we can zero out a lot of computations to essentially break down the original DFT from a $4 \times 4$ to two $2 \times 2$ matrix multiplications:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
X_0 \\ X_1 \\ - \\ - \\
\end{bmatrix}
=
\begin{bmatrix}
w_4^0 &amp; - &amp; w_4^0 &amp; - \\
w_4^0 &amp; - &amp; w_4^2 &amp; - \\
- &amp; - &amp; - &amp; -  \\
- &amp; - &amp; - &amp; -  \\
\end{bmatrix}
\begin{bmatrix}
x_0 \\ - \\ x_4 \\ - \\
\end{bmatrix}
+ 
\begin{bmatrix}
w_4^0 &amp;     &amp;     &amp; \\
    &amp; w_4^1 &amp;     &amp; \\
    &amp;     &amp; - &amp; \\
    &amp;     &amp;     &amp; - \\
\end{bmatrix}
\begin{bmatrix}
- &amp; w_4^0 &amp; - &amp; w_4^0\\
- &amp; w_4^0 &amp; - &amp; w_4^2 \\
- &amp; - &amp; - &amp; -  \\
- &amp; - &amp; - &amp; -  \\
\end{bmatrix}
\begin{bmatrix}
- \\ x_2 \\ - \\ x_6 \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;and we can reconfigure the already computed $2 \times 2$ matrices to get the second half of the frequency bins&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
X_3 \\ X_4 \\
\end{bmatrix}
=
\underbrace{
\begin{bmatrix}
w_2^0 &amp; w_2^0 \\
w_2^0 &amp; w_2^1 \\
\end{bmatrix}
\begin{bmatrix}
x_0 \\ x_4 \\
\end{bmatrix}
}_{\text{already computed}} 
- 
\begin{bmatrix}
w_4^2 &amp;     \\
    &amp; w_4^3 \\
\end{bmatrix}
\begin{bmatrix}
w_2^0 &amp; w_2^0\\
w_2^0 &amp; w_2^1 \\
\end{bmatrix}
\begin{bmatrix}
x_2 \\ x_6 \\
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;And we can do it yet again by observing that the $2 \times 2$ matrix can be broken up again once more (but at size 1 the recursion naturally stops).
Similarly this recursion applies equally to the original odd entry terms in the upper most recursion layer.&lt;/p&gt;

&lt;p&gt;This recursive breaking up matrices and saving half the computations (via reconstruction of the second half of the frequency bins) gives the FFT itâ€™s highly useful $O(N \log N)$ complexity.&lt;/p&gt;

&lt;p&gt;The efficiency stems from us retracing the recursive matrix break ups with our results once we arrived at the DFT with length of one.
Each evaluation in the recursion allows us to reconstruct frequency bins twice our original size (thanks to periodicity) with minimal overhead, which goes from $1 \rightarrow 2 \rightarrow 4 \rightarrow 8$.
So for signals of length $8$, we need 4 recursive step to arrive at a DFT length of one, from which we can reconstruct the frequency bins efficiently.
For a signal of length $16$ we need 5 recursions, for $32$ just one more, namely 6 recursions, and for $64$ just seven recursions.
While the speed up might be small for short signals, audio people with 20.000 samplings steps should seriously rejoice and feel blessed by the $O(N \log N)$ complexity.&lt;/p&gt;

&lt;h3 id=&quot;the-inverse-dft&quot;&gt;The inverse DFT&lt;/h3&gt;

&lt;p&gt;In order to reconstruct a signal from its Fourier coefficients $X_k$, we multiply the frequency amplitude $X_k$ with a complex exponential which is a periodic function with a specific frequency $k$.
We have the reconstruction
&lt;script type=&quot;math/tex&quot;&gt;x_n = \frac{1}{N} \sum_{k=0}^K X_k e^{i 2\pi k \frac{n}{N}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where the only difference to the DFT is the minus sign in the exponential and a scaling factor $1/N$.
The cool thing is that the minus sign has no influence on the core structure of the transformation, so we can employ the entire algorithm again for the reconstruction from frequency to time domain.&lt;/p&gt;

&lt;p&gt;Thus we have a $O(N \log N)$ algorithm both for the transformation in both directions. Sweet â€¦&lt;/p&gt;</content><author><name></name></author><summary type="html">From Complex Exponentials to Frequencies in O(N log N)</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/blog/blogthumbnails/FFT.png" /></entry><entry><title type="html">Continuous Time Markov Chains in Jax</title><link href="http://localhost:4000/blog/ContTimeMarkovChain/" rel="alternate" type="text/html" title="Continuous Time Markov Chains in Jax" /><published>2023-01-09T00:00:00+01:00</published><updated>2023-01-09T00:00:00+01:00</updated><id>http://localhost:4000/blog/ContTimeMarkovChain</id><content type="html" xml:base="http://localhost:4000/blog/ContTimeMarkovChain/">&lt;head&gt;
&lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: &quot;all&quot; } } }); &lt;/script&gt;
       &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
         MathJax.Hub.Config({
           tex2jax: {
             inlineMath: [ ['$','$'], [&quot;\\(&quot;,&quot;\\)&quot;] ],
             displayMath: [['$$','$$']],
             processEscapes: true
           }
         });
       &lt;/script&gt;
       &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\def\tr#1{\text{Tr}\left[ #1 \right]}
 \def\Efunc#1{\mathbb{E}\left[ #1\right]}
 \def\Efuncc#1#2{\mathbb{E}_{#1}\left[ #2 \right]}&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;continuous-time-markov-chains&quot;&gt;Continuous Time Markov Chains&lt;/h3&gt;

&lt;p&gt;A continuous-time Markov chain (CTMC) is a mathematical model that describes the evolution of a system over time, where the state of the system changes according to a set of probabilities at each point in time. 
Like a discrete-time Markov chain, a CTMC consists of a set of states and a set of transitions between those states. 
However, in a CTMC, the transitions between states can occur at any point in time, rather than only at discrete time steps.&lt;/p&gt;

&lt;p&gt;A CTMC is defined by its generator matrix, which describes the rate at which the system transitions between states. 
The elements of the generator matrix are typically denoted by $Q_{ij}$, where $Q_{ij}$ is the rate at which the system transitions from state $i$ to state $j$.
These rates denote the intensity $\lambda$ of exponentially distributed random variables.
The diagonal elements $Q_{ii}$ denote the rate with which we will stay in state $i$, whereas $Q_{ij}, i \neq j$ denotes the rate of changing from state $i$ to $j$.
Whereas discrete time markov chains have transition probabilities in form of the matrix $P_{ij}$ for discrete time steps, CTMC are a bit more involved by changing continuously in time $t$ and change states according to $P(t)$.&lt;/p&gt;

&lt;p&gt;But how are the rates $Q_{ij}$ and the transition matrix $P_{ij}(t)$ connected?
The â€˜generatorâ€™ in generator matrix $Q$ comes from $Q$â€™s property of containing the instantaneous rate of change for an infinitesimally small change in time.
The rate describes the instantaneous propensity or affinity for the process to transition between its states.
If we know how the instantaneous behaviour of the stochastic process is, we can â€˜generateâ€™ entire trajectories of it.&lt;/p&gt;

&lt;p&gt;Each entry $P_ij(t)$ denotes the probability of transitioning from state $i$ to state $j$ dependent on the time $t$ that has passed.
This ergodicity is due to the Markov property that treats each transition independently from all previous.
For $t=0$ we get $P(0)=I$ as we will surely stay in the same state $i$ since no time has passed.
If no time has passed, we concurrently didnâ€™t have time to transition.&lt;/p&gt;

&lt;p&gt;Thus $Q$ and $P(t)$ are connected via
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
  Q = \lim_{t \rightarrow 0^+} \frac{P(t)- I}{t} = \lim_{t \rightarrow 0^+} \frac{P(t)- P(0)}{t}.
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Each row of $P(t)$ has to sum up to 1, namely $\sum_j P_{ij}(t) = 1$. 
Another intriguing property of the generator matrix $Q$ is that the diagonal terms are negative.
To see why we can construct a simple example by looking at the first row $i=1$ after one unit of time has passed, $P_{i=1}(t=1) = [0.8, 0.1, 0.1]$.
Plugging it into the limit (albeit be it with $t=1$), we get 
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
  Q = P(1) - I = [0.8, 0.1, 0.1] - [1, 0, 0] = [-0.2, 0.1, 0.1].
\end{align}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Taking this to the limit of $\lim t \rightarrow 0^+$ and seeing that the identity matrix only subtracts from the diagonal elements, we can conclude that the diagonal elements $Q_{ii}$ are in effect negative and the negative sum of the off-diagonal terms in each row, $Q_{ii} = - \sum_{i \neq j} Q_{ij}$.
We can thus interpret the absolute value of the diagonal terms $Q_{ii}$ as the rate of staying in the state $i$, whereas all other rates determine the rate of changing to a different state $j$.&lt;/p&gt;

&lt;p&gt;Computing the limit $\lim t \rightarrow 0^+$ gives us the rates of the exponentially distributed holding times in each state.
The exponential distribution models the time between events in a Poisson point process, explained on the blog &lt;a href=&quot;https://ludwigwinkler.github.io/blog/Poisson/&quot;&gt;here&lt;/a&gt;.
Thus given a rate $\lambda$ which is given by the elements in the matrix $Q$, we have multiple competing exponentially distributed random variables.
The question now arises what transition will occur first.&lt;/p&gt;

&lt;p&gt;Conveniently, we can ask a different question and split the problem into two subproblems, namely â€˜How long will we stay in $i$?â€™ and â€˜Once we exit state $i$, where do we go?â€™.&lt;/p&gt;

&lt;p&gt;The first question can be answered by observing what the probability is, that &lt;em&gt;any&lt;/em&gt; process activates.
Any means here simply the minimum that any process changes, namely $\min{X_1, X_2, X_3}$.
Each off-diagonal entry $\lambda_j$ denotes the rate of an independent exponentially distributed random variable $\tau_j \sim \text{Exp}[\lambda_j]$.
Thus we are interested in the probability of how the minimum of all holding times $\tau_j$ is distributed vis-a-vis being larger than some aggregated holding time $t$.
For that we can employ the complementary cumulative density function (cCDF = 1-CDF so not standard CDF $p(\tau_i &amp;lt; t)$ but $p(\tau_i &amp;gt; t)$ lying outside of $t$) of the exponential distribution and ask whether $p(\tau_i &amp;gt; t)$:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(\min \{ \tau_1, \tau_2, \tau_3 \} &gt; t) &amp;= p(\tau_1 &gt; t, \tau_2 &gt; t, \tau_3 &gt; t) \\
  &amp;= \prod_{i=1}^3 p(\tau_i &gt; x) \\
  &amp;= \prod_{i=1}^3 \overbrace{1 - \underbrace{(1 - \exp[-\lambda_i x])}_{\text{Exp CDF}}}^{\text{Exp cCDF}} \\
  &amp;= \prod_{i=1}^3 \exp[-\lambda_i x] \\
  &amp;=  \exp \left[- \sum_{i=1}^3 \lambda_i x \right]
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Thus the minimum holding time is again an exponential distribution with the rate $\sum_i \lambda_i$.
Once the holding time is â€˜exhaustedâ€™ or has passed, we have to determine the second question, namely which process is going to occur next.
Therefore we want to know the probability
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(i = \text{argmin}_i \{ \tau_1, \tau_2, \tau_3 \}) &amp;= \int_0^\infty p(\tau_i = t) \ p(\forall_{k \neq i} \tau_k &gt; t) dt \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;which states that our $i$ in question is precisely the holding time $t$ and factorizing via conditional independence that every other exponentially distributed holding time $\tau_k$ is larger than $t$ which is again the cCDF.
Finally we marginalize over $t$ to incorporate the fact the holding time $t$ is itself a random variable which ought to be marginalized out, effectively taking into account every possible value of $t$.
We obtain
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
  p(i = \text{argmin}_i \{ \tau_1, \tau_2, \tau_3 \}) 
  &amp;= \int_0^\infty p(\tau_i = t) \ p(\forall_{k \neq i} \tau_k &gt; t) dt \\
  &amp;= \int_0^\infty \underbrace{p(\tau_i = t)}_{\text{Exp}} \ \underbrace{p(\forall_{k \neq i} \tau_k &gt; t)}_{\text{cCDF}} dt \\
  &amp;= \int_0^\infty \lambda_i \exp[-\lambda_i t] \ \prod_{k \neq i} \exp[- \lambda_k t] dt \\
  &amp;= \int_0^\infty \lambda_i  \ \prod_{k} \exp[- \lambda_k t] dt \\
  &amp;= \lambda_i \int_0^\infty  \ \exp \left[- \sum_{k} \lambda_k t \right] dt \\
  &amp;= \lambda_i  \left[ - \frac{\exp \left[- \sum_{k} \lambda_k t \right]}{\sum_{k} \lambda_k} \right]_0^\infty \\
  &amp;= \lambda_i  \left(  0 + \frac{1}{\sum_{k} \lambda_k} \right) \\
  &amp;= \frac{\lambda_i}{\sum_{k} \lambda_k} \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Thus we can conclude that the process that â€˜acts firstâ€™ is $i \sim \text{Cat}[\lambda_1, \lambda_2, \lambda_3]$.
We can thus devise a sampling algorithm based on rates $\lambda_i$ which first samples holding time $t \sim \text{Exp}[\sum_i \lambda_i]$ and after the holding time samples the next state as $i \sim \text{Cat}[\lambda_i]$.&lt;/p&gt;

&lt;h3 id=&quot;birth-death-process&quot;&gt;Birth-Death Process&lt;/h3&gt;

&lt;p&gt;A birth-death process is a stochastic process $\{X_t\}_{t \in \mathbb{R}^+}$ with $X_t = X_t^\lambda - X_t^\mu$ with two â€˜duellingâ€™ rates: the birth rate $\lambda$ and the death rate $\mu$.
Both rates induce a counting process (albeit be it with opposite signs) such that the infinitissimal generators are
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\lim_{h \rightarrow 0^+} P(X_{t+h} = X_t + 1 | X_t) &amp;= \lambda h \\
\lim_{h \rightarrow 0^+} P(X_{t+h} = X_t - 1 | X_t) &amp; = \mu h \\
\lim_{h \rightarrow 0^+} P(X_{t+h} = X_t + 0| X_t) &amp; = 1- (\lambda + \mu) h
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;the derivation of which can be followed up &lt;a href=&quot;https://ludwigwinkler.github.io/blog/Poisson/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We can thus construct a straight forward sampling algorithm by sampling the holding time $\tau$ in state $X_{t+\tau} = X_t$ with $\tau \sim \text{Exp}[ \lambda + \mu]$ and once the holding time is over, sampling either the death or the birth process with ${+1, -1} \sim \text{Cat}[\lambda, \mu]$.&lt;/p&gt;

&lt;p&gt;Sampling from the exponential distribution can be easily done with inverse transform sampling by first sampling $u \sim U[0,1]$ and using 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
u &amp;= \text{ExpCDF}(x, \lambda) \\
u &amp;= 1 - \exp[-\lambda x] \\
\underbrace{1 - u}_{=u'} &amp;= \exp[-\lambda x] \\
\log u' &amp;= -\lambda x \\
-\frac{1}{\lambda} \log u' &amp;= x \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where we used the fact that $uâ€™ = 1 - u \sim U[0,1]$ is again a uniformly distributed random variable.&lt;/p&gt;

&lt;h3 id=&quot;jax&quot;&gt;Jax&lt;/h3&gt;

&lt;p&gt;If you havenâ€™t been living under a proverbial analog rock in the digital machine learning space, you might have heard of &lt;a href=&quot;https://github.com/google/jax&quot;&gt;Jax&lt;/a&gt;.
At the core of Jax are four function transforms with three to four letters: &lt;code class=&quot;highlighter-rouge&quot;&gt;grad&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;jit&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;pmap&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;grad&lt;/code&gt; traces a function when itâ€™s called the first time and transforms that function by replacing the operations in the function with its derivatives with respect to the input&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;jit&lt;/code&gt; adds a just-in-time compilation function transform which aims at compiling an optimized version of your given function.
Python is an interpreted language which does executes every instruction without anticipating the future.
After having traced through a &lt;code class=&quot;highlighter-rouge&quot;&gt;jit&lt;/code&gt; marked function for the first time, Jax will know what the whole execution of the function will entail.
Since it knows all the operations, it will upon finishing the first evaluation of the function start compiling it fusing operations and removing unneeded data copying for example (this is a very broad example).
Obviously this entails some programming restrictions which can be read up in the &lt;a href=&quot;https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html&quot;&gt;Jax - The Sharp Bits&lt;/a&gt;.
You have to essentially live with a few restrictions and in order to ensure deterministic function evaluations the random key has to passed to stochastic functions, rendering the deterministic given the random number generator key.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; is in my opinion the true power move of Jax by allowing to replicate the same function over an extra dimension.
You can write a possibly very complicated function for a single data point and simply vmap over to enable it to evaluate the function over batches of data points in parallel.
No more extra dimensions, no more custom forward passes changing every matrix-vector to a matrix-matrix operation etc.
Just vmap it.
Weâ€™ll see down below how powerful &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; can be.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pmap&lt;/code&gt; does automatic accelerator placement by automatically optimizing the given function over all sorts of TPUâ€™s and GPUâ€™s.
It is akin to PyTorchâ€™s tensor.to(device) by compiles the entire function custom made for each accelerator on you compute node.
Powerful stuff right there.&lt;/p&gt;

&lt;h3 id=&quot;continuous-time-markov-chains-in-jax&quot;&gt;Continuous Time Markov Chains in Jax&lt;/h3&gt;

&lt;p&gt;The setup is going to be the following:
We are going to have a single birth death process with three dimensions.
Each dimension has its own birth rate $\lambda_i$ and death rate $\mu_i$.
Since itâ€™s a Markov chain, we can treat each holding time $t$ independently from all previous holding times.
This allows us to construct the following algorithm to sample the multi-dimensional birth death process:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Sample holding time $t \sim \text{Exp}(\sum_k \lambda_k + \mu_k)$&lt;/li&gt;
  &lt;li&gt;Once $t$ has passed, sample active process $i \sim \text{Cat}( \lambda_1 + \mu_1, â€¦ , \lambda_d + \mu_d)$&lt;/li&gt;
  &lt;li&gt;From â€˜activeâ€™ process $i$ sample the increment $\Delta X_t \sim \text{Cat}(\lambda_i, \mu_i)$ with $\Delta X_t \in \{ +1, -1 \}$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In practice, we could combine step 2 and step 3 into a single categorical distribution but this is fiddly and splitting it into two sampling looks cleaner. 
Just-in-time compilation should in theory remove an inefficiencies anyway.
Up first on our to do list is to be able to sample from an exponential distribution.
This can be achieved readily with the reparameterization trick for the exponential distribution describes earlier,&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import jax

la = jnp.array([3., 4., 0.5]).reshape(-1, 1) # birth rates, lambda is already reserved by Python for anonymous functions
mu = jnp.array([2., 3., 4.]).reshape(-1, 1) # death rate
key = jax.random.PRNGKey(1) #

def sample_exponential(lam, key):
  '''Reparameterization for exponential distribution```
	return - 1 / lam * jnp.log(jax.random.uniform(key))

@jax.jit
def batched_sample_exponential(lam, key):
	'''first argument has to be inner most vmap over anonymous lambda function'''
	return jax.vmap(lambda key: jax.vmap(lambda la: sample_exponential(la, key))(la))(key).squeeze(-1)

n=1_000
key, *subkey = jax.random.split(key,n+1)
subkey = jnp.stack(subkey)
samples = batched_sample_exponential(la, subkey)

fig = plt.figure(figsize=(20,10))
for samples_, la_ in zip(samples.T, la):
	_ = plt.hist(samples_, bins=50, density=True, alpha=0.5, label=f'{la_}')
_ = plt.xlim(-1,3)
plt.legend()
plt.show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which should return some exponential distributions looking like this&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../blog/CTMC/exponential.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Next up is to get acquainted to sampling processes given&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;key = jax.random.PRNGKey(1)
la = jnp.array([0.1, 1.5, 2.]).reshape(-1,1)
mu = jnp.array([0.1, 1.5, 2.]).reshape(-1,1) - 0.01 * la # slightly smaller death rate

weights = jnp.concatenate([la, mu], axis=0) # concat them to one long vector

key, *subkey = jax.random.split(key, 10000)
subkey = jnp.stack(subkey)
active_process = jax.vmap(lambda key: jax.random.choice(key, a=jnp.size(weights), p=weights.squeeze()))(subkey)

_ = plt.hist(active_process, bins=jnp.size(weights), density=True)
_ = plt.xticks(jnp.arange(jnp.size(weights)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;from which we get the following plot where the first three bins are the probability of sampling the birth process and the last three bins the probability of sampling the death process.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../blog/CTMC/activprocess.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can now implement our first CTMC sampling algorithm by packing the sampling into a while loop:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import jax.numpy as jnp
la = jnp.array([0.1, 1, 2.]).reshape(-1,1)
mu = jnp.array([0.1, 1, 2.]).reshape(-1,1) - 0.1 * la # slightly smaller da

def sample_process( la, mu, T, key):

	num_processes = jnp.size(la) # 3 processes since we have three birth rates Î»
	concat_weights = jnp.concatenate([la, mu], axis=0) # [la_1, la_2, la_3, mu_1, mu_2, mu_3]

	traj = jnp.zeros((1,jnp.size(la),)) # [step=1, F=3]
	t = jnp.zeros((1,)) # [step=1]

	key = jax.random.PRNGKey(2)
	active_process_idxs = [] # collecting active process samplings

	while t[-1]&amp;lt; T:
		key, process_key, time_key = jax.random.split(key, 3)
		''' sampling process index from [la_1, la_2, la_3, mu_1, mu_2, mu_3]'''
		active_process = jax.random.choice(process_key, a=jnp.size(concat_weights), p=concat_weights.squeeze())
		active_process_idxs += [active_process]
		
		if active_process &amp;lt; num_processes: # [0, num_processes -1]
			# birth process
			rate = la[active_process]
			state_change = jax.nn.one_hot(jnp.array([active_process]), num_classes=num_processes)
		else:
			# death process
			rate = mu[active_process - num_processes]
			state_change = -jax.nn.one_hot(jnp.array([active_process - num_processes]), num_classes=num_processes)

		traj = jnp.concatenate([traj, traj[-1:] + state_change]) # do increment
		holding_time = sample_exponential(rate, time_key) # sample holding time where nothing happens
		t = jnp.concatenate([t, t[-1]+holding_time])

	return t, traj, active_process_idxs

key = jax.random.PRNGKey(1)
num_samples = 1
key, *subkey = jax.random.split(key, 1+num_samples)
subkey = jnp.stack(subkey, axis=0)
print(subkey.shape)
T = 100
t, traj, active_process_idxs = jax.vmap(lambda key: sample_process(la, mu, T, key))(subkey)

t.shape, traj.shape
color = {0: 'r', 1: 'g', 2:'b'}
fig = plt.figure(figsize=(20, 10))
for dim, traj_ in enumerate(traj[0].T):
	label=f'$\lambda={la[dim][0]:.2f}, \mu={mu[dim][0]:.2f}$'
	_ = plt.step(t[0], traj_.squeeze(), alpha=0.66, c=color[dim], label=label)
plt.legend()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And the result is a nice plot of a three dimensional continuous time Markov chain in which each process â€˜duelsâ€™ for action.
We can see from the behaviour of the sampled dimension and their corresponding parameters $\lambda$ and $\mu$, that the birth death process with the highest rates also exhibits the most fluctuations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../blog/CTMC/firstctmc.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Our first plotting function was straight out of the matplotlib box.
We will now implement a custom &lt;code class=&quot;highlighter-rouge&quot;&gt;plot_ctmc()&lt;/code&gt; function which can plot multiple draws of the processes.
The following function allows us to plot multiple draws conveniently.
For this we adopt the convention that all samples from a CTMC must be of the shape &lt;code class=&quot;highlighter-rouge&quot;&gt;[MC, T, F]&lt;/code&gt; where &lt;code class=&quot;highlighter-rouge&quot;&gt;MC&lt;/code&gt; is the number of random draws, &lt;code class=&quot;highlighter-rouge&quot;&gt;T&lt;/code&gt; is the number of time index and &lt;code class=&quot;highlighter-rouge&quot;&gt;F&lt;/code&gt; is the dimensionality of the process.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import matplotlib
def plot_ctmc(t, traj, la, mu):
	'''
	t: [T]
	traj: [MC, T, F]
	labels: 2F birth mu and death lambda
	colors: 2F
	'''
	assert traj.shape[0]==t.shape[0], f&quot;{traj.shape=} vs {t.shape[0]=}&quot;
	if traj.ndim==2:
		traj = jnp.expand_dims(traj, 0) # [T, F] -&amp;gt; [1, T, F]
	assert traj.ndim==3
	if t.ndim==2:
		t = jnp.expand_dims(t, 0)

	if t.ndim==1 and t.size==traj.shape[1]:
		t = jnp.expand_dims(t, -1) # [T] -&amp;gt; [T, 1]
	assert t.shape[:2]==traj.shape[:2], f&quot;{t.size=} vs {traj.shape=}&quot;
	
	color = {0: 'r', 1: 'g', 2:'b'}
	fig = plt.figure(figsize=(20,10))
	for dim in range(traj.shape[-1]):
		for mc_t, mc_traj in zip(t, traj):
			_ = plt.step(mc_t[:,0], mc_traj[:,dim], c=color[dim], alpha=max(0.1, 1/traj.shape[0]))
	plt.grid()
	plt.legend(handles=[matplotlib.lines.Line2D([0],[0], color=color[dim], label=f'$\lambda={la[dim]:.2f}, \mu={mu[dim]:.2f}$') for dim in range(traj.shape[-1])])
	return fig
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;using-jaxjit-and-making-things-go-vrooooom&quot;&gt;Using jax.jit and making things go â€˜vrooooomâ€™&lt;/h3&gt;

&lt;p&gt;Unfortunately &lt;code class=&quot;highlighter-rouge&quot;&gt;jax.jit&lt;/code&gt; is not very good with stochastic control flow.
We have the problem that we sample the active processes indices and then decide which part of the condition we execute.
That is a big no-no for JIT compilation as the stochasticity makes mapping out the data flow through the entire function not 100% deterministic.
Secondly, &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; will wonâ€™t work either as each process that will vmap will decide differently due to separately sampling itâ€™s condition.
Figuratively, the first vmapped process will sample the a birth process, but the second vmapped process will sample a death process.
What branch of the condition should the vmapped function then take?
Should it follow the first condition or the second?
Through some testing, which is too verbose for here, I have the very substantiated hunch that &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; would follow the first condition.&lt;/p&gt;

&lt;p&gt;What to do then?
We have to generalize the control flow by using a &lt;code class=&quot;highlighter-rouge&quot;&gt;mask = jax.numpy.where(condition, a, b)&lt;/code&gt; function which allows for control flow to be applied to an arbitrary array, and thus is also vmap-able as new dimension can be added to these arrays.&lt;/p&gt;

&lt;p&gt;Additionally, the time index in the while loop is not ideal, as &lt;code class=&quot;highlighter-rouge&quot;&gt;while(current_time &amp;lt; T )&lt;/code&gt; allows for vastly different lengths of the time index. Imagine that right before reaching &lt;code class=&quot;highlighter-rouge&quot;&gt;T&lt;/code&gt;, one vmapped process suddenly samples a super long holding time $t$.
Then youâ€™d have one process which is suddenly significantly longer time-wise than all other processes.
To alleviate this problem we will discretize the time axis with a &lt;code class=&quot;highlighter-rouge&quot;&gt;for(jax.numpy.linspace(0,T, steps))&lt;/code&gt; similar to a standard stochastic differential equation solved with Runge-Kutta 4 or Euler-Maryuama.
Sure, in theory we would want to sample continuously and correctly, but if we choose the discretized time grid with a fine enough resolution we get a sufficient result with the added bonus that our time index is standardized over all experiments.&lt;/p&gt;

&lt;p&gt;Letâ€™s get coding:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;key = jax.random.PRNGKey(1)

la = jnp.array([0.1, 1, 2.])
mu = jnp.round(la - 0.01 * la, 2) # slightly smaller da

def matrix_birth_death_process(key, la, mu):
	```Time resolution```
  T = 20
	steps = T * 100
	
  ```Preparing rates```
  num_processes = jnp.size(la)
	rates = jnp.stack([mu, la], axis=-1)
  
  ```Preparing arrays holding sampled process```
	traj = jnp.zeros_like(la).reshape(1,-1)
	t = jnp.zeros((1,1))
	
  for t_ in tqdm(jnp.linspace(0, T, steps)): # discretized time axis
    ```Use jax.numpy.where() to enable vmap-able control flow by using multiplication of arrays```
		mask = jnp.where(t[-1:]&amp;lt;=t_, jnp.ones((1,)), jnp.zeros((1,))) # if t_ has progressed further than last t, time to jump
    ```Splitting the relevant keys```
    key, process_key, birth_death_key, time_key = jax.random.split(key, 4)
    ```Sampling the active process, birth or death and holding time in new state```
		active_process_idx = jax.random.categorical(key=process_key, logits=la + mu)
		birth_death_idx = jax.random.categorical(key=birth_death_key, logits=rates[active_process_idx])
    holding_time_intensity = jnp.sum(la+mu)
		holding_time = sample_exponential(lam = holding_time_intensity, key=time_key)

    ```Updating state of process```
    increment = 2* birth_death_idx - 1 # rescale {0,1} to {-1, 1}
		update = increment * jax.nn.one_hot(x=active_process_idx, num_classes=num_processes)
    
    ```Concatenating current state and holding time to solution arrays of CTMC```
		traj = jnp.concatenate([traj, traj[-1:] + mask* update])
		t = jnp.concatenate([t, t[-1:] + mask *holding_time])

	return t, traj

t, traj = matrix_birth_death_process(key, la, mu)

fig = plot_ctmc(t, traj, la=la, mu=mu)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;../../blog/CTMC/matrixctmc.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately we have to wait close to a minute for the sampling process to execute fully.
To speed things up, weâ€™ll introduce a single function &lt;code class=&quot;highlighter-rouge&quot;&gt;jax.jit&lt;/code&gt; and see what will happen.
Weâ€™ll also â€˜allocateâ€™ the appropriate memory by fixing the size of arrays holding the sampled trajectories instead of concatenating it.
The more information the JIT compiler has, the more it can condense the verbose code into itâ€™s minimum viable representation.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;key = jax.random.PRNGKey(1)
num_process_samples = 20
key, *process_samples_key = jax.random.split(key, 1 + num_process_samples)
process_samples_key = jnp.stack(process_samples_key)


la = jnp.array([0.1, 0.1, 0.1])*10
mu = jnp.round(la - 0.01 * la, 2)  # slightly smaller death process

def fast_matrix_birth_death_process(key, la, mu, jit=True):

    def sampling(t, idx, next_event, traj, la, mu, key):
        '''Some prepration for sampling'''
        num_processes = jnp.size(la)
        rates = jnp.stack([mu, la], axis=-1)
        '''
        vmap-able and jit-able control flow in shape of jax.numpy.where
        If current time t has progressed further than last event time, time to act!
        '''

        mask = jnp.where(t &amp;gt;= next_event[idx-1], jnp.ones((1,)), jnp.zeros((1,)))

        '''Split keys for sampling: process selection key, birth or death selection key, holding time key'''
        key, process_key, birth_death_key, time_key = jax.random.split(key, 4)

        '''Sampling the active process, whether birth or death, and holding time until next event'''
        active_process_idx = jax.random.categorical(key=process_key, logits=la + mu)
        birth_death_idx = jax.random.categorical(key=birth_death_key, logits=rates[active_process_idx])
        holding_time = sample_exponential(lam=jnp.sum(la+mu), key=time_key)
        
        '''Rescale increment from {0,1} to {-1, +1}'''
        increment = 2 * birth_death_idx - 1
        update = increment * jax.nn.one_hot(x=active_process_idx, num_classes=num_processes)

        '''
        Only adds when mask is one, if idx=0, then idx-1 wraps around to final time step which is zeros anyway
        If mask=0, it simply copies the event time from last step, but if mask=1, sampling is kicked off and the next holding time is added to current time
        '''
        traj = traj.at[idx].set(traj[idx-1] + mask.squeeze() * update.squeeze())
        next_event = next_event.at[idx].set(next_event[idx - 1] + mask.squeeze() * holding_time.squeeze())
        return next_event, traj, key

    '''Fixing time index'''
    T = 100
    steps = T * 100
    
    '''Allocating arrays to make life easier for JIT compiler, but shouldn't make a huge difference in this case'''
    traj = jnp.zeros((steps, la.size))  # [T, F]*0
    next_event = jnp.zeros((steps, 1))  # [T, 1]*0
    
    '''Single function transformation makes things go vroooom'''
    sampling = jax.jit(sampling) if jit else sampling

    for idx, t_ in enumerate(tqdm(jnp.linspace(0, T, steps))):
        next_event, traj, key = sampling(t_, idx, next_event, traj, la, mu, key)

    t = jnp.linspace(0, T, steps).reshape(-1, 1)
    return t, traj


t, traj = fast_matrix_birth_death_process(key, la, mu, jit=False)
fig = plot_ctmc(t, traj, la=la, mu=mu)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you run the notebook cell above in Visual Studio Code, and switch the jit flag in &lt;code class=&quot;highlighter-rouge&quot;&gt;fast_matrix_birth_death_process&lt;/code&gt; you will encounter that the jited code block will accelerate the execution to &lt;strong&gt;0.5 seconds&lt;/strong&gt; whereas the unjitted version takes a stupendous &lt;strong&gt;23.9 seconds&lt;/strong&gt;. Thatâ€™s a &lt;strong&gt;50X&lt;/strong&gt; speed up by merely introducing a single function call more.&lt;/p&gt;

&lt;h3 id=&quot;making-parallel-evaluations-a-breeze-with-vmap&quot;&gt;Making parallel evaluations a breeze with &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;Next up is the simple but powerful functionality of &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Sampling a single process is all nice and stuff, but as soon as weâ€™re dealing with probabilistic systems, we need to draw samples,
In classic numpy or PyTorch we would know rewrite the code from single operations to batch-able operations.
If youâ€™re smart, youâ€™d always written your code with parallel evaluations in mind, such as a matrix-vector product is just a matrix-matrix product with a single column in the second matrix and so on and so forth.&lt;/p&gt;

&lt;p&gt;With &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; we have to introduce a single modified line to make parallel evaluations of the same function on different data (SIMD: single instruction multiple data) a reality.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'''New birth death rates'''
la = jnp.array([0.1, 1, 2])
mu = jnp.round(la - 0.1 * la, 2)  # slightly smaller death process

key = jax.random.PRNGKey(5)
num_process_samples = 4
key, *process_samples_key = jax.random.split(key, 1+num_process_samples)
'''Stack four PRNG keys via to [4,2] with the first dimension being the vmap dimension'''
process_samples_key = jnp.stack(process_samples_key)

'''Wrap the fast_matrix_birth_death_process() function by fixing la and mu parameters and making process_samples_key the vmap argument'''
t, traj = jax.vmap(lambda key: fast_matrix_birth_death_process(key, la, mu))(process_samples_key)
f'{t.shape=} and {traj.shape=}'
fig = plot_ctmc(t, traj, la=la, mu=mu)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;jax.vmap&lt;/code&gt; command acts as a wrapper around our sampling function.
It says that we keep the rates &lt;code class=&quot;highlighter-rouge&quot;&gt;la&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;mu&lt;/code&gt; fixed and the &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; wrapped function takes a only the sampling keys.
A single pseudo random number generator key is of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;(2,)&lt;/code&gt;.
By stacking the keys we obtain an array of PRNG keys of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;(4,2)&lt;/code&gt;.
&lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; will automatically recognize the added dimension and evaluate the same function in parallel for each of the 4 PRNG keys.&lt;/p&gt;

&lt;p&gt;Executing the sampling function with &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;jit&lt;/code&gt;, it takes us &lt;strong&gt;2.3 seconds&lt;/strong&gt; while the unjitted version takes a whopping &lt;strong&gt;106 seconds&lt;/strong&gt;, again the speed up factor of &lt;strong&gt;50X&lt;/strong&gt;.
One caveat is that jiting loops themselves is usually a bad idea as the compiler will trace the entire slow loop and then optimize it.
It usually better to &lt;code class=&quot;highlighter-rouge&quot;&gt;jit&lt;/code&gt; code blocks in for loops as the jit tracer doesnâ€™t have to unroll the loops and subsequently optimize them.
Using JIT on our little for loop in the sampling function predicted a &lt;strong&gt;5 minutes&lt;/strong&gt; run time for the first evaluation as it executes and traces the slow unjitted version of the function on its first call.
I tried recurseively jiting and vmaping hoping that &lt;code class=&quot;highlighter-rouge&quot;&gt;jit&lt;/code&gt; would reuse previously jited code blocks but thatâ€™s apparently not the case and it executes only the outer most &lt;code class=&quot;highlighter-rouge&quot;&gt;jit&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;Where things get really funky is once you start to realize that you can &lt;code class=&quot;highlighter-rouge&quot;&gt;vmap&lt;/code&gt; over all sorts of things.
Letâ€™s assume you have different birth death rates, you can then do the following:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'''Vmap over parameters'''

key = jax.random.PRNGKey(5)
la = jnp.array([[0.01, 0.01, 0.01], [0.01, 1, 10], [0.1, 1, 2], [0.5, 1., 2.]]) # [4, 3] birth rate set
mu = jnp.round(la - 0.01 * la, 2) # slightly smaller [4,3] death rate set
print(la.shape, mu.shape)

num_process_samples = la.shape[0]*5 # draw 4 x 5 samples to get 20 processes with distinct behaviour
key, *process_samples_key = jax.random.split(key, 1+num_process_samples)
process_samples_key = jnp.stack(process_samples_key).reshape(la.shape[0],5,2) # reshape to [4, 5, 2] random keys

'''
Outer/First vmap takes keys [4,5,2], birth rates [4,3] and death rates [4,3]
Outer/First vmap has 4 vmap inputs
Inner/Second vmap takes vmapped keys [5,2] for fixed birth rates [3] and death rates [3]
Outer/First vmap strips away the outer most dimension (=4)
Inner/Second vmap maps only over vmap-dimension of keys (second key dimension=5)
'''
vmap_matrix_birth_death_process = jax.vmap(lambda key, la, mu: jax.vmap(lambda key: fast_matrix_birth_death_process(key, la, mu))(key)) 
t, traj = vmap_matrix_birth_death_process(process_samples_key, la, mu) # ([4,5,2], [4,3], [4,3])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;traj.shape=[params, samples, time, F]
Loop over params dimension as plot_ctmc is only laid out for [Samples, T, F] data&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for t_, traj_, la_, mu_ in zip(t, traj, la, mu): # [params=4, samples=5, time=T, features=F]
	fig = plot_ctmc(t_, traj_, la=la_, mu=mu_)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and with a few extra lines of code and proper vmaping we quickly have the verification plots&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../blog/CTMC/vmap1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;../../blog/CTMC/vmap2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;../../blog/CTMC/vmap3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;../../blog/CTMC/vmap4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">jax.jit(jax.vmap(x=Discrete Space, t=Continuous Time))</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/blog/CTMC/vmap4.png" /></entry><entry><title type="html">Steinâ€™s Lemma for Trace Estimation</title><link href="http://localhost:4000/blog/TraceEstimation/" rel="alternate" type="text/html" title="Stein's Lemma for Trace Estimation" /><published>2022-12-09T00:00:00+01:00</published><updated>2022-12-09T00:00:00+01:00</updated><id>http://localhost:4000/blog/TraceEstimation</id><content type="html" xml:base="http://localhost:4000/blog/TraceEstimation/">&lt;head&gt;
&lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: &quot;all&quot; } } }); &lt;/script&gt;
       &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
         MathJax.Hub.Config({
           tex2jax: {
             inlineMath: [ ['$','$'], [&quot;\\(&quot;,&quot;\\)&quot;] ],
             displayMath: [['$$','$$']],
             processEscapes: true
           }
         });
       &lt;/script&gt;
       &lt;script src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\def\tr#1{\text{Tr}\left[ #1 \right]}
 \def\Efunc#1{\mathbb{E}\left[ #1\right]}
 \def\Efuncc#1#2{\mathbb{E}_{#1}\left[ #2 \right]}&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-trace-of-a-matrix&quot;&gt;The Trace of a Matrix&lt;/h3&gt;

&lt;p&gt;For a square matrix $A \in \mathbb{R}^{d \times d}$ the trace is defined as
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
\tr{A} = \sum_i^d A_{ii}
\end{align}&lt;/script&gt;
which sums over the diagonal terms of the matrix $A$. Plain and simple.&lt;/p&gt;

&lt;h3 id=&quot;hutchinsons-stochastic-trace-estimation&quot;&gt;Hutchinsonâ€™s Stochastic Trace Estimation&lt;/h3&gt;

&lt;p&gt;By definition we are only interested in the diagonal terms of a matrix when computing the trace of it.
But in cases where the matrix is computationally expensive to compute we might want to approximate it.&lt;/p&gt;

&lt;p&gt;Given a matrix $A$ one might think why the stochastic estimation is necessary when all we need to do is sum up the diagonal terms.
But Hutchinsonâ€™s trick can unfold its full potential when leveraging the specific structure of the matrix $A$.
Just wait until the Jacobian joins the party down below.&lt;/p&gt;

&lt;p&gt;We can approximate the exact trace with a stochastic estimate.
We therefore sample from $Z \in \mathbb{R}^D$, the mean of which is a zero vector and the covariance matrix is a identity matrix, i.e. $\Sigma[Z] = I$.
More precisely we determine the covariance matrix as
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
    \Sigma[Z] 
    &amp;= \Efunc{(z - \Efunc{Z})(z - \Efunc{Z})^T}\\
    &amp;= \Efunc{zz^T} - \Efunc{Z} \Efunc{Z}^T \\
    &amp;= \Efunc{zz^T} \\
    &amp;= I
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The Rademacher distribution which samples from the set ${-1, +1}$ with equal probability offers the lowest estimator variance and is commonly used in the trace estimation trick for this reason.
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
    \text{Tr}[A]
    &amp;= \text{Tr}[I A] \\
    &amp;= \text{Tr}[\Efuncc{z \sim p(z)}{z z^T} A] \\
    &amp;= \Efuncc{z \sim p(z)}{\text{Tr}{z z^T A}} \\
    &amp;= \Efuncc{z \sim p(z)}{\text{Tr}{z^T A z}} \\
    &amp;= \Efuncc{z \sim p(z)}{z^T A z} \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where the trace operator disappears as $z^T A z \in \mathbb{R}$ is a scalar value for which the trace is a superfluous operation.&lt;/p&gt;

&lt;p&gt;For estimating the trace of the Jacobian, we can circumvent the quadratic nature of the Jacobian by reducing the network output with a random vector z to a scalar, which can then be readily derived with a single backward pass.
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
    \text{Tr}[J_f(x)]
    &amp;= \Efuncc{z \sim p(z)}{z^T J_f(x) z} \\
    &amp;= \Efuncc{z \sim p(z)}{z^T \nabla_x [f(x)^T] z} \\
    &amp;= \Efuncc{z \sim p(z)}{z^T \nabla_x [f(x)^T z] } \\
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The important piece of information lies with the contraction $f(x)^T x$ which is an inner product.
Naively in equation (12), we would compute the full Jacobian matrix $J_f(x)$ and then contract it.
But since $z$ is a constant quantity for each sample in the expectancy, we can instead interpret $z$ as a constant scaling factor in the derivation of each output to each input which so happens to contract the full matrix.
You can think of it as a inner product of random vectors in which the Jacobian matrix provides the metric tensor.
So instead of Jacobian matrix times vector, we suddenly have a derivative of the scalar $J_f(x)^T z$.
The Jacobian evaluation $J_f(x): \mathbb{R}^\mathcal{X} \rightarrow \mathbb{R}^{\mathcal{X}\times \mathcal{Y}}$ reduces to the stochastic $\nabla_x [ f(x)^T z ]: \mathbb{R} \rightarrow \mathbb{R}^\mathcal{X}$.
Thus we saved us a lot of computations.
There is obviously a price to pay, namely that weâ€™re working with stochastic evaluations which introduces the curse of dimensionality into our evaluation.&lt;/p&gt;

&lt;h3 id=&quot;stein-is-entering-the-picture&quot;&gt;Stein is entering the picture&lt;/h3&gt;

&lt;p&gt;Let $X \in \mathbb{R}^N$ be a normally distributed random variable $p(x) =\mathcal{N}(x ; \mu, \sigma^2)$ with mean $\mu$ and variance $\sigma^2$.
Let the derivative of the normal distribution with respect to $x$ be
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\partial_x p(x) 
&amp;= \partial_x \left[\frac{1}{\sqrt{2\pi} \sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \right]\\
&amp;= -\frac{(x-\mu)}{\sigma^2} \frac{1}{\sqrt{2\pi} \sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \\
&amp;= - \frac{(x-\mu)}{\sigma^2} p(x).
\end{align} %]]&gt;&lt;/script&gt;
Integration by parts (IbP) serves as a inverse of the product rule $\partial_x [u(x) v(x)] = \partial_x u(x) v(x) + u(x) \partial_x v(x)$ namely 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
[u(x)v(x)]_{x=-\infty}^{\infty} &amp;= \int_{x=-\infty}^{\infty} u(x) \partial_x v(x) + \partial_x u(x) v(x) dx \\
&amp;= \int_{x=-\infty}^{\infty} u(x) \partial_x v(x) dx + \int_{x=-\infty}^{\infty} \partial_x u(x) v(x) dx
\end{align} %]]&gt;&lt;/script&gt;
which yields the often used identity
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
\int_{x=-\infty}^{\infty} u(x) \partial_x v(x) dx 
&amp;= [u(x)v(x)]_{x=-\infty}^{\infty} - \int_{x=-\infty}^{\infty} \partial_x u(x) v(x) dx.
\end{align} %]]&gt;&lt;/script&gt;
In practice, the property that either $u(x)$ or $v(x)$ or both evaluate to zero at $x = \pm \infty$ as it is the case with common probability distributions is leveraged as an algebraic trick to â€˜switch the derivative to the other functionâ€™.&lt;/p&gt;

&lt;p&gt;Given a function $g(x)$ we can obtain a gradient estimator with the following steps via integration by parts
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
    \Efuncc{p(x))}{g(x) ( x - \mu)}
    &amp;= \int g(x) (x-\mu) \frac{1}{\sqrt{2\pi} \sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} dx\\
    &amp;= \int g(x) (x-\mu) \frac{-\sigma^2}{-\sigma^2}\frac{1}{\sqrt{2\pi} \sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} dx \\
    &amp;= -\sigma^2 \int g(x) \underbrace{\frac{(x-\mu)}{-\sigma^2}\frac{1}{\sqrt{2\pi} \sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}}}_{\partial_x p(x)} dx \\
    &amp;= - \sigma^2 \underbrace{\int g(x) \partial_x p(x) dx}_{\text{IbP}} \\
    &amp;= -\sigma^2 \big\{ \underbrace{[ g(x) p(x)]_{x=-\infty}^{\infty}}_{p(\pm \infty)=0} - \int \partial_x g(x) p(x) dx \big\} \\
    &amp;= \sigma^2 \int \partial_x g(x) p(x) dx \\
    &amp;= \sigma^2 \Efuncc{p(x)}{\partial_x g(x)}
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;trace-estimation-with-steins-lemma&quot;&gt;Trace Estimation with Steinâ€™s Lemma&lt;/h3&gt;

&lt;p&gt;By choosing a perturbation $\epsilon \sim p(0, \sigma_\epsilon^2)$ with zero mean and a small variance $\sigma_\epsilon^2$ we can define a perturbed data point $xâ€™ \sim p(x,\sigma_\epsilon^2)$ via $xâ€™ = x + \epsilon$.
This transforms Steinâ€™s lemma into
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
    &amp;\Efuncc{p(\nu))}{g(x') ( x' - x)}
    = \Efuncc{p(\epsilon))}{g(x + \epsilon) \epsilon}
    = \sigma_\epsilon^2 \Efuncc{p(\epsilon)}{\partial_{x'} g(x')}.
\end{align} %]]&gt;&lt;/script&gt;
In practice we rescale with $1/\sigma_\epsilon^2$ and evaluate the left side of the following identity
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
    \Efuncc{p(\epsilon)}{g(x + \epsilon) \frac{\epsilon}{\sigma_\epsilon^2}} = \Efuncc{p(\epsilon)}{\partial_{x+\epsilon} g(x+\epsilon)}.
\end{align}&lt;/script&gt;
which gives us an estimator of the gradient $\partial_x g(x)$ by averaging the gradients in the $\epsilon$-neighborhood of $x$.
For a function $g: \mathbb{R}^M \rightarrow \mathbb{R}^N$, the gradient estimation with Steinâ€™s lemma estimates the trace of the Jacobian $J_g(x+\epsilon)$
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
    \Efuncc{p(\epsilon)}{g(x + \epsilon) \frac{\epsilon}{\sigma_\epsilon^2}} = \Efuncc{p(\epsilon)}{\text{Tr}\left[ J_g(x+\epsilon)\right]}.
\end{align}&lt;/script&gt;
In the limit of $\sigma_\epsilon \rightarrow 0$ we obtain the trace estimator
&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
    \text{Tr}\left[ J_g(x) \right] 
    = \lim_{\sigma_\epsilon \downarrow 0} \Efuncc{p(\epsilon)}{\text{Tr}\left[ J_g(x+\epsilon)\right]}
    = \lim_{\sigma_\epsilon \downarrow 0} \Efuncc{p(\epsilon)}{g(x + \epsilon) \frac{\epsilon}{\sigma_\epsilon^2}}
\end{align}&lt;/script&gt;
in which we compute the right most term to obtain the left most term.&lt;/p&gt;

&lt;!-- The scaling of the perturbation scale $\sigma_\epsilon$ offers at least in theory intriguing similarities to the forward diffusive process of diffusion models.
These models estimate the scores of the data distribution $x'_t \sim p(x, \sigma_t^2)$ in which $x$ is a sample from the true data distribution which is being modelled and the perturbation scale $\sigma_t$ is time dependent which decreases as the generative process is integrated in time.
Thus to stabilize the score estimation in higher dimensions we aim to to make the perturbation scale in the Stein trace estimator time dependent. --&gt;</content><author><name></name></author><summary type="html">Warning: May contain traces of nuts (and matrices)</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/blog/blogthumbnails/stein.png" /></entry><entry><title type="html">Money Laundering</title><link href="http://localhost:4000/blog/moneylaundering/" rel="alternate" type="text/html" title="Money Laundering" /><published>2022-11-26T00:00:00+01:00</published><updated>2022-11-26T00:00:00+01:00</updated><id>http://localhost:4000/blog/moneylaundering</id><content type="html" xml:base="http://localhost:4000/blog/moneylaundering/">&lt;h3 id=&quot;why-should-you-put-your-bills-in-the-laundry-machine&quot;&gt;Why should you put your bills in the laundry machine?&lt;/h3&gt;

&lt;p&gt;Obviously, the spread of Covid-19 has made us all very sensitive to germs and viruses.
Cash changes hands a lot of times and thus is the perfect medium to transmit diseases.
â€¦ yeah, Iâ€™m actually talking about the art of financial subterfuge obscuring the illicit origin of illegally obtained money.&lt;/p&gt;

&lt;p&gt;Apart from their ideologically motivated peers, criminals are driven by one thing: profit. 
Greed is the principal goal, but people that require money laundering skills donâ€™t sell stolen chewing gum on the school yard.
Instead, they have millions or even billions originating from illegal sources which need to be moved into official, legitimate and unsuspecting bank accounts of the criminals.
Thus the money needs to be able to be handled just like any other legitimate money.&lt;/p&gt;

&lt;p&gt;The problem is, as soon as a sovereign (and hopefully clean) police force would ascertain that an investment was done with money originating from illicit sources, they are most of the time allowed to seize the investments.&lt;/p&gt;

&lt;p&gt;The goal is now to disguise the financial assets so they can be used without detection of the illegal activity that produced them. 
The term â€˜money launderingâ€™ describes the process of transforming the monetary proceeds derived from criminal activity into funds of an apparently legal origin.&lt;/p&gt;

&lt;p&gt;Who is a potential user of money laundering? 
Drug cartels, terrorists, mobsters or the mafia, human traffickers, illegal arms dealers and the list goes on and on.&lt;/p&gt;

&lt;h3 id=&quot;money-laundering-methods&quot;&gt;Money Laundering Methods&lt;/h3&gt;

&lt;p&gt;In principal, money laundering consists of three distinct stages: placement, layering, and integration.
Personally, I use the terms entry, obfuscation, and integration which are more vivid terms in my opinion.&lt;/p&gt;

&lt;p&gt;The first step is to place the money at the entry points of the modern financial system.
If you got cash, you get â€˜smurfsâ€™ which repeatedly deposit money amounts just below the reporting line.
Usually, deposits below 10.000 USD donâ€™t have to be reported in the US, which led to bank tellers close to the Mexican border on the US side receiving up to 400.000 USD of deposits per week in cartel-linked accounts parceled out in 10k portions and deposited by local Americans to reduce suspicion.&lt;/p&gt;

&lt;p&gt;The second step is to obfuscate the origin of the cash.
You start moving money through different accounts or start to create round-about invoices with complicit companies.
For example, a smurf would deposit money in a bank account or would pay a bogus invoice for a company that only exists on paper.
Then the fake company would pay a fake invoice of another company which would then have an apparently legitimate income stream.&lt;/p&gt;

&lt;p&gt;Layering or obfuscation serves the purpose of creating a fake, seemingly legitimate origin of the funds.
Once a fake story for the money has been created, the main financial investments can be accomplished.
Imagine a suspicious person trying to buy a condominium in New York with a pile of unexplained cash and a real estate company headquartered in the Bahamas buying the apartment next to him.
The real estate company got its capital from the drug trade, human trafficking or sanction-busting arms trade just like the individual next door, but the police would be way more interested in the sole person with 15 million USD in unexplained cash and an unexplained stream of income.
The real estate company first laundered its capital through multiple layers of obfuscation and wouldnâ€™t provide a reasonable doubt for the origin of its money.
Itâ€™s basically all about appearances.&lt;/p&gt;

&lt;p&gt;Iâ€™ll outline some of the more common money laundering schemes.
Itâ€™s important to note that dubious origin of criminally obtained money can in theory always be traced back.
But the money launderers put in place so many layering steps that when law enforcement turns around the 20th corner and still has an apparently legit money stream, theyâ€™ll eventually give up.&lt;/p&gt;

&lt;p&gt;You can have fake trials in which both parties are in on the jig and ultimately under your control.
The defendant uses your illicit cash to pay the plaintiff the reimbursements.
But, lo and behold, both the plaintiff and the defendant are just conduits with the damages paid creating a clean income receipt.
If the police comes knocking, you can present the receipt of the indemnities.&lt;/p&gt;

&lt;p&gt;Exaggerated or even fake invoices which can include non-existent services.
Consulting on intellectual property is a favourite scheme, as the intellectual property is hard to value.
Since the worth of intellectual property is more symbolic or even intangible you can pay whatever you want for consultation.
Iâ€™ll outline an interesting scheme that was concocted to launder money in Germany using the sales of gangster rap music.
Organized crime supported musicians and ordered their drug dealers, respectively and more formal vendors of miscellaneous illegal wares, to accept purchases of the musicians work in exchange for illicit goods.
Instead of paying for drugs, they paid for intellectual property of the artist and thus the organized crime group had a steady inflow of money from music sales, which in itself is a legit business.
This was expanded to bot farms in the era of music streaming with bot farms which are controlled out of the dark part of the internet anyway.
The bot farms listened repeatedly to a musicians music who was under contract with an organized crime group.
Thus Spotify paid the artist for the increased number of streams and the OC group got their cut.&lt;/p&gt;

&lt;p&gt;Alternatively Mr. Criminal can buy real estate way below the market value with the difference to the full market price price being paid in illegal cash. 
Afterwards, the property is quickly sold for the appropriate price on the open market.
The illicit cash is given to the original owner and the money launderer creates a bogus profit via the sale at market level.&lt;/p&gt;

&lt;p&gt;You can convert illegal cash to casino jetons and a little bit is used for gambling.
Since gambling is intrinsically stochastic nobody can really trace back when you lost or when you won more money.
After some time, the casino jetons are cashed back in and you get a receipt that youâ€™re apparently an awesome gambler.&lt;/p&gt;

&lt;p&gt;The most straightforward method is still fictitious business activity of cash-based enterprises.
There, the illegal cash is simply mixed into the income stream proportional to the untainted money stream.
I mean proportional since even the most amazing taco truck usually doesnâ€™t make 200 million USD in revenue per year.
The usual suspects are dry cleaning shops, casinos, supermarkets, drug stores, car shops, and anything that has a largely cash-based income stream.&lt;/p&gt;

&lt;p&gt;Auctions of hard-to-value objects have also become a popular method and especially the art market has been captured.
You basically let two fake personas outbid each other with your own illegal cash.
The object with little intrinsic value is offered by you and the bidders get your illegal cash.
The sale creates a fake yet clean receipt.
Funnily enough, auction houses are exempt from money laundering prevention laws and you can often see people on phones bidding millions for an anonymous bidder watching it all from his or her sofa.&lt;/p&gt;

&lt;h3 id=&quot;offshore-jurisdictions-and-banking&quot;&gt;Offshore Jurisdictions and Banking&lt;/h3&gt;

&lt;p&gt;The principal safeguard against money laundering is the stringent enforcement of Know-Your-Customer (KYC) and Anti Money Laundering (AML) laws.
Ideally, the entry points to the financial system should have gatekeepers who check for potentially illegal sources of money.
Obviously, there is a conflict of interest since a lot of money means a lot of business for banks as was shown by HSBC scandal with the cartel money or the Raul Salinas story.&lt;/p&gt;

&lt;p&gt;Fortunately, a whole industry sector has blossomed between the beaches of the Caribbean, the mountains of the Alps, and in general small insignificant countries selling the legislative sovereignty to the highest bidder: the offshore finance industry.
Itâ€™s basically a sunny places for shady people.&lt;/p&gt;

&lt;p&gt;Offshore finance centers implement effectively no regulation of the financial industry within their borders and similarly implement convenient financial secrecy laws by allowing trusts, straight-out banking secrecy limiting the information of who actually owns a bank account, nominee directors of shell companies hiding the true owner of a company, and the like.&lt;/p&gt;

&lt;p&gt;By using the intricacy of modern tax codes, you can create a multitude of opaque companies which move money between them for no apparent reason.
For law enforcement, proving that the money being moved around is originally from illicit conduct is close to impossible.
Since innocence until proven wrong is a tenet in well-functioning judicial systems, it becomes close to impossible to prove the illegal source of the money.&lt;/p&gt;

&lt;p&gt;Using international banking, one could use mirror trades like the ones Deutsche Bank executed for Russian customers in 2007.
Two well-capitalized accounts, one in London and one in Moscow, would be under the control of the same entity at Deutsche Bank.
The Moscow based account would use dirty money to buy stocks in a company and Deutsche Bank holds the stocks as a broker.
Via â€˜remote bookingâ€™ the Moscow front office would then conduct a sale of the same stocks in the London market place for an apparently unaffiliated entity in London obtaining euros or dollars in that brokerage account.
The money to buy the stocks in London in the first place can be obtained via loans in Russia for example.
But since the London entity was controlled by the same person, they spend Roubles in Moscow and obtained and an equal amount of Dollars in a financial offshore jurisdiction.
The sale of the stocks in London created a squeaky-clean bill of financial health for the Dollars.&lt;/p&gt;

&lt;p&gt;Alternatively, you can also buy options in the derivative market for which you pay a premium.
These options have intrinsic value and can be sold, such that the dirty money can be used for the premium payments and the option itself can be sold for a higher value.&lt;/p&gt;

&lt;p&gt;Or you could use looped swap contracts across borders.
For example, interest rate swaps make one party pay the London Interbank Offered Rate (the LIBOR, itself subject to major manipulations at the cost of millions of people as portrayed in â€˜The Spider Networkâ€™ by David Enrich) while the other party pays a fixed rate and thus they â€˜swapâ€™ interest rates.
If you now chain these swaps in a circle, you can easily move money with a valid, seemingly clean contract from Moscow to London and then to Moscow back again.
Of course, the round-tripping is not obfuscated but each party seemingly gets a clean origin of money.&lt;/p&gt;

&lt;p&gt;Once the money has been safely moved into offshore financial centers it can then be used to invest.
The irony of many international active criminals is that they move their wealth out of their often unstable countries and park it in luxury real estate in judicially stable places like London, Paris, and New York.
There has been a rise in super tall skyscrapers in New York City which is commonly referred to as â€˜Billionaireâ€™s Rowâ€™.
But while these apartments offer amazing views of the City high above the problems of ordinary people, the ownership is more than opaque.
A majority of the luxury real estate is bought by shell companies and they are often occupied only a couple of days of the year.
Since they were legitimately bought, and the front companies in secrecy jurisdictions buying them being nearly impossible to crack open, it is next to impossible to prove that they had been bought with money obtained through illegal means.&lt;/p&gt;

&lt;p&gt;Especially in the case of the US, there is an interesting historical anecdote to tell.
Before 9/11, not a lot of people were interested in anti-money-laundering (AML) legislation.
But once the terrorist attacks on 9/11 occurred, everybody suddenly became very interested in how it was possible that a terrorist organization was able to pay for the flight school of the terrorist hijackers.
Somehow money was funneled half-way around the world out of Aghanistan into the US and used to pay for hotels, rental cars, flight schools and flights in and out of the US.
Itâ€™s not exactly that Al-Qaida was selling hot dogs in front of the Metropolitan Museum in Central Park.
Thus stringent AML laws were passed targeting every possible nook and cranny in which illegal money could be parked.
Included were luxury real estate and luxury products such that prior to a transaction in these industries KYC procedures and other AML laws had to be conducted.&lt;/p&gt;

&lt;p&gt;But a short while later, precisely these luxury industries were exempt from KYC and AML procedures.
The industries lobbied lawmakers to exempt them such that they could continue to sell luxury real estate and products to customers they knew little about.
To be fair, at a certain wealth you might want peace of mind and privacy and not see your latest purchase plastered over the morning edition of a tabloid.
Nevertheless, it is a peculiar coincidence precisely because luxury items give you the ability to store large amounts of money in a small number of objects.
Semi-fancy art paintings for 25 Million USD in an auction, a super expensive apartment in the UK or a gold-plated Lamborghini, none of these transactions require a stringent KYC procedure now anymore.&lt;/p&gt;

&lt;h3 id=&quot;reputation-laundering&quot;&gt;Reputation Laundering&lt;/h3&gt;

&lt;p&gt;But what do you do after youâ€™ve laundered all your money?
Essentially you have a criminal or a criminally connected person with large amounts of cash.
After you laundered your money, itâ€™s now time to launder your reputation.&lt;/p&gt;

&lt;p&gt;A good example of this is the story of Dmitry Firtash.
In essence, Dmytro Firtash is just a puppet for Semion Mogilevich, the mastermind of the Russian mob.
He came out of nowhere and was suddenly made co-owner of RosUkrEnergo, which is an intermediary that for some unknown reason gets to buy gas cheaply from Gazprom and sell expensively to Europe.
Since Gazprom is solidly in the hand of the Kremlin, it is assumed that these intermediary organizations pocket the difference and transfer it to Putinâ€™s kleptocracy.
Dmitry Firtash came out of nowhere within a position nobody could really explain resulting in money that is a bit shady, to say the least.
Nevertheless, he quickly ingratiated himself with the who is who in the UKâ€™s public sphere.&lt;/p&gt;

&lt;p&gt;He went through all the necessary procedures that I will outline down below to become one of Londonâ€™s elite and seemingly respected members.
The first step was to obviously buy expensive real estate which gives ample room to host dinners and invite important people.
This lets you put roots down and people consider you a member of Londonâ€™s exclusive super-rich social circle.
Next, you hire a public relations firm ( in itself a more than a weird concept) that will manage your public image.
They will put you in touch with members of parliament and other prestigious people which will serve as directors for you charity or foundation which you obviously founded only for the reason to pay prestigious people.
The charity, foundation or whatever should be nice and uncontroversial when people think of it: be socially active, give out stipends, build sports facilities or anything that gives you a nice PR photo op.&lt;/p&gt;

&lt;p&gt;Given that you have paid a company to give you a good image with a suitable background, the PR firm will continue to actively forge new relationships.
You host dinners with ex-politicians with a powerful rolodex, you cast your dubious conglomerate as a useful and relevant aid to the national interests of the country.
Commodities, energy, media, and construction are of interest to a country but are hardly irreplaceable.
Nevertheless, you are now a useful member of society and worth keeping in the fold.
Another step is to be philanthropic in high society circles by sponsoring new buildings for colleges, preferably Oxford, Cambridge, and the London colleges like UCL.
Dmitry Firtash founded a Ukrainian studies program that brought him in close contact with exclusive circles of Oxbridge.
Given that Londonâ€™s elite is definitely to almost exclusively educated at Oxbridge that brings you in fortuitous contact with a little of influential people.&lt;/p&gt;

&lt;p&gt;The first aim of these PR shenanigans is to make the client too well-connected and too important to discard.
The second part of reputation laundering in the UK is to use its potent libel laws to make reporting on the source of these peopleâ€™s wealth impossible.&lt;/p&gt;

&lt;h3 id=&quot;libel-law--tourism&quot;&gt;Libel Law &amp;amp; Tourism&lt;/h3&gt;

&lt;p&gt;Ultra-wealthy people donâ€™t just travel to the UK to park their money there but also like to travel there to suffocate any reporting on their dodgy wealth.&lt;/p&gt;

&lt;p&gt;English law allows them to sue for libel for any published statements which are allegedly defaming a named or identifiable individual if these have caused a loss in their trade or profession or just plainly damage their reputation.
This is pretty standard around the world and is present in almost any judicial code.
What sets the UK apart is that in a libel case, the allegedly defamatory statement is presumed to be false unless the defendant can prove its veracity.&lt;/p&gt;

&lt;p&gt;This has conferred the status of â€˜most favored nationâ€™ (to borrow a WTO term) onto the UK from ultra-high net worth people with questionable sources of income.
In essence, the burden of proof lies with the defendant such that even the slightest insinuation is impossible unless is airtight and reinforced with proof.
Any sentence like â€˜ â€¦ who has reportedly close dealings with the Russian mob â€¦â€™ could set loose the legal hounds upon the publication outfit under which auspice this sentence was printed.
Just imagine a multi-billionaire going to court against an investigative newspaper with the billionaire plaintiff being able to bankrupt the investigative newspaper through legal costs alone.&lt;/p&gt;

&lt;p&gt;A good example of this is the excellently written book â€˜Putinâ€™s Kleptocracy - Who owns Russiaâ€™ by Karen Dawisha which was essentially shunned by every publisher in the UK for fear of being bankrupted by legal proceedings and ultimately had to be published in the US.
The rebellious colony across the Atlantic had passed the SPEECH Act of 2010 which made foreign libel judgements without equivalent free speech enforcements unenforcible in the US.&lt;/p&gt;

&lt;p&gt;To top it out, a public official or public figure as a plaintiff has to prove actual malice in writing possible â€˜slanderâ€™ causing professional or reputational harm.
A private individual instead must only prove negligence to be able to win the libel case.
Especially in the case of off-shore finance and other dealings taking place in the dark, nothing is ever fully known and the slightest mistake which can be exploited by the plaintiff as negligence can lead to bankrupting the entire publishing outfit or journalist.&lt;/p&gt;

&lt;p&gt;The misuse of libel lawsuits become so egregious that the libel law slightly reformed in 2013.
While it made winning libel cases harder for plaintiffs as they now had to prove actual and objective harm, it left the legal costs unchanged.
Simply maintaining a legal team which can hold its own against high-powered legal advice from oligarchs would bankrupt the defendant.&lt;/p&gt;

&lt;p&gt;Unfortunately, this is not limited to news papers.
Even the National Crime Agency, the UKâ€™s main police force for economic crime and organized crime, is capped by litigious oligarchs.
In a more than questionable legal setup the NCA is required to pay the full legal fees in case of a loss in court of the defendant.
Given that shady ultra-high net worth people are financially able to employ law firms of the likes of Mishcon de Reya, the legal fees quickly become too much to bear by the public office.
Thus the effect is that the economic crime division of the UK is legally hamstrung to prosecute shady billionaires afraid it will loose its entire annual budget to a single criminal case.&lt;/p&gt;

&lt;p&gt;The annual budget of the NCA is around 4.3 million pounds.&lt;/p&gt;

&lt;p&gt;Oligarchs buy third houses in Kensington and Mayfair for 80 million pounds â€¦&lt;/p&gt;</content><author><name></name></author><category term="globalizedfinance" /><summary type="html">Greenbacks, Soap and Hopefully No Questions</summary></entry><entry><title type="html">Kleptocracy with Vodka &amp;amp; Borscht</title><link href="http://localhost:4000/blog/kleptocracyrussia/" rel="alternate" type="text/html" title="Kleptocracy with Vodka &amp; Borscht" /><published>2022-10-16T00:00:00+02:00</published><updated>2022-10-16T00:00:00+02:00</updated><id>http://localhost:4000/blog/kleptocracyrussia</id><content type="html" xml:base="http://localhost:4000/blog/kleptocracyrussia/">&lt;h3 id=&quot;kleptocracy-in-russia&quot;&gt;Kleptocracy in Russia&lt;/h3&gt;

&lt;p&gt;The Russian kleptocratic system is more straight forward and relies more on direct theft than currency manipulation.
But here, too, we have to first go back in time a bit to 1980â€™s in the Soviet Union.&lt;/p&gt;

&lt;h4 id=&quot;a-bit-of-historical-context&quot;&gt;A Bit of Historical Context&lt;/h4&gt;

&lt;p&gt;Supposedly everybody is familiar with â€˜Star Wasâ€™, the saga of one messed up family that keeps an entire galaxy busy with its family issues.
Itâ€™s so popular that Mickey Mouse eventually decided to to buy up the IP to milk it harder than an Irish cow (which has a better life than the Disneyland employees).
Ronald Reagan, being an actor originally who read the likes of Hayek and Friedman on between shoots while on set, pushed ahead with a â€˜Star Warsâ€™ missile defense program which would protect the US from Russian ballistic missiles.
It was the final chapter of a tremendous arms race which had pitted the US and the Soviet Union against each other in the search for ever more advanced weapons.
While eventually being massively overhyped, it did let the Russians realize that they could not win the arms race with their inefficient planned economy.
After a bit more than half a century of planning their economies during which the Soviet Union had been able to pull of tremendous feats of engineering by concentrating labour, resources and a disregard for human necessities, the realization set in among the higher ups in the Soviet economy that they could not sustain the arms race on their own terms.&lt;/p&gt;

&lt;p&gt;Even during the darkest economic days of the Soviet Union, there had been a multitude of black market operations who provided the population with a few basic goods.
These operations were mainly run by mostly ethnic outsiders such as Chechens, Jews and Kazakhs.
Due to latent, political and sometimes rampant anti-semitism, Jews often had to struggle to survive in country in which the word â€˜progromâ€™ had been gained its infamous meaning.
Then criminal enterprises in a country which deemed criminality a capitalist disease and thus couldnâ€™t exist in the communist union became a very attractive alternative occupation.
Even nowadays it remains interesting high the percentage of Jewish gangsters is in the criminal scene of Russia given its overall percentage such as Semion Mogilevich (long time on the FBIâ€™s most wanted list), Marat Balagula or Evsei Agron.&lt;/p&gt;

&lt;p&gt;The KGB as the most powerful security organization was tasked with controlling the black market but quickly realized that they could run their own protection rackets and make money out of the economic misery of their compatriots.
To some extent, the existence of the black market was even timidly encouraged as it eased some of the economic hard ship by increasing the supply, even at inflated prices.
This led to a political-security-criminal nexus in which KGB officers were quick to learn their first lessons in private enterprise.&lt;/p&gt;

&lt;p&gt;Then in the 1980â€™s a motley crew of KGB officers and Russian economists began to think about a new hybrid system which could have developed similarly to the Chinese emergence out of communism into hybrid, controlled capitalism.
During the Glasnost &amp;amp; Perestroika period, Gorbachev became loosening the iron grip on the Soviet Unions political and economic system and urged other Warsaw Pact countries to follow suit.
In 1991, the New Union Treaty was signed due to incessant and increasing unrest of the other Soviet republics which handed more control and independence from Moscow to the individual republics.
Hardliners in the Soviet Unions Communist Party wanted to have none of that and staged a coup on August 19-22 1991.
While the KGB detained Gorbachev at his holiday estate on the Black Sea, they did not arrest Boris Yeltsin who was able to confront the putschists and effectively ended it.
In the wake of the coup the Communist Party of the Soviet Union was effectively dissolved by Yeltsin.&lt;/p&gt;

&lt;h4 id=&quot;the-looting-begins&quot;&gt;The Looting Begins&lt;/h4&gt;

&lt;p&gt;The East German Stasi had a dedicated department called â€˜Kommerzielle Koordinierungâ€™ for stealing western military and dual use technology as well as procure foreign currency reserves through smuggling.
It is estimated that up to 50% of all Soviet weapons systems at the end of the cold war were based upon stolen blue prints from the West.
But the technological gap became so wide, that the Soviets werenâ€™t able to implement the blue prints anymore as the manufacturing capabilities were ultimately lagging far behind.
Initially it was organized under infamous Markus Wolfâ€™s espionage department before coming a force of itself, a sign of how important it became to East Germany and in extension to the Soviet Union.
The KGB had developed a similar department for economic and financial logistics in foreign countries.
A multitude of shell companies and banks had been founded and were controlled by the First Main Directorate if the KGB in charge of foreign intelligence.
These shell companies were used to buy resources and material on the international markets as well as transfer money out of the country to causes which were deemed important to the Soviet Union or the KGB.&lt;/p&gt;

&lt;p&gt;More often than not though, the profits from the difference between Soviet and market prices were stashed away in the untold bank accounts and companies, control over which was held by the KGB.
The funneling of black cash was done through â€˜friendly firmsâ€™ which were shell companies or corrupted real companies through which untraceable money went on its way to its final use.
These were front companies serving just as financial conduits to which other companies wishing to do business in or with the Soviet Union had to pay money for bogus or inflated prices.
These â€˜friendly firmsâ€™ could then disburse their enormous profits to fund for example the communist parties in Spain, the UK and France.
Sometimes they were busy with smuggling technology to the Soviet Union or East Germany.&lt;/p&gt;

&lt;p&gt;Then there were â€˜friendly banksâ€™ in which the profits of barter deals was stashed.
Often, these â€˜friendly firmsâ€™ would buy natural resources, which the Soviet Union had a lot of, at extremely undervalued Soviet Prices and sold them on the world market for the spot price.
Later during Putinâ€™s reign as trade chief under Anatoly Sobchack in St. Petersburg, a license was given out to export 13 tons of rare earth metals for 1/2000 th of the current world market price.
The profit margin is directly there in the divisor and the part of the profits of such export deals were then stashed in accounts in â€˜friendly banksâ€™ such as Switzerlandâ€™s Banco del Gottardo or secrecy jurisdictions like Panama, Hong Kong or the British Channel Islands.
The sums could then be used as slush funds for communist party to destabilize the West or do whatever else they wanted to achieve, but more importantly, they were overseen by the KGB.&lt;/p&gt;

&lt;p&gt;As Gorbachevâ€™s reform sent the Soviet Union towards unruly chaos, his deputy signed off the intention in August of 1990 to create an â€˜invisible economyâ€™ managed by â€˜trusted custodiansâ€™ with a network of shell companies to spirit away the wealth of the Communist Party.
When the Communist Party was dissolved on live TV by Boris Yeltsin on August 25 1991, this automatically raised the question what would happen to all the money, foreign currencies, property and investments nominally under their control.
Less than three day after Yeltsin had averted the coup in Moscow with a fiery speech on a tank, Nikolay Kruchina, the Parties property department chief, fell out of his window.
A month later, his predecessor Georgy Pavlov fell out of his window as well at the age of 81.
Eleven days Dmitry Lissovolik, the American Section chief of Communist Partyâ€™s International Department, which oversaw funding of international operations and was thus at the heart of the web of shell companies, fell to his death as well.
All three men had deep insights into the property of the Communist Party which was officially valued at 9 billion USD but unofficially valued at many times over that.
Thus when the new government came looking for the money that the Communist Party had amassed over the last 80 years, they found nothing.&lt;/p&gt;

&lt;p&gt;The second round of lopsided privatization occurred with the creation of cooperatives, the Soviet version of private enterprises first allowed in 1987, inside large state-owned enterprises which started selling off the huge stockpiles of strategic reservers.
The directors started privatizing the state-owned enterprises from the inside out by controlling the cash flow in the large, still state-owned, enterprises.
Back then, having a positive cash flow allowed you to achieve extraordinary gains in a massively inefficient organize economy.
The government agreed to privatize parts of the Russian economy via a voucher system during a time of rampant hyper inflation when the general population had little nerve for long-term investing.
Additionally, the vast majority of the population were unaccustomed to the idea of investing and owning shares after 80 years of communism.
Since people were more interested in surviving, the company directors, the Russian mafia and other insiders with access to the cash flow were able to buy up large amounts of the share vouchers.&lt;/p&gt;

&lt;p&gt;A small addition to the cooperative legislation allowed the creation of banks which is where the real massive privatization of the Russian economy started.
Among the first banks to obtain a foreign currency trading permission was the Menatep bank of Mikhail Khodorkovsky.
CIA station chief Richard Palmer and Procurator General Aristov claim that between 500 Miollion to 1.5 Billion USD of vanished Communist party funds were used by ex-KGB officers to fund these first commercial banks and at the same time hide the money.
Among other schemes, they used the official state exchange rate of 1 USD to 65 kopecks to change roubles into US dollars and buy private computers in the West.
They then sold the computers in Russia with the value being close to 40 roubles for each dollar of import computers.
You can probably see how you can print exponential money by using currency exchange arbitrage and cycling the roubles back through the official state sanctioned exchange rate into dollars.&lt;/p&gt;

&lt;p&gt;The third theft from the Russian people after the billions of CPSU money and the mismanaged voucher system was committed during the privatization of the hugely profitable sectors of the formerly Russian state economy creating the first generation of Russian oligarchs.
The transition of 80 years of planned economy mired in inefficiency, political suppression and corruption towards a free market went as smoothly as one would think.
The government under Boris Yeltsin soon fell on fiscally hard times and was in dire need for cash to keep the country running.&lt;/p&gt;

&lt;p&gt;The original sin of the Russian market economy was the loans-for-shares program, also termed the second wave of privatization.
For reasons unknown or inconvenient at the moment, Boris Yeltsinâ€™s government refrained from creating its own treasury and instead simply deposited the governments funds into the oligarchs privately owned banks.
Without doing any work, they could suddenly invest money worth an entire countries budget into high yielding investements.&lt;/p&gt;

&lt;p&gt;As Boris Berezovsky put it somewhat humorously upon being asked whether he would let his wealths provenance be checked: â€˜Absolutely, I would submit all my wealth to legal scrutiny. Except for the first million.â€&lt;/p&gt;

&lt;p&gt;But the government was still cash-strapped and needed money fast.
The banks agreed to give the government private loans and as collateral took considerable minority stakes in large state-owned enterprises predominantly in the natural resources sector.
When the government couldnâ€™t repay the loans, they were allowed to auction off their stakes and pocket the proceeds.&lt;/p&gt;

&lt;p&gt;Yeltsin held the oligarchs politically hostage by receiving the loans before the election but ensuring the auction to sell them off would only occur after the election.
Thus the oligarchs had a massive interest in ensuring Yeltsin reelection.
To little surprise, the government couldnâ€™t in fact repay the loans and the oligarchs through their political clout were able to rig the auctions.&lt;/p&gt;

&lt;p&gt;Thus Potanin got Norilsk Nickel, the worlds largest nickel and platinum producer, with 1.2 billion USD of profits in 1995 for a mere 175 million USD in the same year.
Khodorkovsky took control of 78 percent of Yukos valued at 5 billion USD for 310 million USD.
Berezovsky took over Sibneft worth around 3 billion USD for just 100 million USD.
After the auctions, Boris Berezovsky remarked that seven bankers now controlled 50 percent of the Russian economy.&lt;/p&gt;

&lt;p&gt;The KGB and the company directors tried to fight the take over but were only able to win two out of the numerous auctions.
During one auction, the company directors closed down the closest airport and armed guards blocked the streets to prevent anybody but the company directors to bid in the auction.
It was truly the â€˜Wild, Wild Eastâ€™.
Yet, while many of the first generation of oligarchs had been nurtured by the KGB itself, the securocrats quickly found themselves outwitted and outmaneuvered by the freshly minted billionaires.
For an organization steeped in the sense of control over an entire country, this was a moment which was neither forgiven nor forgotten.&lt;/p&gt;

&lt;p&gt;The grudges and resentment created during that privatization in which the KGB lost economic control of the country created the vengeance with which the Putin government went after the first generation of oligarchs.
It led to the rise of the â€˜silovikiâ€™, ex-security and military personnel, which installed Vladimir Putin in power and viciously took over the country by expropriating the oligarchs or pummeling them into political submission.&lt;/p&gt;

&lt;h4 id=&quot;the-1999-legislative-and-2000-presidential-election&quot;&gt;The 1999 Legislative and 2000 Presidential Election&lt;/h4&gt;

&lt;p&gt;The Russian constitution officially allows only two terms which Boris Yeltsin had served after his reelection in 1996.
But there was a minor issue at hand for the Yeltsin family: there was massive resistance to his corruption and multiple investigations into his and his familyâ€™s dealings during his presidency.
The â€˜Familyâ€™ as it was called consisted of the Yeltsin family as well as close friends who had used the power position to enrich themselves.
The problem was that the most probably succesor to Yeltsin was Yevgeny Primakov who had clearly signalled to clear up and prosecute the graft of Yeltsins inner circle.
He teamed with popular Moscow mayor Yury Luzhkov and gouvernors of the Russian Federationâ€™s provinces to position himself as the clear winner of the 1999 election.
Since Yeltsin himself couldnâ€™t run anymore they needed a viable succesor who could prevent Primakovâ€™s wrath and grant them immediate immunity from any legal prosecutions once he and his family and cronies left the presidency.
So they settled on Vladimir Putin and Boris Yeltsin dissolved his government to force reelections which was hopefully too soon for the opposition to organize a viable campaign.
In August of 1999, he made Putin his prime minister.
But yet again there was one problem: Yeltsinâ€™s approval rating were at a rock-bottom 2% and hardly anyone in the population knew Putin at all.&lt;/p&gt;

&lt;p&gt;The second half of Yeltsin first presidency was overshadowed by the first Chechen War, in which between 30.000 to 100.000 Chechen civilians were killed.
There is a haunting transcript from a radio communication between two officers who had fought side by side in Afghanistan and now faced each other during the Battle of Grozny.
The &lt;a href=&quot;https://www.youtube.com/watch?v=NnA552tMV8g&quot;&gt;link to the video and transcript&lt;/a&gt; can be found on YouTube and tells a story of senseless murder between friends condensed in less than a minute.
The date in the title of the video is wrong as the Battle of Grozny was waged during the First Chechen War in 1994-1996 and not the second, which was in 1999 to 2009.
The Russian army demolished Grozny with artillery fire after failed first attempts to take the city in what was described as the largest destruction of a civilian city since Stalingrad.&lt;/p&gt;

&lt;p&gt;Nevertheless the first Chechen War created a menacing enemy for the Russian Federation.
Then suddenly bombs started to go off in appartment buildings in September of 1999 killing close to 300 civilians sleeping in their beds in Moscow and Volgodonsk.
While it was initially believed to be the work of Chechen terrorist, the Duma speaker Gennady Seleznyov made an announcement that a bomb had exploded in Volgodonsk on 13 September 1999.
Nobody took him for full until a bomb did explode three days later on 16 September.
This was the first suspicious incident which was quickly overshadowed by the prevented bombing of an appartment complex in Ryazan.&lt;/p&gt;

&lt;p&gt;On the evening of 22 September 1999, a resident saw two shady men carry sacks of what appeared to be sugar into the basement of an appartment building.
The car was from Moscow but the license plate was altered to make appear local.
After multiple bombings in the same month, the resident was suspicious and alerted the police which found three sacks of white powder totalling 150kg with a timer set to 5.30 the next day.
The local bomb squad identified the white powder as RDX, a military grade explosive which is not especially easy to organize.
Terrorists commonly use ammonium nitrate which can be produced with supplies from the local hardware/gardening store as it also used as a fertilizer.&lt;/p&gt;

&lt;p&gt;On the next day a telephone service employee listened in on a suspicious phone call which was traced back to three FSB officers who were apprehended by the local police.
Prior to the identification of these three security officers, both the local FSB and the headquarters had been on the same page that the averted bombing had been the work of terrorists.
But as soon as the three FSB officers from Moscow had been identified, the FSB director Nikolay Patrushev suddenly made it a training exercise to which the local Ryazan FSB denounced vehemently.
The RDX suddenly became sugar according to the FSB director and the two privates in Ryzan who had tried to use the RDX/sugar as sweetener during their shift and found it to taste terribly were reprimanded by the FSB personally to â€˜forget everythingâ€™ and â€˜not get mixed up in such troublesâ€™ after telling their story to an investigative newspaper.
Additionally, all investigations were hindered by the FSB and even the Duma member Trepashkin was suddenly arrested when he started asking uncomfortable questions regarding the Chechen origins of the perpetrators.
The Duma even voted to seal all documents on the Ryazan bombing for the next 75 years and officially forbade any investigations into the FSBâ€™s role in the bombing.&lt;/p&gt;

&lt;p&gt;As there has been no investigation there is nothing that can be said with certainty.
But the bombings and the final botched bombing does become malicious and cynical once the meteoric rise of Vladimir Putins approval ratings is taken into account.
As a tough talking KGB guy who ran a campaign on order and restraining the chaos of the Yeltsin time, the bombings came to a fortuitous time as it gave a perfect pretense to exalt his strengths as a tough policing guy.
The bombings played greatly into his approval ratings going from a mere 2% to 45% right before the presidential election.&lt;/p&gt;

&lt;p&gt;A last note on the legitimacy of the 2000 presidential election on 26 March 2000:
It was reported that the region of Chechnya, an astonishing 50.63% voted for Putin.
This result was apparently achieved after the Russian military had laid siege to Grozny from December 1999 to February 2000.
Apparently the half the population of a bombed out region with 30.000-100.000 civilian casualties from a war a mere 4 years ago voted for a guy who said he would march back into Chechnya to finish what was started in the first Chechen war.
I guess elections are full of suprises â€¦&lt;/p&gt;

&lt;h4 id=&quot;russian-kleptocracy-today&quot;&gt;Russian Kleptocracy Today&lt;/h4&gt;

&lt;p&gt;The corruption in Russia has taken on such extremes that the Moscow station chief of the CIA Richard Palmer summarized the extents of the system in 1999 as following&lt;/p&gt;

&lt;p&gt;â€
For the U.S. to be like Russia is today, it would be necessary to have massive corruption by the majority of the members of Congress as well as by the Departments of Justice and Treasury, and agents of the FBI, CIA, DIA (Defense Intelligence Agency), IRS, Marshal Ser-vice, Border Patrol, state and local police officers, the Federal Reserve Bank, Supreme Court justices, U.S. District court judges, support of the varied Organized Crime families, the leadership of the Fortune 500 companies, at least half of the banks in the U.S., and the New York Stock Exchange. This cabal would then have to seize the gold at Fort Knox and the federal assets deposited in the entire banking system. It would have to take control of the key industries such as oil, natural gas, mining, precious and semi-precious metals, forestry, cotton, construction, insurance, and banking industries and then claim these items to be their private property. The legal system would have to nullify most of the key provisions against corruption, conflict of interest, criminal conspiracy, money laundering, economic fraud and weaken tax evasion laws. This unholy alliance would then have to spend about 50% of its billions in profits to bribe officials that remained in government and be the primary supporters of all of the political candidates. Then, most of the stolen funds, excess profits and bribes would have to be sent to off-shore banks for safekeep-ing. Finally, while claiming that the country was literally bankrupt and needed vast infusions of foreign aid to survive, this conspiratorial group would invest billions in spreading illegal activities to developed foreign countries. â€¦ The President would not only be aware of all these activities but would support them.
â€œ&lt;/p&gt;

&lt;p&gt;A summary I read in Karen Dawishas excellent book â€˜Putinâ€™s Kleptocracyâ€™ perfectly summarizes the current system and Iâ€™m just going to quote it here:&lt;/p&gt;

&lt;p&gt;â€
It became clear to Russian and Western observers long before Putin started his third full term as president in 2012 that he operated a complex informal system in which subgroups were constantly balanced against each other, with Putin alone as the ultimate arbiter.
His power derived less from the institutional legitimacy conferred by being head of state than from the successful operation of a tribute system that obliged all participants to recognize his authority.
In the words of American economists Clifford Gaddy from the Brookings Institution and Barry Ickes from Pennsylvania State University, Putin operates a â€œprotection racketâ€ dependent on a code of behavior that severely punishes disloyalty while allowing access to economic predation on a world-historic scale for the inner core of his elite.
By his third term, he had created a highly controlled security system able to use the laws, the media, and the security forces as a means of intimidating, and critically balancing, rival economic elites.
Others have called it a â€œcorporationâ€ â€œKremlin, Inc.,â€ â€œa sistema,â€ or a â€œcorporatist-kleptocratic regime.
â€œ&lt;/p&gt;

&lt;p&gt;On average, billionaires in the wide world own 1-2% of a countries wealth.
In Russia, this number is turned upside down as 110 billionairs own 35% of Russias wealth.
Furthermore, the amount of capital flight is so extreme, that 50% of all Russian wealth is reported to reside outside of Russia.
Now this also points the finger indirectly squarely at the West, especially the US and the UK, in which huge sums of Russian money is invested in luxury real estate and miscellaneous luxury items.&lt;/p&gt;

&lt;p&gt;The judicial system is so steady in the grip of the kleptocracy that hundred of thousands of entrepreneurs are currently incarcerated in Russian prisons.
They have been framed by competitors or just plain black mail racketeers who bribed the criminal system with police and judges.
While the average salary has grown to 1650 USD per year, the median salary remains stagnant at 871 USD, even below Indias median salary of 1040 USD.
This gap is explained with the extreme inequality relating to billionaires and millionaires who work hand in glove with the kleptocracy.&lt;/p&gt;

&lt;p&gt;A worrying trend is that 35% of workers under 30 have a government job which is paid for by extractive industries such as timber, oil, gas and minerals.
This is the result of a fusion of a resource curse combined with a kleptocracy in which nobody is interested in building impartial institutions which serve the public and not a well connected kleptomaniac.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;div class=&quot;tableauPlaceholder&quot; id=&quot;viz1688392485502&quot; style=&quot;position: relative&quot;&gt;&lt;noscript&gt;&lt;a href=&quot;#&quot;&gt;&lt;img alt=&quot; &quot; src=&quot;https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;We&amp;#47;Week44Thecountrieswiththemostbankholidays_1&amp;#47;multi-colourHEX&amp;#47;1_rss.png&quot; style=&quot;border: none&quot; /&gt;&lt;/a&gt;&lt;/noscript&gt;&lt;object class=&quot;tableauViz&quot; style=&quot;display:none;&quot;&gt;&lt;param name=&quot;host_url&quot; value=&quot;https%3A%2F%2Fpublic.tableau.com%2F&quot; /&gt; &lt;param name=&quot;embed_code_version&quot; value=&quot;3&quot; /&gt; &lt;param name=&quot;site_root&quot; value=&quot;&quot; /&gt;&lt;param name=&quot;name&quot; value=&quot;Week44Thecountrieswiththemostbankholidays_1&amp;#47;multi-colourHEX&quot; /&gt;&lt;param name=&quot;tabs&quot; value=&quot;yes&quot; /&gt;&lt;param name=&quot;toolbar&quot; value=&quot;yes&quot; /&gt;&lt;param name=&quot;static_image&quot; value=&quot;https:&amp;#47;&amp;#47;public.tableau.com&amp;#47;static&amp;#47;images&amp;#47;We&amp;#47;Week44Thecountrieswiththemostbankholidays_1&amp;#47;multi-colourHEX&amp;#47;1.png&quot; /&gt; &lt;param name=&quot;animate_transition&quot; value=&quot;yes&quot; /&gt;&lt;param name=&quot;display_static_image&quot; value=&quot;yes&quot; /&gt;&lt;param name=&quot;display_spinner&quot; value=&quot;yes&quot; /&gt;&lt;param name=&quot;display_overlay&quot; value=&quot;yes&quot; /&gt;&lt;param name=&quot;display_count&quot; value=&quot;yes&quot; /&gt;&lt;param name=&quot;language&quot; value=&quot;en-GB&quot; /&gt;&lt;/object&gt;&lt;/div&gt;                &lt;script type=&quot;text/javascript&quot;&gt;                    var divElement = document.getElementById('viz1688392485502');                    var vizElement = divElement.getElementsByTagName('object')[0];                    vizElement.style.width='1000px';vizElement.style.height='1050px';                    var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                &lt;/script&gt;
&lt;/div&gt;</content><author><name></name></author><category term="globalizedfinance" /><summary type="html">What was ours is now mine, ex-comrade</summary></entry><entry><title type="html">Kleptocracy, Lebanese Style</title><link href="http://localhost:4000/blog/kleptocracylebanon/" rel="alternate" type="text/html" title="Kleptocracy, Lebanese Style" /><published>2022-10-09T00:00:00+02:00</published><updated>2022-10-09T00:00:00+02:00</updated><id>http://localhost:4000/blog/kleptocracylebanon</id><content type="html" xml:base="http://localhost:4000/blog/kleptocracylebanon/">&lt;h3 id=&quot;kleptocracy-in-lebanon&quot;&gt;Kleptocracy in Lebanon&lt;/h3&gt;

&lt;h4 id=&quot;a-bit-of-context-which-is-a-wild-ride-in-itself&quot;&gt;A bit of context which is a wild ride in itself&lt;/h4&gt;

&lt;p&gt;The modern story of the Lebanon starts with a French Monsieur Francois Georges-Picot, a British Gentleman Mark Sykes and the Ottoman Sultan Mehmed V.
As members of the Triple Entente between France, England and Russia, the British and French had plans for the Middle East which they wanted to wrest from the control of the Ottoman Empire which had allied itself with the German Empire.
Even before the war was over, the two diplomats Picot and Sykes duked it out and divided the central Middle East into spheres of influence between France and Britain.&lt;/p&gt;

&lt;p&gt;The British would control a strip of land ranging from modern Israel/Palestine through Jordan to central and southern Iraq, whereas France would control modern day Lebanon, Syria and northern Iraq.
European powers had a specific infatuation with protecting Christians outside of Europe.
The Russians had gone to war with the Ottoman empire as they wanted to style themselves as the protectors of Christians in the Ottoman Empire and Caucasus.
Similarly, the French wanted to see themselves as protectors of the significant Christian population living in the area around Mount Lebanon and in the Levant.
Important for the later story, the region was characterized by multi-ethnic and multi-religious cohabitation, with Maronite Christians, Druze, Shia and Sunni with their subdominations Alawites and Alevis also hanging around in the same region.
Maronite Christians are an Eastern Catholics while Druze are an eclectic mixture of religions and believes.
Shia and Sunni are similar to Protestants and Catholics in Christianity which split over an succession issue with the Shiaâ€™s favoring Ali, a direct descendant of the prophet Muhammed, while the Sunni favored the unrelated Abu Bakr.&lt;/p&gt;

&lt;p&gt;The British and French had indirectly already come to blows during a Maronite-Druze civil war in the Levant.
While the French supported the Maronites, the British wanted to protect their interests and supported the Druze.
If youâ€™re confused why Iâ€™m recounting Lebanonâ€™s history on a napkin, the multi-confessional composition of Lebanon will play an important role later on.&lt;/p&gt;

&lt;p&gt;With the collapse of the Ottoman Empire, the French became the rulers of Lebanon under the mandate of the League of Nations.
The French would stay in Lebanon until shortly after World War 2 and the country prospered.
It was soon regarded as the Switzerland of the Middle East with a well functioning administration, a multi-lingual population and strong banking secrecy.
So literally like Switzerland, but a bit sunnier.&lt;/p&gt;

&lt;p&gt;Things went well for quite some time but the ill-configured setup of the Lebanon was already discernible.
It should be noted that especially the Maronites and the Druze were ethno-religious groups which offered two ways of separating themselves from other people, through kinship and through religion.
This was unofficially encoded in the National Pact of 1943 which assigned seats and thus political power in the parliament on a 6-to-5 proportionality based on a 1932 census of the population.
Another implementation to get to grips with the multi-ethno-religious composition of the population was to predetermine the representative posts in the government according to the confession: the president was always a Maronite Christian, the speaker of the parliament a Shia and the prime minister a Sunni.
While it did not seem like the best way to govern a country, economically the strong banking sector was especially well positioned to benefit from the fresh petro money coming out of the oil rich middle eastern countries and thus the Lebanon prospered tremendously in the 1960.&lt;/p&gt;

&lt;h4 id=&quot;the-civil-war&quot;&gt;The Civil War&lt;/h4&gt;

&lt;p&gt;But right at its door step a convoluted situation had developed in the British part of the Sykes-Picot agreement.
After the establishment of the Israeli state in 1948 and the Suez War of 1956, which was also instigated by the Brits and the French over the nationalization of the Suez canal, the Israelis invaded the Sinai peninsula to open the strait of Tiran to Israeli naval vessels.
In the relatively short period of six days, Israel managed to take over the Sinai peninsula again and conquer the Gaza strip, the West Bank and East Jerusalem.
As a consequence, 300.000 Palestinians and 100.000 Syrians fled and/or were expelled from the newly occupied areas with many Palestinians fleeing to Jordan.
The suffering of the Palestinian population caused the Palestine Liberation Organization to become militarily active and soon it started accumulating large amounts of money and weapons with its headquarter established in Jordans capital Amman.&lt;/p&gt;

&lt;p&gt;The PLO as the dominant recipient of political, financial and military support and prime proxy insurgency against Israel quickly became a state within the state of Jordan.
Soon, the idea was promulgated that the PLO should overthrow the Jordan Hashemite monarchy.
Obviously the Jordanian kingdom would have none of that and the short lived Jordanian civil war broke out, in which the PLO was ultimately defeated by the Jordanian armed forces in September 1970 and allowed to leave for Lebanon.&lt;/p&gt;

&lt;p&gt;The fighting in September of 1970 lead to the formation of a terrorist splinter faction which called itself â€˜Black Septemberâ€™ and which sought retribution for the expulsion from Jordan.
But they soon focused on attacking Israel again and became infamous through the massacre of Israeli athletes at the 1972 olympic games in Munich.
Unfortunately, when the PLO arrived in Lebanon the Jordanian story was repeated again as the PLO again started to behave like a semi-autonomous state within a state.
Maybe they did inspire the Hezbollah 20 years later who are behaving just the same â€¦ but who knows.&lt;/p&gt;

&lt;p&gt;The Lebanese state of political affairs had already been fragile necessitating the afore-mentioned power sharing agreements.
The sudden arrival of the PLO as the most powerful military force in Lebanon quickly pitted them against the ethno-religious militias as power had always remained with the different political factions and not with a centralized state.
Tensions started to flare up especially with the Maronite Christian Phalange militia which ultimately led to the start of the Lebanese civil war from 1975 to 1990.&lt;/p&gt;

&lt;p&gt;While the civil war was raging, a Lebanese business man by the name of Rafic Hariri made his first millions doing construction work in Saudi-Arabia.
He quickly gained the trust of the Saudi royal family and as a native Lebanese became embroiled in the factional power plays of the Lebanese civil war.
After 15 years of civil war, the fatigued factions were ready for a peace deal and Rafic Hariri was there to broker it in one of his hotels in Taâ€™if in Saudi Arabia.
It was appropriately called the Taâ€™if agreement.&lt;/p&gt;

&lt;p&gt;Every fight should require a truth and reconciliation process in which the reasons and deeds of the each party are post-hoc worked through.
It is true that a civil war is not constant fighting and life continues once the demarcation lines, like the Green Line in Beirut separating Muslim east Beirut from Christian west Beirut, are established especially if the fighting goes on for 15 years without a clear winner.
But it is somewhat suspicious that the Taâ€™if accord was agreed upon by all the warring factions which had been fighting each other to the teeth.
And this is where the kleptocracy begins in earnest.&lt;/p&gt;

&lt;p&gt;The Taâ€™if agreement changed the parliament to a 1-to-1 Muslim-Christian preassigned composition while strengthening the president.
Nevertheless, the previous agreements such as the predetermined religious affiliation of the speaker, president and prime minister was kept.
In essence, the militias partitioned the newly founded Lebanese state among themselves and created extreme rent-seeking mechanisms and patronage systems.
Ministries were distributed to the factional warlords and jobs were allotted along sectarian affiliation.&lt;/p&gt;

&lt;h4 id=&quot;neo-liberal-post-war-order&quot;&gt;Neo-Liberal Post-War Order&lt;/h4&gt;

&lt;p&gt;This is are fairly run-of-the-mill corruption and has been replicated before and after the Taâ€™if agreement in many other countries.
But what made the Lebanese kleptocracy truly breath-taking is probably the largest Ponzi scheme and an entire national level in history that makes even Bernie Madoff look like an amateur.
It all boils down to the adage: Why rob a bank, if you can have one.&lt;/p&gt;

&lt;p&gt;One has to remember that the Lebanese state was basically run by different confessional parties which had crafted the political system in such a way that their grip on power could hardly be challenged.
This became especially evident during the 2022 elections, when new parties had to be signed off by the ruling system which obviously never allowed new parties to push them out of power.&lt;/p&gt;

&lt;p&gt;Rafic Hariri believed that the guarantor of growth for the Lebanese economy was the pegging of the Lebanese pound to the US dollar.
In a previous blog post I referred to the impossible trinity of economics: You can only choose two out of the following three: a stable exchange, a floating currency and sovereign economic policy.
The post civil war administration under Rafic Hariri chose to sacrifice economic sovereignty to keep the Lebanese pound at a stable exchange rate at around 1.500 LL to one dollar.
But since the national currency was floating, enough interest in the currency had to be generated to be able to keep the exchange rate.
Said differently, the central bank overseeing a currency pegged to the USD has to have considerable amounts of foreign exchange reserves to be able to exchange said currency at the fixed exchange rate at any time.&lt;/p&gt;

&lt;p&gt;Lebanon had been living far beyond its means for a long time.
Trade balance had averaged from 2011 to 2019 between -20% and close to -30% while the fiscal balance went from -5% to -11% in the same time period.
The country was able to stave off the consequences on the exchange rate due to the large diaspora sending back remittances.
While Lebanon itself has around 6.8m citizens, the diaspora is estimated to be between 8m to 20m people which actively are in contact with their relatives.
This large diaspora sent back home over 7 billion USD, accounting up to 10% of GDP and providing a large steady influx of foreign currencies into the country.
But with the fall of oil prices in the 2010â€™s, the remittances of the Lebanese diaspora from the oil-rich gulf states diminished, leading to the first signs of the liquidity crisis.&lt;/p&gt;

&lt;p&gt;Additionally, the banking sector had a weird skew as 1% of the accounts accounted for 50% of overall banking deposits yielding an extreme concentration.
Even better, 0.1% of accounts held 20% of all deposits at the banks inside Lebanon.
This was worrisome in its own right but raised the question who these accounts were.
If roughly 7.000 accounts controlled 20% of all deposits, this yields considerable control over the banks.
The banking sector was also concentrated in another manner, namely that the secondary debt market was very limited with 70% of all bank deposits invested in public sector and government securities.
In essence, the banks and the government were cozy with each other up to a worrying degree.
One could in fact ask whether the banking sector and the government were run by the same interest groups.
This does hark back to the proverb earlier about robbing versus owning a bank, as to how corrupt and nepotistic the banking sector in Lebanon actually was.&lt;/p&gt;

&lt;h4 id=&quot;the-swap&quot;&gt;The â€˜Swapâ€™&lt;/h4&gt;

&lt;p&gt;The peg of the Lebanese pound became more strenuous to maintain with less and less hard currencies (Euros, Dollars, Yen, Francs etc) flowing into the country.
Remember that the official peg of ~1.500 LL to 1 USD forced the central bank to have sufficient foreign currencies on hand.
With the fissures in the foundation becoming apparent, the Banque du Liban went ape-shit neo-liberal at the extreme cost of the population to maintain the currency.
It started to serve the market instead of the people.&lt;/p&gt;

&lt;p&gt;The Ministry of Finance issued Eurobonds (remember the unregulated British offshore market) in foreign currencies while the Banque du Liban issued equivalently valued treasury bills denominated in Lebanese pound.
Remember that the foundation and goal was the pegged Lebanese pound and as a consequence both the Eurobonds and the TBâ€™s were equivalent in value at least on paper.
In order to attract foreign currencies the Eurobonds offered a high interest rate up to 15% to guarantee that somebody would take the bonds off their hands.
The finance ministry and the central bank then swapped these bonds such that the central bank held the Eurobonds and the finance ministry the LL TBâ€™s.&lt;/p&gt;

&lt;p&gt;Then the central bank turned around and sold the Eurobonds on the open market receiving sought-after hard currencies in return.
But the government was still on the hook for the Eurobonds while the nominal USD value had been transferred to the central bank which was now happy that it had hard currencies again.
Who was unhappy you might ask?
The population the taxes of which were used to pay the high interest rates.
But who was the beneficiary of the high return on investment of the Lebanese Eurobonds?
The commercial banks who provided USD from the diasporas remittances and received a significant interest of up to 15%.
This encouraged the commercial banks with the diasporas USD to offer higher interest rates as well which set of a Ponzi scheme pulling in more USD dollar deposits.&lt;/p&gt;

&lt;p&gt;Additionally, the central bank printed fresh Lebanese pounds depositing them at very low interest rates at the commercial banks, while allowing the commercial banks to deposit high interest deposits at the central bank.
In total the commercial banks had net liabilities of zero, as the central bank and commercial banks matched each otherâ€™s deposits.
But the central bank gave out significant higher interest with the round-tripping profit going as high as 11%.
Since Lebanese pound and USD were equivalent with the unsustainable peg, this amounted to 11% USD denominated profits.
Not bad, ey?&lt;/p&gt;

&lt;p&gt;Ultimately, the people of Lebanon got two raw ends of a deal with the corrupt sectarian political order.
The government had to spend a lot of precious foreign currency on pegging the currency instead of devaluing it which was done with tax payer money.
Secondly, after protests erupted in 2019 the banks closed for an unprecedented two weeks and upon reopening restricted the depositors access to their dollars.
While the black market exchange had already devaluated to a 1/10th of the value, the banks maintained the official peg thus giving their customers significantly less Lebanese pounds for each dollar.
This led to the coinage (pun intended) of the term â€˜lollarâ€™ with the abbreviation â€˜lolâ€™ as the Lebanese people could look at their Dollar statements but had no means of accessing them.
Most Lebanese have given up on the notion that they will one day recover their valuable dollar deposits as they have probably been pilfered to buy the treasuryâ€™s Eurobonds on which the government defaulted.
Thus the Dollars are most likely gone forever.&lt;/p&gt;

&lt;p&gt;Given the nepotism and patronage in the entire sectarian economy this raises the strong case the commercial banks in Lebanon were obviously affiliated with the corrupt power brokers and used the central bank as printing press with USD denominated profits through the peg.
This entire financial engineering scheme amounted to little else than short-term fixes, ensuring that enough foreign currencies where in the country while paying out enormous interest rates to the commercial banks offering USD from the diaspora.
The IMF estimates that the Lebanese commercial banks participating in the scheme made off with 5 billion USD in profits at the expense of the tax payers with the central bank loosing up to 13 billion USD.&lt;/p&gt;

&lt;p&gt;Why rob a bank, if you can rob an entire country with it? Preferably its central bank.&lt;/p&gt;

&lt;p&gt;For more detailed reading, look at &lt;a href=&quot;https://www.fdd.org/analysis/2020/08/04/crisis-in-lebanon/&quot;&gt;this&lt;/a&gt; sophisticated article on the whole issue.&lt;/p&gt;</content><author><name></name></author><category term="globalizedfinance" /><summary type="html">From the People, not For the People</summary></entry><entry><title type="html">Paris to Istanbul</title><link href="http://localhost:4000/blog/ParisIstanbul2022-copy/" rel="alternate" type="text/html" title="Paris to Istanbul" /><published>2022-09-08T00:00:00+02:00</published><updated>2022-09-08T00:00:00+02:00</updated><id>http://localhost:4000/blog/ParisIstanbul2022%20copy</id><content type="html" xml:base="http://localhost:4000/blog/ParisIstanbul2022-copy/">&lt;!-- ## Berlin Over The Years --&gt;
&lt;style&gt;
    .image-gallery {overflow: auto; margin-left: -1%!important;}
    .image-gallery li {float: left; float: top; display: block; margin: 0 0 1% 1%; width: 99%;}
    .image-gallery li a {text-align: top; text-decoration: none!important; color: #777;}
    .image-gallery li a span {display: block; text-overflow: ellipsis; overflow: hidden; white-space: nowrap; padding: 3px 0;}
    .image-gallery li a img {width: 100%; height: 100%; display: flex; vertical-align: top;
    }
&lt;/style&gt;

&lt;ul class=&quot;image-gallery&quot;&gt;
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul001.jpg&quot; title=&quot;parisistanbul001&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul001.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul001&quot; title=&quot;parisistanbul001&quot; /&gt;&lt;span&gt;parisistanbul001&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul001.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul001.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul002.jpg&quot; title=&quot;parisistanbul002&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul002.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul002&quot; title=&quot;parisistanbul002&quot; /&gt;&lt;span&gt;parisistanbul002&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul002.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul002.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul003.jpg&quot; title=&quot;parisistanbul003&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul003.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul003&quot; title=&quot;parisistanbul003&quot; /&gt;&lt;span&gt;parisistanbul003&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul003.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul003.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul201.jpg&quot; title=&quot;parisistanbul201&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul201.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul201&quot; title=&quot;parisistanbul201&quot; /&gt;&lt;span&gt;parisistanbul201&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul201.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul201.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul202.jpg&quot; title=&quot;parisistanbul202&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul202.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul202&quot; title=&quot;parisistanbul202&quot; /&gt;&lt;span&gt;parisistanbul202&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul202.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul202.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul203.jpg&quot; title=&quot;parisistanbul203&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul203.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul203&quot; title=&quot;parisistanbul203&quot; /&gt;&lt;span&gt;parisistanbul203&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul203.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul203.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul209.jpg&quot; title=&quot;parisistanbul209&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul209.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul209&quot; title=&quot;parisistanbul209&quot; /&gt;&lt;span&gt;parisistanbul209&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul209.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul209.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul210.jpg&quot; title=&quot;parisistanbul210&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul210.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul210&quot; title=&quot;parisistanbul210&quot; /&gt;&lt;span&gt;parisistanbul210&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul210.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul210.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul219.jpg&quot; title=&quot;parisistanbul219&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul219.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul219&quot; title=&quot;parisistanbul219&quot; /&gt;&lt;span&gt;parisistanbul219&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul219.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul219.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    &lt;!-- &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul220.jpg&quot; title=&quot;parisistanbul220&quot;&gt;&lt;img src=&quot;//images.weserv.nl/?url=localhost:4000/photo_gallery/parisistanbul22/parisistanbul220.jpg&amp;w=300&amp;h=300&amp;output=jpg&amp;q=50&amp;t=square&quot; alt=&quot;parisistanbul220&quot; title=&quot;parisistanbul220&quot; /&gt;&lt;span&gt;parisistanbul220&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; --&gt;
    &lt;li&gt;&lt;a href=&quot;/photo_gallery/parisistanbul22/parisistanbul220.jpg&quot;&gt;&lt;img src=&quot;/photo_gallery/parisistanbul22/parisistanbul220.jpg&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
&lt;/ul&gt;</content><author><name></name></author><category term="photography" /><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/photo_gallery/parisistanbul22/parisistanbul201.jpg" /></entry></feed>