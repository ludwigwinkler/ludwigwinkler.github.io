---
layout: post
title:  "Annealed Importance Sampling"
category: blog
date:   2025-02-12
excerpt: "... it's giving off the same energy!"
# highlighter: rouge
image: "/blog/ItoDensityEstimator.png"
---
<head>
<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
       <script type="text/x-mathjax-config">
         MathJax.Hub.Config({
          TeX: {
                equationNumbers: { autoNumber: "all" },
                extensions: ["AMSmath.js", "AMSsymbols.js", "cancel.js"]
            },
           tex2jax: {
             inlineMath: [ ['$','$'], ["\\(","\\)"] ],
             displayMath: [['$$','$$']],
             processEscapes: true
           }
         });
       </script>
       <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>

### Energy

In the context of statistical mechanics, the energy of a system is a measure of its state. In the context of machine learning, we can think of the energy as a measure of how well a model fits the data. The lower the energy, the better the fit.

- absolute energy doesn't matter, only relative energy matters
- potential energy defined with reference to earth surface, just add six feet if you're dead
- we can always add +/-c to the energy of a system, it doesn't change the physics
- plot where two energy functions with different heights result in the same probability distribution
- why not work with the energy directly? after all lower is better, right?
  - because absolute values of energy without an anchor are meaningless, but a probability of 0.000001 or 0.98 is meaningful
  - I give you energy values of 100, 200, 300, and 400, you have no idea what they mean, but I give you probabilities of 0.01, 0.02, 0.03, and 0.04, you know exactly what they mean
  - because we want to work with probabilities, not energies
  - we can convert energy to probability using the Boltzmann distribution
- Boltzmann distribution: $P(x) = \frac{e^{-E(x)}}{Z}$, where $Z$ is the partition function
- in ML, this occurs in logsumexp and softmax, where we can add a constant to the log likelihood without changing the model, used to avoid numerical issues 

### Importance Sampling

how to estimate $Z$ with importance sampling

### Annealed Importance Sampling

- Pull Z through explicitely to show how it distributions evolve

- do the mathematically nice thing pull through the importance weights

### Sequential Monte Carlo